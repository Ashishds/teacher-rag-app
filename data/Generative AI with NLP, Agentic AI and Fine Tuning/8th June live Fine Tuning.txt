WEBVTT

00:00:00.080 --> 00:00:03.460
Okay, fine. So let's get started guys. So like I said, today

00:00:03.460 --> 00:00:07.340
I will be talking about fine tuning and in this lecture, I'm

00:00:07.340 --> 00:00:10.560
not just going to talk about a fine tuning in my local

00:00:10.560 --> 00:00:14.180
system, but I'll even try to show you that how we can try to

00:00:14.180 --> 00:00:18.320
do a fine tuning in a real time, right in a real time with

00:00:18.320 --> 00:00:22.280
our open AI model, part number one. So in a local, I'm going

00:00:22.280 --> 00:00:25.380
to show you like a fine tuning that how you will be able to

00:00:25.380 --> 00:00:28.640
do a fine tuning based on the LoRa and QLoRa basically,

00:00:28.840 --> 00:00:32.600
right? So basically like a low rank adoption and then like a

00:00:32.600 --> 00:00:35.600
quantized low rank adoption. So based on that, how you will

00:00:35.600 --> 00:00:39.200
be able to do a fine tuning in your local system, part

00:00:39.200 --> 00:00:41.620
number one, then after doing a fine tuning, so how you will

00:00:41.620 --> 00:00:45.740
be able to do the inferencing and the third part is, so once

00:00:45.740 --> 00:00:49.600
let's suppose I have created my fine tuned model, right? If

00:00:49.600 --> 00:00:53.100
I have created my fine tuned file, so how I can make it

00:00:53.100 --> 00:00:56.180
available into a hugging phase means I have done the fine

00:00:56.180 --> 00:00:59.080
tuning. I'm going to do the fine tuning. It's available in

00:00:59.080 --> 00:01:02.700
my local or maybe in some other server. And let's suppose I

00:01:02.700 --> 00:01:05.860
have to make it available for the entire public so that

00:01:05.860 --> 00:01:09.260
anyone and everyone in this world will be able to use it. So

00:01:09.260 --> 00:01:12.540
that is also, I'm going to show you. So like a local fine

00:01:12.540 --> 00:01:15.500
tuning, then pushing those fine tune model into an hugging

00:01:15.500 --> 00:01:18.360
phase repository so that all of us will be able to use it

00:01:18.360 --> 00:01:21.900
the way you are downloading a model. So even you are using a

00:01:21.900 --> 00:01:24.120
hugging phase and you are trying to download the model. So

00:01:24.120 --> 00:01:26.940
someone has pushed it over there. So that is something which

00:01:26.940 --> 00:01:29.780
I'm going to teach you. In today's class, apart from that.

00:01:29.880 --> 00:01:33.400
So how I will be able to do a fine tuning with respect to

00:01:33.400 --> 00:01:37.080
our open AI. So open AI, again, there are like a tons of

00:01:37.080 --> 00:01:40.420
model which is available in our open AI. So GPT like a 3.5,

00:01:40.500 --> 00:01:43.780
GPT-4, all sorts of models are available inside our open AI.

00:01:44.140 --> 00:01:47.680
And we'll try to prepare a data based on the supervised fine

00:01:47.680 --> 00:01:50.660
tuning or based on the RHFL kind of a fine tuning. So we'll

00:01:50.660 --> 00:01:53.640
see that how we can try to prepare a data set for such kind

00:01:53.640 --> 00:01:56.600
of a fine tuning. And then how we can actually do a fine

00:01:56.600 --> 00:02:00.340
tuning. In reality, so that model will be aware about my

00:02:00.340 --> 00:02:03.820
fine tune data. Apart from that, also, I'm going to show you

00:02:03.820 --> 00:02:06.880
that whatever model is available, whether it's a Lama,

00:02:06.960 --> 00:02:09.880
whether it's a Mistral, or any other model which is

00:02:09.880 --> 00:02:13.960
available on hugging phase. So how you will be able to do a

00:02:13.960 --> 00:02:17.960
fine tuning for any model, whether it's a LLM model, whether

00:02:17.960 --> 00:02:20.520
it's like a vision model, whether it's a machine learning

00:02:20.520 --> 00:02:24.000
model, whatever is available on hugging phase. How you will

00:02:24.000 --> 00:02:27.000
be able to do a fine tuning based on your own model. How you

00:02:27.000 --> 00:02:27.480
will be able to do a fine tuning based on your own data set.

00:02:27.580 --> 00:02:31.820
So this class is going to be a complete master class for a

00:02:31.820 --> 00:02:35.560
fine tuning after today's class. So whatever model that you

00:02:35.560 --> 00:02:38.660
would like to do, like a fine tuning with, I believe you

00:02:38.660 --> 00:02:41.760
will be able to do it all model on a hugging phase without

00:02:41.760 --> 00:02:45.760
any kind of exception, everything on open AI and then even

00:02:45.760 --> 00:02:51.140
in a local based on PEFT parameter efficient fine tuning

00:02:51.140 --> 00:02:53.980
basically. So inside PEFT, there are two components which

00:02:53.980 --> 00:02:56.320
comes into a picture. One is a Cora and one is a Laura.

00:02:56.440 --> 00:02:59.240
Basically. And I'll be talking about that as well, that what

00:02:59.240 --> 00:03:02.060
is the exact meaning of this Laura and what is the exact

00:03:02.060 --> 00:03:05.300
meaning of this Q Laura basically. So is it making sense

00:03:05.300 --> 00:03:05.540
guys?

00:03:08.660 --> 00:03:10.200
Yes. Shall we move ahead?

00:03:18.720 --> 00:03:20.920
Amarath is asking me a question also, what is the main

00:03:20.920 --> 00:03:24.220
difference between agent TKI and MCP? I'm little bit

00:03:24.220 --> 00:03:28.400
confused. See even in MCP, so we try to like build tools and

00:03:28.400 --> 00:03:33.200
we try to like make it open. So MCP is technically a

00:03:33.200 --> 00:03:37.220
protocol, right? For example, what is, what is API? So API

00:03:37.220 --> 00:03:39.120
is nothing but it's a protocol, it's a set of the rule.

00:03:39.640 --> 00:03:43.720
Similarly, MCP is a set of the protocol by the way that,

00:03:43.760 --> 00:03:47.640
okay, so any application which is going to follow this

00:03:47.640 --> 00:03:52.300
protocol can be attached to any other application. So people

00:03:52.300 --> 00:03:55.400
have built a standardized approach and everyone is nowadays

00:03:55.400 --> 00:03:59.740
trying to adopt it. For example, so, so far in this entire

00:03:59.740 --> 00:04:04.380
tech world, inside this entire IT world, you must have seen

00:04:04.380 --> 00:04:08.180
that every platform is providing API. Right? So API is what

00:04:08.180 --> 00:04:12.220
API is a standard approach where anyone can look into that

00:04:12.220 --> 00:04:15.520
API. Anyone can call that API by passing credential by

00:04:15.520 --> 00:04:18.140
without passing credential, and they will be able to use

00:04:18.140 --> 00:04:20.900
your product or whatever you are trying to expose via API.

00:04:21.080 --> 00:04:24.800
So API is what technically it's a protocol, right? It's a

00:04:24.800 --> 00:04:27.020
set of rule that, okay, so whenever you are trying to expose

00:04:27.020 --> 00:04:28.840
this one, this is the path. This is the route that you

00:04:28.840 --> 00:04:31.240
should follow. This is the set of the rule. Now. Similarly,

00:04:31.380 --> 00:04:36.420
MCP is technically a protocol that, okay. So if you have to

00:04:36.420 --> 00:04:36.640
apply this protocol, this is the path. If you have to

00:04:36.640 --> 00:04:39.520
attach, or if you have to call, if one tool would like to

00:04:39.520 --> 00:04:42.460
call any other tools, for example, my chat GPT, for example,

00:04:42.540 --> 00:04:46.540
my cloud, for example, like a MCP inspector, or maybe like

00:04:46.540 --> 00:04:49.680
a, your any application, right? If it would like to call

00:04:49.680 --> 00:04:54.100
some other tool. So, so far with the help of API can be

00:04:54.100 --> 00:04:57.200
called, right? With the help of API. So with that route, I

00:04:57.200 --> 00:05:00.720
will be able to call it now. So MCP is a set of the rule,

00:05:00.820 --> 00:05:03.160
which has been derived that, okay, fine. So expose that as a

00:05:03.160 --> 00:05:06.900
MCP and even other is following the same rule. I will be

00:05:06.900 --> 00:05:10.220
able to attach both, right? So now you can call any agents.

00:05:10.320 --> 00:05:12.320
You can call any kind of a tools over there. So that's the

00:05:12.320 --> 00:05:17.100
exact definition of the MCP. Hope you are, I'm able to

00:05:17.100 --> 00:05:21.760
explain you, is this question was from Amarnath, I believe.

00:05:21.900 --> 00:05:25.780
Yeah. Amarnath. It's a protocol, by the way, you can call

00:05:25.780 --> 00:05:28.560
tools, you can call agents, all, whatever you want. You can

00:05:28.560 --> 00:05:28.980
call it.

00:05:33.930 --> 00:05:41.530
Okay. So, sir, when we say fine tuning. Is it that we need

00:05:41.530 --> 00:05:45.490
to optimize the performance of the model on my own data set,

00:05:45.630 --> 00:05:48.510
I will be talking about it. Don't worry. So this class is

00:05:48.510 --> 00:05:52.830
going to be a masterclass of fine tuning. And hopefully this

00:05:52.830 --> 00:05:55.710
class is going to be our last class for your entire

00:05:55.710 --> 00:05:58.630
generative AI lecture. So next week onwards, you don't have

00:05:58.630 --> 00:06:04.290
a class. So I'm going to wrap up this class today. But after

00:06:04.290 --> 00:06:07.230
discussing about this entire things in a very depth, you can

00:06:07.230 --> 00:06:09.910
expect that today will go a little bit longer. Maybe like it

00:06:09.910 --> 00:06:12.310
will take three, three and a half hour of time to discuss

00:06:12.310 --> 00:06:15.850
each and everything. Maybe before that we can, we can try to

00:06:15.850 --> 00:06:18.110
conclude, but yeah, at least because in fine tuning,

00:06:18.270 --> 00:06:20.830
whatever syllabus, which I have mentioned, I'm going to

00:06:20.830 --> 00:06:23.250
cover each and everything in today's class itself. I'll try

00:06:23.250 --> 00:06:26.610
to show you a demo in today's class itself, along with me,

00:06:26.790 --> 00:06:30.410
you guys will be able to do it. If you want, you can do it

00:06:30.410 --> 00:06:33.770
parallelly and you will be able to get the entire experience

00:06:33.770 --> 00:06:38.350
that what exactly the fine tuning is and what can be done.

00:06:38.410 --> 00:06:39.970
What can't be done. What can't be done with the fine tuning

00:06:39.970 --> 00:06:43.810
and how fine tuning is different from RAG. Many people are

00:06:43.810 --> 00:06:47.750
going to come and argue that we are doing a fine tuning. Can

00:06:47.750 --> 00:06:50.750
we go ahead with the RAG because with the help of RAG, I

00:06:50.750 --> 00:06:54.210
will be able to, you know, achieve the exact same thing,

00:06:54.250 --> 00:06:57.530
right? So I'll try to explain you even that particular part.

00:07:01.290 --> 00:07:04.630
Okay. So let's get started guys, step by step, one by one.

00:07:04.910 --> 00:07:07.630
So one step at a time. So we are going to take, and then we

00:07:07.630 --> 00:07:10.810
are going to understand that how we are going to do a fine

00:07:10.810 --> 00:07:14.210
tuning. So let me share my screen. By the way, and I have

00:07:14.210 --> 00:07:17.870
prepared a lot of demo yesterday night. So the late night I

00:07:17.870 --> 00:07:21.070
was just preparing all of this, like a running demo for all

00:07:21.070 --> 00:07:24.550
of you. So I can, so that I can come to class and then I can

00:07:24.550 --> 00:07:29.890
show it to you. Plus guys, you need a account of open AI. So

00:07:29.890 --> 00:07:33.210
anyone who is not having an account, so you need an account

00:07:33.210 --> 00:07:36.070
of open AI. So when I have to show you the fine tuning with

00:07:36.070 --> 00:07:40.310
respect to open AI model, right? Open AI model, all of this

00:07:40.310 --> 00:07:43.790
model. GPD three, four, a turbo, Beanie, nano preview,

00:07:43.990 --> 00:07:47.370
everything you will be able to fine tune. And apart from

00:07:47.370 --> 00:07:51.010
that, so you need a account basically on hugging face,

00:07:51.250 --> 00:07:54.190
right? Hugging face. So please try to log in on a open AI.

00:07:54.430 --> 00:07:57.330
Please try to log in on a hugging face, a inside hugging

00:07:57.330 --> 00:07:59.470
face. So I'm going to show you even there is something

00:07:59.470 --> 00:08:02.450
called as auto train. So where you can go and you can try to

00:08:02.450 --> 00:08:05.830
select any of these models. So I'll try to show you that how

00:08:05.830 --> 00:08:10.050
you can try to, you know, uh, create this, uh, auto train,

00:08:10.450 --> 00:08:13.290
like a models and then how you will be able to, uh,

00:08:13.470 --> 00:08:17.370
basically like a perform those operations. So a lot of

00:08:17.370 --> 00:08:19.990
things, guys, a lot of things, uh, I'm going to like, uh,

00:08:20.090 --> 00:08:25.430
talk about in my today's class. Yeah. Okay. So let's get

00:08:25.430 --> 00:08:28.770
started. First of all, with a theory, though, let me share

00:08:28.770 --> 00:08:31.550
my screen. Okay. Screen is already sharing. So it's

00:08:31.550 --> 00:08:35.010
scribbling by the way. Let's talk about a theory. First of

00:08:35.010 --> 00:08:39.350
all, that what exactly this, uh, fine tuning is right.

00:08:39.570 --> 00:08:43.750
Right. This fine tuning is, and uh, what is a meaning of a P

00:08:43.750 --> 00:08:48.250
E F D parameter efficient fine tuning inside of that, uh,

00:08:48.450 --> 00:08:54.650
you will be able to get the term called as a L O R a. So low

00:08:54.650 --> 00:08:58.590
rank, uh, like a based adoption or a low rank based fine

00:08:58.590 --> 00:09:02.370
tuning basically. And you will be able to find out something

00:09:02.370 --> 00:09:07.470
called as Q L O R A. So Qlora means basically it's a

00:09:07.470 --> 00:09:12.570
quantize low. Right? rank adaption. So what is the

00:09:12.570 --> 00:09:17.170
difference between this LoRa and QLoRa and then we'll be

00:09:17.170 --> 00:09:20.150
talking about I'll try to give you a lot of insights, right,

00:09:20.210 --> 00:09:22.410
a lot of insights that you will be able to understand even

00:09:22.410 --> 00:09:24.790
mathematically that, okay, so what is the difference between

00:09:24.790 --> 00:09:28.010
these two and from an interview perspective, this is

00:09:28.010 --> 00:09:31.190
important. If you have mentioned that you do a fine tuning,

00:09:31.350 --> 00:09:34.350
people are going to ask you the differences and today I

00:09:34.350 --> 00:09:37.230
believe I'm going to clarify that particular difference. So

00:09:37.230 --> 00:09:41.150
guys, see, first of all, what is fine tuning by the way,

00:09:41.230 --> 00:09:44.690
right? And what are the advantages that you all will be able

00:09:44.690 --> 00:09:47.910
to get with the help of fine tuning? Let's try to understand

00:09:47.910 --> 00:09:52.530
that part. So we have a models, right? We have a chat GPT

00:09:52.530 --> 00:09:55.550
models. We have a Gemini models. We have a Mistral models.

00:09:55.810 --> 00:09:58.630
We have models from PopXLity. We have a models from Lama

00:09:58.630 --> 00:10:03.050
series. So we have all of these models and we all know that

00:10:03.050 --> 00:10:06.750
these model is being trained on a certain model. Certain

00:10:06.750 --> 00:10:10.150
data set, right? Certain data set. And nowadays the model

00:10:10.150 --> 00:10:12.250
that we are able to receive the best model that we are able

00:10:12.250 --> 00:10:15.570
to receive. So it is having all the knowledges. It simply

00:10:15.570 --> 00:10:18.010
means that, that it has been trained on all of, all of those

00:10:18.010 --> 00:10:22.730
data set. But, but if you are going to ask a question to

00:10:22.730 --> 00:10:26.770
this model, uh, maybe with respect to a Euron, right? Maybe

00:10:26.770 --> 00:10:28.590
with respect to Euron, if you're going to ask a question,

00:10:28.770 --> 00:10:32.650
maybe those model will not be able to respond, right? Uh, if

00:10:32.650 --> 00:10:35.550
you are going to ask some sort of a question, maybe with

00:10:35.550 --> 00:10:38.390
respect to Euron, maybe your organization, yeah, let's

00:10:38.390 --> 00:10:40.190
suppose your organization is having a certain policies,

00:10:40.270 --> 00:10:42.970
certain HR policies, certain finance policies, certain loan

00:10:42.970 --> 00:10:45.770
policy, right? Certain healthcare policies, certain

00:10:45.770 --> 00:10:49.690
insurance policies. So those model will not be able to

00:10:49.690 --> 00:10:53.110
respond because your organization policy is a private,

00:10:53.250 --> 00:10:55.550
right? Your organization policy is basically private and

00:10:55.550 --> 00:10:58.790
it's private, uh, to your organization. The data is private

00:10:58.790 --> 00:11:01.130
to your organization and model is not aware about that

00:11:01.130 --> 00:11:04.490
particular data. So if model is not aware about that

00:11:04.490 --> 00:11:07.930
particular data. Yeah. Then obviously it will not be able to

00:11:07.930 --> 00:11:13.650
respond, right? It will not be able to respond now. So if I

00:11:13.650 --> 00:11:19.790
want a model to respond based on my data, then what are the

00:11:19.790 --> 00:11:23.230
approaches that I can try to take? Yeah. What are the

00:11:23.230 --> 00:11:26.630
approaches I can try to take? So approach number one, which

00:11:26.630 --> 00:11:30.990
I can try to take is a basically RAG. Yeah. So we have

00:11:30.990 --> 00:11:33.590
already discussed about RAG by the way. So approach number

00:11:33.590 --> 00:11:36.370
one. Yeah. We have already built a lot of RAG application in

00:11:36.370 --> 00:11:39.870
a past, in a class itself. So retrieval augmented generation

00:11:39.870 --> 00:11:44.230
is one of the approach I can try to follow. Now what RAG

00:11:44.230 --> 00:11:47.890
does? So RAG is going to take a LLM model. That's completely

00:11:47.890 --> 00:11:52.630
fine. But technically we try to, when we talk about a RAG,

00:11:52.710 --> 00:11:56.870
so we try to basically store all the information into some

00:11:56.870 --> 00:11:59.990
of the vector database, right? Vector DB. We try to store

00:11:59.990 --> 00:12:03.230
all the information, vector database. Now. So whenever

00:12:03.230 --> 00:12:07.210
someone is going to fire a query, so it will try to do us

00:12:07.210 --> 00:12:09.490
some sort of a searching, some sort of a matching, some sort

00:12:09.490 --> 00:12:11.670
of a similarity search, it will try to do maybe a Euclidean,

00:12:11.710 --> 00:12:15.310
maybe cosine. It will try to do a similarity search. So

00:12:15.310 --> 00:12:20.570
let's suppose if I'm going to fire a query, query, so it

00:12:20.570 --> 00:12:25.730
will go to vector DB and then what ever top K result I will

00:12:25.730 --> 00:12:29.490
be able to get, so I'm going to combine it with my vector

00:12:29.490 --> 00:12:34.450
DB. Okay. And then that will be passed to a LLM, right? That

00:12:34.450 --> 00:12:37.110
will be passed to the LLM. So that LLM is going to like, you

00:12:37.110 --> 00:12:39.330
know, policy it, and then it will be able to give me the

00:12:39.330 --> 00:12:43.310
formatted response. This is what happens in case of RAG. So

00:12:43.310 --> 00:12:48.250
if I have to, like if, if my model should respond with my

00:12:48.250 --> 00:12:52.070
organizational data or maybe my private data, RAG is one of

00:12:52.070 --> 00:12:55.590
the approach. Yeah. RAG is one of the approach. That's

00:12:55.590 --> 00:12:59.990
completely fine. Uh, but the problem with RAG is that. that

00:12:59.990 --> 00:13:04.310
you have to store all of those data into a vector database,

00:13:04.690 --> 00:13:07.970
yeah vector database and every time so it will go to a

00:13:07.970 --> 00:13:10.550
vector DB it will try to do a similarity search and then it

00:13:10.550 --> 00:13:13.590
will be able to give you a response right then only it will

00:13:13.590 --> 00:13:17.990
be able to give you the response now so RAG is best RAG is

00:13:17.990 --> 00:13:21.830
best so whenever your data is changing frequently so let's

00:13:21.830 --> 00:13:24.590
suppose today is this policy tomorrow someone else is going

00:13:24.590 --> 00:13:27.290
to come and they are going to change the policy so if

00:13:27.290 --> 00:13:30.530
something is changing very frequently but still I want my

00:13:30.530 --> 00:13:33.230
model to you know format it and give me a response so in

00:13:33.230 --> 00:13:35.350
that situation I can go ahead with the RAG approach

00:13:35.350 --> 00:13:38.130
retrieval augmented generation approach but let's suppose

00:13:38.130 --> 00:13:41.210
since last 10 years I have a same policy in my company right

00:13:41.210 --> 00:13:44.390
or let's suppose like there is a research paper which I have

00:13:44.390 --> 00:13:47.210
published and it's already been published and now nothing is

00:13:47.210 --> 00:13:50.350
going to change in that research paper I want my model to

00:13:50.350 --> 00:13:53.490
know about my research paper as well maybe my model has not

00:13:53.490 --> 00:13:56.330
seen it I have published the research paper today. And model

00:13:56.330 --> 00:14:00.050
like was trained till studies data right and the research

00:14:00.050 --> 00:14:02.530
paper that I have published is not going to change or maybe

00:14:02.530 --> 00:14:05.590
the data the innovation that I have done the findings that I

00:14:05.590 --> 00:14:08.530
have done it is not going to change let's suppose right but

00:14:08.530 --> 00:14:12.470
my model is not aware about it your GPT model you're like a

00:14:12.470 --> 00:14:15.990
like a scout a sonnet model is not aware about it Gemini is

00:14:15.990 --> 00:14:19.110
not aware about it your LLM Lama is not aware about it

00:14:19.110 --> 00:14:24.010
Maverick is not aware about it right so and your data is

00:14:24.010 --> 00:14:26.410
constant basically your data is not changing. So in that

00:14:26.410 --> 00:14:31.010
case what I can do is I can try to follow one approach

00:14:31.010 --> 00:14:37.250
called as fine fine tuning right I can follow approach

00:14:37.250 --> 00:14:40.690
called as fine tuning when data is not changing right so in

00:14:40.690 --> 00:14:44.330
the case of fine tuning I don't have to involve a vector

00:14:44.330 --> 00:14:47.130
database means whenever someone is going to query I don't

00:14:47.130 --> 00:14:49.970
have to hit my vector database again and again and again and

00:14:49.970 --> 00:14:54.790
extract the chunk and then go for the answering no so if my

00:14:54.790 --> 00:14:58.850
model is already aware about a data. Like the data private

00:14:58.850 --> 00:15:02.850
data that I have right the data that I have so I can

00:15:02.850 --> 00:15:05.290
directly go ahead and do the inferencing with the model

00:15:05.290 --> 00:15:08.730
right so after inferencing the way I'm trying I'm able to

00:15:08.730 --> 00:15:11.430
inference the current model so even after fine tuning I will

00:15:11.430 --> 00:15:14.070
be able to inference it I will be able to get the response

00:15:14.070 --> 00:15:18.570
but you should not do a fine tuning where your data is

00:15:18.570 --> 00:15:22.150
changing frequently. The only reason is that fine tuning is

00:15:22.150 --> 00:15:25.890
a costly approach so fine tuning is basically one time like.

00:15:26.850 --> 00:15:28.830
It will give you a cost means whenever you will fine tune

00:15:28.830 --> 00:15:32.530
obviously your GPUs and your CPUs will come into a picture

00:15:32.530 --> 00:15:36.770
your resources will come into a picture and it will cost you

00:15:36.770 --> 00:15:40.470
something right. RAG will keep on giving you a recurring

00:15:40.470 --> 00:15:44.370
cost as your data will increase you will try to take a

00:15:44.370 --> 00:15:46.970
bigger and bigger and bigger instances of vector database

00:15:46.970 --> 00:15:50.010
and then you will keep on holding a data inside that so both

00:15:50.010 --> 00:15:52.010
both is having pros and cons and this is something which I'm

00:15:52.010 --> 00:15:54.870
trying to explain you that RAG will give you a recurring

00:15:54.870 --> 00:15:58.270
kind of a cost as it's not like RAG will go for a free no

00:15:58.270 --> 00:16:01.670
not at all you are using a LLM model so technically you are

00:16:01.670 --> 00:16:05.110
doing an inferencing even in case of RAG right even in case

00:16:05.110 --> 00:16:07.870
of a fine tuned model you are going to do the inferencing in

00:16:07.870 --> 00:16:10.870
case of RAG you are using the inferencing of the model plus

00:16:10.870 --> 00:16:15.150
vector DB and obviously vector DB is a costly operation

00:16:15.150 --> 00:16:18.250
right it's a costly operation by the way and as your data

00:16:18.250 --> 00:16:21.110
size will grow so obviously you have to increase the

00:16:21.110 --> 00:16:23.930
instances and again the search is going to be the costly

00:16:23.930 --> 00:16:27.470
operation it needs a more compute. By the way in terms of

00:16:27.470 --> 00:16:30.890
even doing a check like a checking and then trying to find

00:16:30.890 --> 00:16:35.910
out the similar similar top K data so to avoid that if my

00:16:35.910 --> 00:16:39.070
data is constant what we do is that we go ahead with the

00:16:39.070 --> 00:16:43.970
fine tuning approach that okay let's try to like a train my

00:16:43.970 --> 00:16:47.930
model the existing big model right the big one which is

00:16:47.930 --> 00:16:50.610
already aware about a lot of context lot of like information

00:16:50.610 --> 00:16:56.270
with my small data right with my small data. RAG. And then

00:16:56.270 --> 00:17:01.670
try to use the same big model for my day to day job right

00:17:01.670 --> 00:17:04.150
for my day to day job so this is something called as fine

00:17:04.150 --> 00:17:09.170
tuning now in case of fine tuning we can try to go and

00:17:09.170 --> 00:17:12.390
adjust the entire weight so when I talked about transformer

00:17:12.390 --> 00:17:14.890
right so I have already shown you in a transformer

00:17:14.890 --> 00:17:19.790
visualization that everywhere wherever we talk about KQV so

00:17:19.790 --> 00:17:22.090
obviously everywhere we will be having a weight matrix I

00:17:22.090 --> 00:17:25.590
hope you remember the attention formula KQV. Right. Based on

00:17:25.590 --> 00:17:31.450
KQV right that I have explained you so basically in case of

00:17:31.450 --> 00:17:34.650
fine tuning what we can do is so whatever neural network

00:17:34.650 --> 00:17:37.750
like a weights I'm just going to draw a very simple neural

00:17:37.750 --> 00:17:42.370
network so whatever weight that we have whatever weight that

00:17:42.370 --> 00:17:45.610
we have so here we have a weight in between right so we can

00:17:45.610 --> 00:17:48.770
go ahead and we can try to change all the weight we can tune

00:17:48.770 --> 00:17:53.290
all the weight yeah that is one of the approach in terms of

00:17:53.290 --> 00:17:57.250
fine tuning right. Now let's talk about a transformer

00:17:57.250 --> 00:18:01.150
architecture and let's talk about a 96 layer maybe a 400

00:18:01.150 --> 00:18:05.190
layer 500 or thousands layers right layer of such kind of a

00:18:05.190 --> 00:18:09.410
transformer now the number of parameter will be in billion

00:18:09.410 --> 00:18:12.270
and again we are able to see like a 70 billion parameter

00:18:12.270 --> 00:18:14.910
model right so from Lama itself even 400 billion parameter

00:18:14.910 --> 00:18:19.310
model we had yeah so the number of parameter means number of

00:18:19.310 --> 00:18:21.990
trainable parameter I'm talking about these weights right

00:18:21.990 --> 00:18:26.470
it's 400 billion. 70 billion right even 1 billion it's a

00:18:26.470 --> 00:18:31.250
huge number. So if you will start tuning all of this as per

00:18:31.250 --> 00:18:33.870
your small data that you are trying to pass or whatever data

00:18:33.870 --> 00:18:37.270
you are trying to pass right again this fine tuning will be

00:18:37.270 --> 00:18:40.430
a costly approach the meaning of fine tuning is very simple

00:18:40.430 --> 00:18:45.970
changing our weight changing our weight which the weight

00:18:45.970 --> 00:18:50.430
which is adjusted on my data set or adding some weights over

00:18:50.430 --> 00:18:53.490
here right adding some weights over here. So which is

00:18:53.490 --> 00:18:56.530
basically been tuned or which is which will be able to

00:18:56.530 --> 00:18:58.590
understand the relationship between my data because at the

00:18:58.590 --> 00:19:00.730
end of the day any neural network is going to give you an

00:19:00.730 --> 00:19:04.510
output based on the weights right based on the bits and

00:19:04.510 --> 00:19:07.190
biases that's it right doesn't matter which design you are

00:19:07.190 --> 00:19:09.710
going to use because at the end it's just architecture right

00:19:09.710 --> 00:19:12.110
but at the end of the day trainable parameters are weight

00:19:12.110 --> 00:19:15.910
right so here basically

00:19:19.560 --> 00:19:22.380
we can go ahead and we can try to change all the weights

00:19:22.380 --> 00:19:24.680
that's one of the approach but this approach is again going

00:19:24.680 --> 00:19:26.960
to be very costly approach. Because we are talking about a

00:19:26.960 --> 00:19:29.940
billions of parameter right but I hope you are able to

00:19:29.940 --> 00:19:31.920
understand the meaning of fine tuning fine tuning means

00:19:31.920 --> 00:19:38.220
changing of weights as per your own data set right and

00:19:38.220 --> 00:19:41.140
changing a weight not from the scratch not from the random

00:19:41.140 --> 00:19:44.580
weights changing a weight from a weight where model has

00:19:44.580 --> 00:19:48.160
already learnt a lot this model has already adjusted a lot

00:19:48.160 --> 00:19:50.300
so that's the reason so we are using a fine tuning right

00:19:50.300 --> 00:19:52.700
otherwise we can go and we can try to create a model from

00:19:52.700 --> 00:19:56.420
the scratch right. But no. We want a previous knowledge as

00:19:56.420 --> 00:19:58.620
well as we want a new knowledge we want both the knowledge

00:19:58.620 --> 00:20:02.000
by the way right. So if you want both the knowledge in that

00:20:02.000 --> 00:20:05.480
case obviously we have to train or we have to tune the

00:20:05.480 --> 00:20:08.840
previous model the existing the big model by the way okay.

00:20:09.020 --> 00:20:13.480
So fine tuning now changing all the weights is going to be

00:20:13.480 --> 00:20:16.160
the costliest operation and I don't want to follow that

00:20:16.160 --> 00:20:19.520
approach that's yes I don't want to follow that approach

00:20:19.520 --> 00:20:24.220
basically. So what approach I should follow? Where? Where I

00:20:24.220 --> 00:20:27.840
will be able to tune my model the big one with the billions

00:20:27.840 --> 00:20:32.520
of parameter but in a very very efficient way right in a

00:20:32.520 --> 00:20:35.480
very very efficient way so then people have derived

00:20:35.480 --> 00:20:38.880
basically for a fine tuning people have derived an approach

00:20:38.880 --> 00:20:43.840
called as PEFT and this is something that you will be able

00:20:43.840 --> 00:20:49.680
to like get all the time so PEFT now what is the meaning of

00:20:49.680 --> 00:20:52.880
this PEFT by the way? So the meaning of PEFT or full form of

00:20:52.880 --> 00:20:57.610
PEFT is parameterization. So this is a parameter efficient

00:21:03.460 --> 00:21:08.720
fine tuning

00:21:10.100 --> 00:21:13.220
okay inside the fine tuning. So one approach is I can go

00:21:13.220 --> 00:21:15.120
ahead and change the entire weight or tune the entire

00:21:15.120 --> 00:21:19.680
weight. The second is PEFT approach says that that parameter

00:21:19.680 --> 00:21:22.880
efficient fine tuning now what is the meaning of this

00:21:22.880 --> 00:21:25.920
parameter efficient fine tuning by the way yeah. So this is

00:21:25.920 --> 00:21:29.700
just one of the term this is one of the approach PEFT is one

00:21:29.700 --> 00:21:34.080
of the approach by the way. Okay now this is one of the

00:21:34.080 --> 00:21:37.500
umbrella you can say now under this umbrella under this

00:21:37.500 --> 00:21:40.480
umbrella under this PEFT approach that people have derived

00:21:40.480 --> 00:21:45.140
so there is something called as capital L a small o r a

00:21:45.140 --> 00:21:49.800
comes into a picture capital Q again L o r a come into a

00:21:49.800 --> 00:21:53.120
picture and you must be able to heard about this LoRa and Q

00:21:53.120 --> 00:21:56.920
LoRa again and again and again and again right and out of

00:21:56.920 --> 00:21:58.840
curiosity people keep on asking question that can you please

00:21:58.840 --> 00:22:02.480
explain me LoRa and Q LoRa. Now after today's class you will

00:22:02.480 --> 00:22:05.700
be able to explain. So under this parameter efficient fine

00:22:05.700 --> 00:22:09.360
tuning so people said that that okay we can try to do a fine

00:22:09.360 --> 00:22:12.420
tuning but instead of doing a fine tuning of whole weight

00:22:12.420 --> 00:22:15.960
which is available inside my model inside my neural network

00:22:15.960 --> 00:22:21.100
what I can do is I can try to choose some parameter right

00:22:21.100 --> 00:22:23.680
some parameter and then I will just try to do a fine tuning

00:22:23.680 --> 00:22:27.420
for that particular parameter not beyond that yeah not

00:22:27.420 --> 00:22:30.080
beyond that basically. So then people try to do a fine

00:22:30.080 --> 00:22:30.100
tuning for that particular parameter not beyond that. So let

00:22:30.100 --> 00:22:32.400
say that okay so if you are going with the parameter

00:22:32.400 --> 00:22:35.040
efficient fine tuning then what kind of a parameter how we

00:22:35.040 --> 00:22:38.300
can derive the parameter basically. So then they said that

00:22:38.300 --> 00:22:41.280
that okay there is something called as LoRa approach or Q

00:22:41.280 --> 00:22:43.980
LoRa approach we can try to follow. So full form of this

00:22:43.980 --> 00:22:52.020
LoRa is nothing but low-rank L o w low-rank a d a p t i o n

00:22:52.020 --> 00:22:57.600
and meaning of this one is quantize. q u a n t i z e.

00:22:58.040 --> 00:23:00.080
quantize. low-rank.

00:23:05.440 --> 00:23:08.140
Now, what is the meaning of this low rank adaption then?

00:23:08.920 --> 00:23:11.500
What is the meaning of this low rank adaption and what is

00:23:11.500 --> 00:23:14.700
the meaning of this quantization and quantized low rank

00:23:14.700 --> 00:23:18.260
adaption? I'll try to explain you that part as well. And

00:23:18.260 --> 00:23:20.420
even after today's class, you will be able to understand

00:23:20.420 --> 00:23:23.260
what is the quantized model. So we say that, that we are

00:23:23.260 --> 00:23:26.500
trying to build a quantized model, which can run even on

00:23:26.500 --> 00:23:30.120
edge devices, a devices which is having a very small

00:23:30.120 --> 00:23:33.320
compute, but it is going to run it with that. So after

00:23:33.320 --> 00:23:35.480
today's class, you will be able to understand even that

00:23:35.480 --> 00:23:41.380
particular part. So here, the meaning of basically like a

00:23:41.380 --> 00:23:44.680
LoRa is, let me explain you with some sort of a mathematical

00:23:44.680 --> 00:23:49.320
intuition, by the way, that what happens with respect to a

00:23:49.320 --> 00:23:55.100
LoRa and how like a LoRa efficiently going to like adapt it,

00:23:55.160 --> 00:24:01.800
adapt it. So here, when we are talking about a low rank

00:24:01.800 --> 00:24:07.100
adaption, right? Low rank adaption. So let's suppose we have

00:24:07.100 --> 00:24:10.280
a model and inside the model, obviously we will be having a

00:24:10.280 --> 00:24:14.560
weight, right? We will be having a weight. So it simply

00:24:14.560 --> 00:24:18.400
means that, that we have a matrixes, for example. So we

00:24:18.400 --> 00:24:24.640
have, let's suppose a 512 cross 512 matrixes, which is

00:24:24.640 --> 00:24:26.480
representing a weight, right? Which is representing

00:24:26.480 --> 00:24:30.520
basically a weight. We have seen that KQV values, right? So

00:24:30.520 --> 00:24:35.360
which is representing our weight. Now as a part of this low

00:24:35.360 --> 00:24:40.240
rank adaption, what we are going to do is that, that we are

00:24:40.240 --> 00:24:44.720
not going to change this weight means we are going to freeze

00:24:44.720 --> 00:24:47.980
the weight. Whatever weight is available here, whatever

00:24:47.980 --> 00:24:50.840
weight is available here in this layer and in this layer,

00:24:51.000 --> 00:24:52.860
I'm going to freeze it. I'm not going to change it at all,

00:24:52.900 --> 00:24:56.640
right? Let's keep it as it is. Don't touch this particular

00:24:56.640 --> 00:25:00.480
weight. So this 500 cross 12 cross 512, let's suppose that's

00:25:00.480 --> 00:25:02.740
a matrixes, which is trying to represent the weight. Don't

00:25:02.740 --> 00:25:07.240
try to change anything for this one. Do one thing, try to

00:25:07.240 --> 00:25:11.140
derive one more weight, W dash and W dash is nothing, but

00:25:11.140 --> 00:25:14.080
let's suppose this is the size of this weight. So W plus

00:25:14.080 --> 00:25:20.420
Delta of W, right? Delta of W. Now this Delta W is

00:25:20.420 --> 00:25:25.640
representing a low rank adaption. How? Yeah. Delta W is

00:25:25.640 --> 00:25:29.920
representing. So we are trying to create a new means what we

00:25:29.920 --> 00:25:32.520
are trying to say that, that this is the neural network,

00:25:32.760 --> 00:25:37.540
right? Try to add one more layer, maybe which with a weight,

00:25:37.680 --> 00:25:40.680
with a new weights, try to add one more layer over here with

00:25:40.680 --> 00:25:44.660
a new weights. This is basically what this is a Delta W I'm

00:25:44.660 --> 00:25:47.740
trying to represent. So add a new layer of the weight in the

00:25:47.740 --> 00:25:50.360
neural network itself. Don't touch the existing one, which

00:25:50.360 --> 00:25:54.020
has already been trained. Yeah. Delta W. Delta W. And here,

00:25:54.200 --> 00:25:58.200
when you're trying to create a Delta W, try to follow this

00:25:58.200 --> 00:26:00.960
approach. What approach? Low rank adaption. What is the

00:26:00.960 --> 00:26:03.760
meaning of low rank adaption then? Right? So for example,

00:26:03.940 --> 00:26:10.240
uh, so here Delta W, Delta W is nothing but A dot B. A dot

00:26:10.240 --> 00:26:13.480
B. Now what is this A by the way? So A is going to represent

00:26:13.480 --> 00:26:18.620
basically, uh, like a dimension of the matrixes with maybe,

00:26:18.740 --> 00:26:23.020
uh, like a 512 class four. And B is going to represent. B is

00:26:23.020 --> 00:26:29.260
going to represent four cross 512, 512. So just try to

00:26:29.260 --> 00:26:33.500
attach this Delta W. Delta W is nothing but this particular

00:26:33.500 --> 00:26:38.900
matrix multiplication. Yeah. This particular matrix

00:26:38.900 --> 00:26:42.780
multiplication. So where A dimension, dimension of A is this

00:26:42.780 --> 00:26:47.520
dimension of B is basically this one. So this Delta W means

00:26:47.520 --> 00:26:52.220
one more layer. Try to attach it over there. And we try to

00:26:52.220 --> 00:26:54.040
take this. Okay. So we are going to use low rank, a small

00:26:54.040 --> 00:26:57.420
number as maybe four, maybe we can try to take it as a eight

00:26:57.420 --> 00:27:01.760
because, uh, so this is, this is something called as Delta W

00:27:01.760 --> 00:27:07.240
is called as low rank approximation for the new layer that

00:27:07.240 --> 00:27:10.100
we are going to create. So is it making sense guys? So when

00:27:10.100 --> 00:27:12.660
we say like a low rank adaption, what is the meaning of it?

00:27:12.960 --> 00:27:16.420
And what is the new weight? New weight is nothing but my old

00:27:16.420 --> 00:27:18.800
weight means the older weight, whatever weight that we have

00:27:18.800 --> 00:27:22.580
plus adding a new layer of the weight at the end of the day.

00:27:28.850 --> 00:27:33.090
Yup. So technically in case of a low rank, right? So what is

00:27:33.090 --> 00:27:35.570
the actual, actual meaning of a low rank? So whenever we say

00:27:35.570 --> 00:27:41.330
low rank, so let's suppose we have a 512 cross 512 matrixes.

00:27:41.390 --> 00:27:44.450
So total number of parameter will be how much two, six, two,

00:27:44.530 --> 00:27:48.750
one 44. If you are going to multiply 512 cross 512. So this

00:27:48.750 --> 00:27:52.770
is the total number of parameter for a full matrix, full

00:27:52.770 --> 00:27:55.910
matrix, right? Full mat means full weights. If there is a

00:27:55.910 --> 00:27:59.010
512 plus 512. Now, what? What we are trying to propose over

00:27:59.010 --> 00:28:04.730
here that, okay, just try to take 512 cross four plus four

00:28:04.730 --> 00:28:09.470
cross 512, 512. Now what is the total number? So this total

00:28:09.470 --> 00:28:14.690
number will become 4096 basically, and this will be low

00:28:14.690 --> 00:28:22.250
rank. So we are trying to add this matrixes to my existing

00:28:22.250 --> 00:28:26.630
one, to my existing one basically. And we are going to tune

00:28:26.630 --> 00:28:32.210
this one. So this, this number is approximately 1.5% of the

00:28:32.210 --> 00:28:35.430
total number that we have. Total number of trainable

00:28:35.430 --> 00:28:39.550
parameter that we originally had in my model 1.5%. So I'm

00:28:39.550 --> 00:28:41.550
not training the a hundred percent, right? I'm just trying

00:28:41.550 --> 00:28:46.130
to create separate. Again, this is not a subset. Many people

00:28:46.130 --> 00:28:48.070
even get confused and many people have asked me this

00:28:48.070 --> 00:28:51.310
question that is the matrixes that we are trying to derive.

00:28:51.450 --> 00:28:56.030
Is it the subset? Delta W is a subset of W. Not at all. And

00:28:56.030 --> 00:28:57.850
again, in an interview. Okay. Many people ask this question.

00:28:58.010 --> 00:29:00.350
It's a very interesting question. So generally people think

00:29:00.350 --> 00:29:03.890
that, that this Delta W is actually a subset of the loop,

00:29:03.910 --> 00:29:07.550
but no Delta W is a complete new matrixes. We are just

00:29:07.550 --> 00:29:10.430
trying to take an inspiration in terms of a dimension, but

00:29:10.430 --> 00:29:12.990
not the value. You're not taking any values out of that,

00:29:13.110 --> 00:29:15.910
right? It's a complete, like a random matrixes that we are

00:29:15.910 --> 00:29:19.570
going to take. And then we are going to tune it based on our

00:29:19.570 --> 00:29:24.510
data set. The amazing part is that we are only having 1.5%

00:29:24.510 --> 00:29:27.770
of the trainable parameter as compared to this one, as per

00:29:27.770 --> 00:29:30.590
this calculation, as my model will change. This is going to

00:29:30.590 --> 00:29:35.850
basically change so that my model can be trained

00:29:35.850 --> 00:29:38.890
efficiently. It is going to take a low memory and it will be

00:29:38.890 --> 00:29:41.870
able to do a better generalization. So this is basically

00:29:41.870 --> 00:29:44.770
called as a low rank guys, by the way, this is how you can

00:29:44.770 --> 00:29:48.870
try to represent a LORL. Now so let's talk about a

00:29:48.870 --> 00:29:51.610
quantization. So what is the meaning of a quantization in

00:29:51.610 --> 00:29:57.070
general? Right? So whenever. We try to say. Okay. That we

00:29:57.070 --> 00:29:59.850
have a weight, right? We have a weight inside a neural

00:29:59.850 --> 00:30:02.730
network, right? Whenever we say that we have a weight inside

00:30:02.730 --> 00:30:07.590
a neural network. So here, uh, I'm saying that that weight

00:30:07.590 --> 00:30:13.170
is 2.3, 2, 3, 3, yeah, 2.33. Now this weight is 3.48. This

00:30:13.170 --> 00:30:16.950
weight is minus 5.68. So this numbers, these numbers are

00:30:16.950 --> 00:30:20.130
going to represent my, uh, like, uh, weight by the way.

00:30:20.190 --> 00:30:25.550
Yeah. Wait, by the way. So by default, we are using this

00:30:25.550 --> 00:30:28.710
number over here. Now, this is basically, uh, like a, a

00:30:28.710 --> 00:30:30.750
fractional number I'm trying to use, or like a real number

00:30:30.750 --> 00:30:34.650
I'm trying to use in terms of computer, because at the end

00:30:34.650 --> 00:30:37.370
of the day, computer is storing this number, right? And how

00:30:37.370 --> 00:30:41.230
computer store this numbers in one zero in a bits, computer

00:30:41.230 --> 00:30:44.210
is going to store the number, right? In a bits, computer is

00:30:44.210 --> 00:30:46.930
going to store the number. Computer doesn't understand this

00:30:46.930 --> 00:30:50.770
one. I think we all are aware about it, right? Computer

00:30:50.770 --> 00:30:52.750
doesn't understand this one. Computer doesn't understand

00:30:52.750 --> 00:30:57.790
like a decimal, right? Computer. Computer only understands a

00:30:57.790 --> 00:31:01.590
binary. It never understand octa. It never understand hex.

00:31:01.730 --> 00:31:05.230
It never understands a decimal, right? It always understands

00:31:05.230 --> 00:31:10.150
what? Only zero and one binary, right? So to store these

00:31:10.150 --> 00:31:16.210
numbers, we are occupying a 32 bit of the space, FP 32, 32

00:31:16.210 --> 00:31:21.550
bit of the space. And we are using to store this numbers.

00:31:22.010 --> 00:31:24.730
Yeah. These numbers, these weights. Yeah. So all these

00:31:24.730 --> 00:31:28.730
weights are like a 32 bit, 32 bit, right? 32 bit of

00:31:28.730 --> 00:31:31.370
precision. So we're like a one zero, one zero, one zero.

00:31:31.530 --> 00:31:34.650
People said that, that, okay, by default, we are using this

00:31:34.650 --> 00:31:41.410
32 bit to represent this number. So for example, 5.6825889,

00:31:41.530 --> 00:31:43.970
something like this, right? This long numbers, 32 bit, we

00:31:43.970 --> 00:31:47.790
are trying to use to store this particular number. Now, if

00:31:47.790 --> 00:31:52.110
you are going to multiply anything, 32 bit, 32 bit, it's a

00:31:52.110 --> 00:31:54.910
huge calculation because at the end of the day, when

00:31:54.910 --> 00:31:58.190
multiplication happens, it happens in a binary. We as a

00:31:58.190 --> 00:32:00.330
human being, we try to use a decimal right for a reference,

00:32:00.410 --> 00:32:03.110
for easy references, but actual calculation on a computer

00:32:03.110 --> 00:32:05.730
label happens in binary. It never understand decimal by the

00:32:05.730 --> 00:32:08.330
way, right? Everything is binary, right? Everything is zero

00:32:08.330 --> 00:32:11.950
one in terms of computer. So 32 bit we are using, and then

00:32:11.950 --> 00:32:14.390
we are representing zero one, zero one, zero one, one, one,

00:32:14.490 --> 00:32:17.670
zero, zero, zero with to represent this number inside a

00:32:17.670 --> 00:32:20.410
memory, right? 32 bit of memory. It is trying to occupy.

00:32:20.790 --> 00:32:23.770
People said that, that, okay. So can we do one thing over

00:32:23.770 --> 00:32:27.830
here? That we can reduce the number of bits, right? Reduce

00:32:27.830 --> 00:32:30.610
the number of bits. Maybe we can try to chop off some of the

00:32:30.610 --> 00:32:33.910
data and that is something called as what quantization. So

00:32:33.910 --> 00:32:37.850
people said that, that what if, if we can try to take a

00:32:37.850 --> 00:32:41.910
small set of fixed value, right? Take a small set of fixed

00:32:41.910 --> 00:32:46.230
value. And then that is going to represent, for example,

00:32:46.310 --> 00:32:49.150
I'll just give you one example, very amazing example to

00:32:49.150 --> 00:32:52.390
explain to quantization. So let's suppose my original

00:32:52.390 --> 00:33:01.080
weight. Original weight, right? Which is been represented by

00:33:01.080 --> 00:33:09.660
using a 32 bit was let's suppose this one, uh, 0.98 yeah. So

00:33:09.660 --> 00:33:17.720
0.98, I'm just giving you a sample 1.23, 1.23, uh, 0.41, and

00:33:17.720 --> 00:33:22.600
then 2.67, right? This is my weight. Now 32 bit

00:33:22.600 --> 00:33:26.120
representation. Okay. So every number, every number is using

00:33:26.120 --> 00:33:29.480
32 bit of a space, right? So 32 combination of 0 and 1, 0

00:33:29.480 --> 00:33:34.780
and 1, 0 and 1, it is trying to take now. So what if, if we

00:33:34.780 --> 00:33:37.940
can try to represent this number in a quantized way, right?

00:33:41.820 --> 00:33:46.700
Quantized way, right? Quantized to maybe four bit or maybe

00:33:46.700 --> 00:33:49.800
to eight bit. So let's, let's do it in a four bit. So maybe

00:33:49.800 --> 00:33:56.180
0.98, I can try to represent by using 1, 1, 1, 0. Yeah. I

00:33:56.180 --> 00:33:59.560
can try to represent why and I'll tell you that as well, 0,

00:33:59.640 --> 00:34:04.500
0, 1, 0 to represent this one 1, 0, 0, 1. And then for this

00:34:04.500 --> 00:34:07.880
1, 1, 1, 1, I can try to use now, what does the meaning of

00:34:07.880 --> 00:34:11.860
by the way, 1, 1, 0, triple 1, 0. The meaning of this one is

00:34:11.860 --> 00:34:17.660
basically 1.0. What is the meaning of this? It's minus 1.2.

00:34:17.740 --> 00:34:21.720
What is the meaning of this? It's minus 0.4. What is the

00:34:21.720 --> 00:34:27.240
meaning of what? Triple one, 2.6. Okay. Okay. Now just tell

00:34:27.240 --> 00:34:29.900
me one thing, right? After quantization. So this is

00:34:29.900 --> 00:34:32.420
basically after like a approximation,

00:34:36.530 --> 00:34:40.090
approximation D quantization.

00:34:42.820 --> 00:34:46.360
So meaning of quantization is that just try to use a lesser

00:34:46.360 --> 00:34:49.240
bit. So for example, I have assumed that I'll try to use

00:34:49.240 --> 00:34:52.940
four bit instead of 32 bit to represent this number. Right.

00:34:53.040 --> 00:35:01.840
And can I say that 0.98 is close to one? Can I say 0.12? 0.1

00:35:01.840 --> 00:35:05.640
.2. Okay. 0.1.2. Is close to 0.1.2. Three. Can I say 0.4?

00:35:05.700 --> 00:35:13.340
One is close to 0.4. Can I say 0.267 is a close to 0.2 0.67

00:35:13.340 --> 00:35:19.520
is closer to 2.6. Can I say that guys, everyone, can I say

00:35:19.520 --> 00:35:24.000
that, that original, the 32 bit 32 bit that I'm talking

00:35:24.000 --> 00:35:26.760
about, this was the original one, right? And then I have

00:35:26.760 --> 00:35:30.080
quantized it means I have compressed it in a four bit by

00:35:30.080 --> 00:35:32.980
using a reference. And then I'm just trying to like a de

00:35:32.980 --> 00:35:35.540
-quantize it. And this is representing this, this is

00:35:35.540 --> 00:35:37.760
representing this four bit, right? This four bit I'm using

00:35:37.760 --> 00:35:40.660
to represent this one. Can I say that this, and this one is

00:35:40.660 --> 00:35:44.180
close means after quantization, after converting 32 bit into

00:35:44.180 --> 00:35:47.320
a four bit, can I say that it's close? It's not same, right?

00:35:47.420 --> 00:35:50.500
It's not same, but it's close. So can I say that, can I make

00:35:50.500 --> 00:35:54.340
a statement over here that I'm not losing much of

00:35:54.340 --> 00:35:58.200
information, much of relation over here? Can I say that I'm

00:35:58.200 --> 00:36:00.600
not losing much? So even though let's suppose, you know, I'm

00:36:00.600 --> 00:36:02.520
not losing much. Instead of representing my weight by this

00:36:02.520 --> 00:36:04.900
number, I'm using this number, this number, this number,

00:36:04.920 --> 00:36:08.320
this number. So the meaning over here is that I'm not losing

00:36:08.320 --> 00:36:10.640
much of information. Can I say that?

00:36:14.060 --> 00:36:17.140
Yes. Can I say that, that I'm not losing much of information

00:36:17.140 --> 00:36:24.180
over here? Yep. Weight is same, right? Almost same. The

00:36:24.180 --> 00:36:26.760
weight that I've written with 32 bit, it's actually same,

00:36:26.900 --> 00:36:32.020
right? With approximate quantization as well. So weight is

00:36:32.020 --> 00:36:37.320
almost same. But what is the advantage? Yes, guys. What is

00:36:37.320 --> 00:36:40.500
the advantage? Weight is almost same, right? I'm not losing

00:36:40.500 --> 00:36:43.100
much of information. I'm not losing much of relation, but

00:36:43.100 --> 00:36:45.040
what is the advantage that I'm able to achieve over here?

00:36:46.080 --> 00:36:47.640
Yep. What is the advantage guys?

00:37:04.120 --> 00:37:07.640
Memory saving. That's the biggest advantage, right? Which is

00:37:07.640 --> 00:37:12.040
required to run any model on a edge device. So generally you

00:37:12.040 --> 00:37:15.800
will see that everyone who works in edge devices, they will

00:37:15.800 --> 00:37:17.900
be talking about a quantized model. Now this is the meaning

00:37:17.900 --> 00:37:20.680
of quantization. 32 bit representation. This is the meaning

00:37:20.680 --> 00:37:20.860
of quantization. Can you imagine? So we are saying we are

00:37:20.860 --> 00:37:20.880
going to take a condition, right? You can take a calculation

00:37:20.880 --> 00:37:21.580
and calculate the value of that calculation into 4-bit or

00:37:21.580 --> 00:37:27.000
maybe into 8-bit, right? So 8 times, just imagine 8 times

00:37:27.000 --> 00:37:32.300
memory, I'm able to save and compute as well. Not just

00:37:32.300 --> 00:37:36.800
memory. Not just storage. Compute. Right? So previously I

00:37:36.800 --> 00:37:40.600
was doing 32 x 32 kind of a calculation. Now, it's 4 x 4. 4

00:37:40.600 --> 00:37:44.540
x 4. 4 bit x 4 bit. Right. So we are not just saving our

00:37:44.540 --> 00:37:48.740
memory. Yes. Yes, 8 times memory we are able to save. So if

00:37:48.740 --> 00:37:56.020
model size is like 80 MB, now it just become 8 MB. If model

00:37:56.020 --> 00:38:00.920
size was 80 MB, now it just become 8 MB. There is a huge

00:38:00.920 --> 00:38:04.840
difference between 80 and 8 MB. There's a huge differences.

00:38:05.100 --> 00:38:07.920
So that 80 MB model, maybe I'll not be able to run in my

00:38:07.920 --> 00:38:10.980
mobile device, but 8 MB model, yes, happily I will be able

00:38:10.980 --> 00:38:13.840
to run in my mobile devices and that too without losing much

00:38:13.840 --> 00:38:18.460
of information. Yeah, without losing much of information. So

00:38:18.460 --> 00:38:21.800
that is a meaning of quantization and quantized model, we

00:38:21.800 --> 00:38:25.700
use it for what? So for all the edge devices, for all the

00:38:25.700 --> 00:38:28.280
light weighted devices, because of this reason, this is a

00:38:28.280 --> 00:38:31.420
very simple calculation, very simple intuition, right? Just

00:38:31.420 --> 00:38:35.060
because of this intuition, we try to use it so that compute

00:38:35.060 --> 00:38:40.220
will be less plus memory will be less simple. So here,

00:38:40.300 --> 00:38:43.960
right? So here there is a term called as quantization. This

00:38:43.960 --> 00:38:48.080
is QLORA, right? So low rank adoption, low rank adoption is

00:38:48.080 --> 00:38:49.940
one of the approach. Now what is the meaning of low rank

00:38:49.940 --> 00:38:52.580
adoption basically? So low rank adoption means I'll try to

00:38:52.580 --> 00:38:55.620
add one layer, right? I'll try to add one more layer, one

00:38:55.620 --> 00:38:59.340
layer, but with a small, like a matrixes, I'll try to add

00:38:59.340 --> 00:39:01.120
it, right? That is something called as low rank adoption.

00:39:01.340 --> 00:39:05.180
That low value of matrixes, I'll try to add and I'll try to

00:39:05.180 --> 00:39:08.460
maybe like do the fine tuning, right? Now, what is the

00:39:08.460 --> 00:39:12.100
meaning of this quantized low rank adoption? So quantized

00:39:12.100 --> 00:39:15.140
low rank adoption means? It will be low rank, obviously,

00:39:15.180 --> 00:39:19.020
which is coming from here itself, right? But it will be

00:39:19.020 --> 00:39:23.320
quantized as well means whatever weight, because when we are

00:39:23.320 --> 00:39:25.660
talking about this low rank, when we are talking about even

00:39:25.660 --> 00:39:28.500
these main number of parameter, these main number of

00:39:28.500 --> 00:39:31.800
parameter, right? So in case of low rank, it will be, let's

00:39:31.800 --> 00:39:36.120
suppose 32 bit, right? Fp is equal to 32 bit, right? In case

00:39:36.120 --> 00:39:40.020
of QLORA, it

00:39:42.260 --> 00:39:46.220
will be 4 bit. So it will be 32 bit. So can I say that

00:39:46.220 --> 00:39:50.460
QLORA, quantized LORA will be even way more efficient than

00:39:50.460 --> 00:39:53.740
LORA? LORA was efficient, right? So instead of like a

00:39:53.740 --> 00:39:58.760
training, the entire, like a 2,062,144 parameter as per

00:39:58.760 --> 00:40:01.680
this, this calculation, right? Instead of training this many

00:40:01.680 --> 00:40:04.860
like numbers, we are just training 1.5% this much. So LORA

00:40:04.860 --> 00:40:08.220
was very much efficient, LORA was very much efficient,

00:40:08.380 --> 00:40:12.000
right? But even we are trying to make it more efficient by

00:40:12.000 --> 00:40:16.280
using what? By using quantized LORA. So where instead of

00:40:16.280 --> 00:40:20.040
using a 32 bit representation, we can try to use 4 bit or

00:40:20.040 --> 00:40:22.420
maybe we can try to use a 8 bit representation.

00:40:25.820 --> 00:40:28.800
Making sense to all of us guys? What is the difference

00:40:28.800 --> 00:40:32.120
between LORA and QLORA? And both of this comes under what?

00:40:32.280 --> 00:40:36.800
Comes under this term called as parameter efficient fine

00:40:36.800 --> 00:40:40.440
tuning. So now I believe if anyone is going to ask you that

00:40:40.440 --> 00:40:43.240
what is the meaning of parameter efficient fine tuning, you

00:40:43.240 --> 00:40:46.080
will be able to explain with that by giving example of LORA

00:40:46.080 --> 00:40:48.720
and QLORA. If someone is going to ask you like quantization,

00:40:48.960 --> 00:40:50.920
you will be able to explain. If someone is going to ask you

00:40:50.920 --> 00:40:53.220
about the delta W, you will be able to explain, I believe.

00:40:55.180 --> 00:40:58.660
Yes. Is it clear in your head guys? Is it clear?

00:41:06.640 --> 00:41:10.540
Yes. Then I hope the meaning of fine tuning is also clear to

00:41:10.540 --> 00:41:10.900
all of you.

00:41:18.520 --> 00:41:22.820
Yes. Absolutely. No confusion at all. Or do you have any

00:41:22.820 --> 00:41:24.480
confusion? If you have any confusion, please go ahead and

00:41:24.480 --> 00:41:25.760
ask me a question, I'll answer.

00:41:37.080 --> 00:41:39.440
So I believe after today's class, you will be able to

00:41:39.440 --> 00:41:41.820
explain just like a story to anyone that what is the fine

00:41:41.820 --> 00:41:44.700
tuning? And inside that, what is LORA? What is QLORA? Right?

00:41:45.080 --> 00:41:49.760
Okay. Now, so this is a theoretical understanding and I

00:41:49.760 --> 00:41:51.500
believe theoretical understanding was the only thing which

00:41:51.500 --> 00:41:54.180
was required. Now let's go ahead and do a back to back

00:41:54.180 --> 00:41:57.320
practical. So fine tuning in my local, fine tuning in

00:41:57.320 --> 00:41:59.480
OpenAI, fine tuning on Hugging Face, fine tuning everywhere.

00:42:02.690 --> 00:42:05.990
So from next week, there is a new gen AI batch coming up.

00:42:06.110 --> 00:42:08.950
That is basically a hybrid. That is a hybrid batch that I've

00:42:08.950 --> 00:42:12.230
launched. So not a live classes. I'm not going to take a

00:42:12.230 --> 00:42:15.090
live classes like for some time. Okay. So I have decided

00:42:15.090 --> 00:42:20.470
that I'll just try to take some like a live interaction with

00:42:20.470 --> 00:42:25.270
all of you on a regular interval, not as a fixed time, maybe

00:42:25.270 --> 00:42:29.410
like once in a two week or something like that. Those who

00:42:29.410 --> 00:42:33.010
are the part of hybrid batches so that, and again, I'm not

00:42:33.010 --> 00:42:35.730
going to call it in this kind of a setup. So I'm going to

00:42:35.730 --> 00:42:39.070
give you a zoom link and people can join so that it will be

00:42:39.070 --> 00:42:41.530
like a two way conversation so that even you can share your

00:42:41.530 --> 00:42:46.050
screen and you can unmute yourself. You can talk to me and I

00:42:46.050 --> 00:42:49.490
will be able to answer in a live session. But yeah, there is

00:42:49.490 --> 00:42:52.010
no fixed session I'm going to keep for that one. It's going

00:42:52.010 --> 00:42:55.150
to be like a on demand kind of a session that I'm going to

00:42:55.150 --> 00:42:57.650
keep for my hybrid batches. This is the meaning of hybrid,

00:42:57.750 --> 00:43:02.670
right? Hybrid means like a combination of like, like

00:43:02.670 --> 00:43:06.570
recorded plus conversation.

00:43:09.530 --> 00:43:12.630
Laura will bring down the accuracy, right? Given we are

00:43:12.630 --> 00:43:15.870
training a few bait and biases. No. Laura will not bring

00:43:15.870 --> 00:43:19.970
down the accuracy at all because the thing is we are not

00:43:19.970 --> 00:43:25.110
changing the actual bait. We are freezing that weight. So

00:43:25.110 --> 00:43:28.090
let's suppose if my model is been trained on some of the

00:43:28.090 --> 00:43:30.690
knowledge, it will be able to retain that. We are not

00:43:30.690 --> 00:43:32.990
changing that one. We are just adding one more layer. That's

00:43:32.990 --> 00:43:36.930
it. Yes. To update it with the new knowledge.

00:43:46.100 --> 00:43:51.320
So Laura is basically designed for a, like a training of a

00:43:51.320 --> 00:43:54.200
model, fine tuning of the model with the new data set

00:43:54.200 --> 00:44:00.040
without disturbing the old weight. Otherwise you can go

00:44:00.040 --> 00:44:01.900
ahead with the full layer, fine tuning, full layer, fine

00:44:01.900 --> 00:44:04.180
tuning means you are changing all the baits means there is a

00:44:04.180 --> 00:44:07.520
chances that you will end up disturbing some of the previous

00:44:07.520 --> 00:44:10.840
knowledge as well. If you're going with the full, like a

00:44:10.840 --> 00:44:16.280
weight training for age devices, Kula should be used, but

00:44:16.280 --> 00:44:20.620
should we also use cooler as a normal practice? I have

00:44:20.620 --> 00:44:24.500
already given you the numbers over here. So there is a

00:44:24.500 --> 00:44:28.600
changes between the number. In actual, it was 0.98. Now it

00:44:28.600 --> 00:44:32.920
became one in actual, it was 1.23. Now it became 1.2 in

00:44:32.920 --> 00:44:36.300
actual, it was 0.41. Now it became four one. So we are

00:44:36.300 --> 00:44:39.980
actually changing it, right? So if you are looking for a

00:44:39.980 --> 00:44:44.440
less hallucination, if you're looking for a better

00:44:44.440 --> 00:44:47.480
generation, then you should go ahead with which one you

00:44:47.480 --> 00:44:50.700
should go ahead with the original one, not a quantized one.

00:44:51.680 --> 00:44:54.960
Making sense. Yeah. So it's not like a everywhere just to

00:44:54.960 --> 00:44:58.100
save a memory. So then no one is stopping you. See no one is

00:44:58.100 --> 00:45:00.640
stopping you to, you know, and no one is even forcing you to

00:45:00.640 --> 00:45:04.000
use all the time like the original one and don't use the

00:45:04.000 --> 00:45:06.560
quantized one. You can use anywhere you want. It's your

00:45:06.560 --> 00:45:09.760
choice, but unless and until it is going to serve the

00:45:09.760 --> 00:45:13.460
purpose, there is a trade off. You will be able to find out

00:45:13.460 --> 00:45:17.060
in original one and even in a quantized one. So if it is

00:45:17.060 --> 00:45:19.820
going to fulfill your purpose, go and use it, no one is

00:45:19.820 --> 00:45:22.040
going to stop, but there will be a pros and cons.

00:45:25.690 --> 00:45:29.850
So was the question from whom asked? The question from

00:45:29.850 --> 00:45:33.050
Sanjeev was I think, yeah, Sanjeev, I think I have already

00:45:33.050 --> 00:45:38.610
given your answer. Then, then that Rakesh is saying, does

00:45:38.610 --> 00:45:42.490
LoRa always result a smaller size model?

00:45:46.740 --> 00:45:50.400
Guys, anyone who can answer? So question is, does LoRa

00:45:50.400 --> 00:45:54.800
always give us smaller size model. So if I'm going to apply

00:45:54.800 --> 00:45:59.320
LoRa, will I be able to get a smaller size model? size model

00:45:59.320 --> 00:46:04.120
or same size model or little bit bigger size model? Yes,

00:46:04.120 --> 00:46:06.460
this is the question basically. I think it's an interesting

00:46:06.460 --> 00:46:10.920
one. So Ramesh has asked this question basically. So what is

00:46:10.920 --> 00:46:13.480
your opinion guys? Again I'm going to repeat the question. I

00:46:13.480 --> 00:46:16.300
think you can see the question in your chat Ramesh, asked by

00:46:16.300 --> 00:46:23.020
Ramesh, right? What is the answer? So Ramesh is trying to

00:46:23.020 --> 00:46:26.840
say that if I'm applying LoRa, will I be able to get a less

00:46:26.840 --> 00:46:31.820
size model or like a bigger one or maybe like a same size

00:46:31.820 --> 00:46:36.140
model? Yes. I think everyone is able to understand, everyone

00:46:36.140 --> 00:46:39.720
is saying little bit bigger. See when we are trying to see

00:46:39.720 --> 00:46:44.320
LoRa is a technique, right? Technique for what? Fine tuning.

00:46:44.520 --> 00:46:48.140
Fine tuning means what? Means trying to give a new

00:46:48.140 --> 00:46:51.500
knowledge, new knowledge to my model. Now as a part of LoRa,

00:46:51.620 --> 00:46:54.760
what we are doing? So I have said that, that I'm trying to

00:46:54.760 --> 00:46:57.100
retain the previous weight, right? And then I'm adding. See,

00:46:57.220 --> 00:46:59.540
I have already added a couple of like a small, small

00:46:59.540 --> 00:47:02.860
circles, right? So I'm trying to retain the actual weights.

00:47:02.980 --> 00:47:06.540
Means I'm not changing anything means model size has not, if

00:47:06.540 --> 00:47:09.500
I have not changed the weight, so model size is same, right?

00:47:09.580 --> 00:47:13.340
Model size is same. I'm just trying to add additional

00:47:13.340 --> 00:47:16.860
weights. So model size will increase a little bit. It is not

00:47:16.860 --> 00:47:20.020
going to decrease in case of LoRa. So LoRa is just a

00:47:20.020 --> 00:47:26.040
technique, right? Now if you are going to quantize. If you

00:47:26.040 --> 00:47:29.440
can use a Q LoRa, right? So I said, okay, again, one

00:47:29.440 --> 00:47:33.840
question. So can I say that Q LoRa, right? Can I say that Q

00:47:33.840 --> 00:47:37.420
LoRa is going to reduce a weight or sorry, reduce the size

00:47:37.420 --> 00:47:41.420
of the model or like keep a same size or increase the size?

00:47:41.600 --> 00:47:42.280
What did you answer guys?

00:47:46.060 --> 00:47:48.440
Yeah. So what, what is your opinion about Q LoRa?

00:47:51.330 --> 00:47:53.910
I think all of us, all of us are able to understand in a

00:47:53.910 --> 00:47:56.190
chat. I can see that I'm really very happy about it. That

00:47:56.190 --> 00:48:01.770
all of us are very, very much clear. Okay. So what is, what

00:48:01.770 --> 00:48:05.510
is like a, what will, what will happen with the Q LoRa? So

00:48:05.510 --> 00:48:10.430
people are saying it will reduce, okay, okay, okay. Reduce

00:48:10.430 --> 00:48:16.600
the size Q LoRa, reduce the size. Think again guys, think

00:48:16.600 --> 00:48:18.560
again, think again, think

00:48:20.770 --> 00:48:26.350
about it. Yep. When you're answering this question, right?

00:48:26.410 --> 00:48:28.830
What will happen with the Q LoRa? So is this going to reduce

00:48:28.830 --> 00:48:31.830
or keep it same or it will increase?

00:48:35.960 --> 00:48:39.120
Tell me one thing. Many people are trying to say that in

00:48:39.120 --> 00:48:41.940
case of LoRa, everyone was right, right? Everyone was right.

00:48:42.080 --> 00:48:43.580
They said that it will be a little bit bigger. That's

00:48:43.580 --> 00:48:49.820
correct. Now with Q LoRa, tell me one thing. What is Q LoRa?

00:48:51.040 --> 00:48:56.180
Can I say it's a Delta W coming from Delta W, right? Have I,

00:48:56.200 --> 00:49:01.640
am I changing a W when I say Q LoRa? So see Q LoRa is an

00:49:01.640 --> 00:49:06.060
approach at the time of fine tuning. And I have also

00:49:06.060 --> 00:49:11.020
explained you. The concept of quantization. I'm not saying

00:49:11.020 --> 00:49:16.660
that I'm doing a Q LoRa, I'm quantizing all the model, like

00:49:16.660 --> 00:49:20.720
all the weights. No. Yes, I can go ahead. I can quantize the

00:49:20.720 --> 00:49:25.460
entire model, right? I can quantize the entire model. Then I

00:49:25.460 --> 00:49:27.660
will say that, okay, fine. This is the final quantized model

00:49:27.660 --> 00:49:33.040
making sense, everyone. So when I quantization is a concept

00:49:33.040 --> 00:49:36.420
quantization, I can try to use on the entire weight, or, or

00:49:36.420 --> 00:49:41.720
I can try to use on a partial weight. Depends upon me. Yes.

00:49:42.100 --> 00:49:45.720
Depends upon me. So when I'm saying Q LoRa, it simply means

00:49:45.720 --> 00:49:48.440
that it's a fine tuning, right? I'm not changing the

00:49:48.440 --> 00:49:52.100
previous weight that, that is frozen basically on a, like

00:49:52.100 --> 00:49:55.100
that we are trying to add a new layer of weight, but that

00:49:55.100 --> 00:49:58.880
weight is a basically quantized one. So again, it will be a

00:49:58.880 --> 00:50:02.540
little bit bigger unless and until I'm not going to quantize

00:50:02.540 --> 00:50:05.820
the whole model. If I'm going to quantize the whole model.

00:50:05.820 --> 00:50:10.040
Then I said that, okay, model size will reduce by eight

00:50:10.040 --> 00:50:14.020
times. If from 32 bit, we are converting it to four bit or

00:50:14.020 --> 00:50:17.020
from eight bit, 32 bit, we are converting it to eight bit,

00:50:17.140 --> 00:50:24.700
right, lower bits. But in Q LoRa, only that layer, which is

00:50:24.700 --> 00:50:27.960
responsible for adding a new knowledge, right? We are trying

00:50:27.960 --> 00:50:29.220
to use it in a quantized way.

00:50:32.640 --> 00:50:33.900
Are you able to understand this?

00:50:42.820 --> 00:50:46.280
We had a weight. I'm not changing it. Even in case of a Q

00:50:46.280 --> 00:50:48.260
LoRa. What I'm trying to say is that, that whenever I'm

00:50:48.260 --> 00:50:52.020
trying to use a low rank, right? Low rank, basically. So at

00:50:52.020 --> 00:50:54.920
this point of a time, the weight, because low rank means

00:50:54.920 --> 00:50:57.920
again, it's a weight, but a smaller size, right? So the

00:50:57.920 --> 00:51:00.360
weight that you're trying to take, take it in a lower bit.

00:51:00.820 --> 00:51:04.360
So that is, will be called as a Q LoRa. This has not

00:51:04.360 --> 00:51:08.820
changed. If I'm saying that quantize the whole model means

00:51:08.820 --> 00:51:12.720
quantize this weight plus this weight as well. Then I'll say

00:51:12.720 --> 00:51:15.160
it's a absolute quantized model. But again, that's a

00:51:15.160 --> 00:51:17.320
quantization. That, that concept will be called as a

00:51:17.320 --> 00:51:21.180
quantization of the model. But here I'm talking about Q LoRa

00:51:21.180 --> 00:51:23.480
means fine tuning layer only.

00:51:28.450 --> 00:51:30.990
Ramesh is saying, would we be getting the link of the zoom?

00:51:31.190 --> 00:51:33.890
Yeah. So like I said, it is not going to be the scheduled

00:51:33.890 --> 00:51:37.330
one. It will be like a random one. I'll just ping in maybe

00:51:37.330 --> 00:51:42.230
once in a month or most probably maybe like twice in a week

00:51:42.230 --> 00:51:46.450
so that we can connect and you guys can like talk directly

00:51:46.450 --> 00:51:49.090
and then if you have any kind of a confusion in anything.

00:51:49.090 --> 00:51:52.470
You can go ahead and ask. Otherwise anyhow on a platform

00:51:52.470 --> 00:51:54.810
itself, I'm trying to make sure that everything should be

00:51:54.810 --> 00:51:59.130
clear. But yeah, so if someone has to discuss something, but

00:52:00.920 --> 00:52:03.540
with respect to LoRa, Q LoRa will be smaller. That layer

00:52:03.540 --> 00:52:08.000
will be smaller. That layer will be a smaller and yeah, with

00:52:08.000 --> 00:52:12.900
respect to a LoRa fine tuned model, Q LoRa fine tuned model

00:52:12.900 --> 00:52:16.560
will be lesser. But with respect to original model, it will

00:52:16.560 --> 00:52:19.820
be a little bit bigger. Hope this analogy is pretty much

00:52:19.820 --> 00:52:20.860
clear. Yeah.

00:52:29.460 --> 00:52:33.480
Okay, now let's move ahead and let's start talking about

00:52:33.480 --> 00:52:39.200
talking about basically a practical one. Yes, practical one.

00:52:39.320 --> 00:52:44.000
So I have already prepared this entire like a demo and this

00:52:44.000 --> 00:52:49.040
takes almost half an hour of time to prepare this final

00:52:49.040 --> 00:52:55.200
output the like a final output of this entire fine tuning.

00:52:55.420 --> 00:52:58.940
So I'm going to explain you each and everything that what we

00:52:58.940 --> 00:53:03.620
are trying to do. Over here. Yeah. Do we have more kind of

00:53:03.620 --> 00:53:06.600
these hybrid classes with the two ways interaction? No in

00:53:06.600 --> 00:53:09.980
hybrid classes, we have just one way interaction. So like we

00:53:09.980 --> 00:53:13.000
are going to upload the video, but yeah, we will try to host

00:53:13.000 --> 00:53:15.600
some of the sessions. So where I will come and I'll try to

00:53:15.600 --> 00:53:16.540
discuss with all of you.

00:53:22.330 --> 00:53:25.410
Are we moving to a hybrid model for all the courses? Yeah,

00:53:25.470 --> 00:53:28.390
we are moving to hybrid model to all the courses. The reason

00:53:28.390 --> 00:53:33.090
is very simple. I'm going to take all the class means I have

00:53:33.090 --> 00:53:35.790
a, I have a, I have already created. I plan for me where I'm

00:53:35.790 --> 00:53:40.810
going to record all the tech, uh, every, all the tech, uh,

00:53:40.870 --> 00:53:44.610
plus interview series for all the technology, uh, plus a

00:53:44.610 --> 00:53:48.910
project, a hundreds of projects that I have. So this is what

00:53:48.910 --> 00:53:51.790
I'm trying to do. So with the help, uh, and again, so when

00:53:51.790 --> 00:53:54.770
I'm taking live classes, it's, it's very difficult for me to

00:53:54.770 --> 00:53:58.870
get a time, uh, to do a recording basically because my

00:53:58.870 --> 00:54:01.910
Saturday Sunday completely goes for a live classes and then,

00:54:01.950 --> 00:54:06.530
uh, Monday to Friday. So I just have a five days of time. So

00:54:06.530 --> 00:54:08.790
keeping that in a mind. So I've decided that I will be

00:54:08.790 --> 00:54:13.850
launching just a hybrid classes till the time I'm not going

00:54:13.850 --> 00:54:16.250
to complete everything. Everything means all the technology

00:54:16.250 --> 00:54:21.430
in Hindi and in English, plus all the interview series, like

00:54:21.430 --> 00:54:23.390
a machine learning interview series, RIG interview series,

00:54:23.550 --> 00:54:25.430
NTIA interview series, generative AI interview series,

00:54:25.590 --> 00:54:27.530
separate, separate review series, a deep learning interview

00:54:27.530 --> 00:54:31.550
series, plus at least hundreds of project already 60, 70

00:54:31.550 --> 00:54:33.550
projects that are available, but yeah. So more hundreds of

00:54:33.550 --> 00:54:36.810
project after that, I will think that, okay, fine. Because

00:54:36.810 --> 00:54:40.070
at the end of the day, uh, we are living in our age of AI,

00:54:40.250 --> 00:54:44.410
right? Uh, for example, just take an example of this class

00:54:44.410 --> 00:54:47.810
or maybe take an example of FSDS. It took six months of

00:54:47.810 --> 00:54:51.230
time. Just imagine six months of time. It took when we have

00:54:51.230 --> 00:54:53.470
not even taken the Python classes, Python class was separate

00:54:53.470 --> 00:54:58.650
to complete that particular batch. Now practically for

00:54:58.650 --> 00:55:01.650
anyone and everyone who would like to get into a data

00:55:01.650 --> 00:55:04.310
science industry, if person is trying to do a preparation

00:55:04.310 --> 00:55:08.890
for a three month, right? I think it's possible to crack,

00:55:09.050 --> 00:55:12.910
right? And it is possible to start building an application

00:55:12.910 --> 00:55:16.010
after one, one and a half month of learning itself. No need

00:55:16.010 --> 00:55:19.970
to go for a learning for a six month, right? So because you

00:55:19.970 --> 00:55:21.910
learn something and then you will start forgetting something

00:55:21.910 --> 00:55:24.950
in the past. So keeping that in the mind, I have decided

00:55:24.950 --> 00:55:28.330
that I'll try to record each and everything so that it will

00:55:28.330 --> 00:55:31.370
be available to all of my students, uh, for today, tomorrow,

00:55:31.430 --> 00:55:35.010
or even after a year. It will be relevant. And in this way,

00:55:35.090 --> 00:55:38.190
I will keep on adding more and more content because now

00:55:38.190 --> 00:55:41.710
things are changing rapidly. So with that pace, I have to

00:55:41.710 --> 00:55:45.390
produce a content and with the same pace, my student is

00:55:45.390 --> 00:55:47.970
supposed to consume it. They're not supposed to go for a

00:55:47.970 --> 00:55:51.410
live classes for six months because we all know guys that on

00:55:51.410 --> 00:55:54.830
day one, day zero, so live classes looks amazing. We always

00:55:54.830 --> 00:55:57.350
look for the live classes, but we all know about the

00:55:57.350 --> 00:56:00.630
consistency, right? How many of us are consistent? I can see

00:56:00.630 --> 00:56:04.410
that in a numbers. Doesn't matter what people are going to

00:56:04.410 --> 00:56:07.650
come and say that I like live classes. No, you don't. Right?

00:56:08.030 --> 00:56:10.530
You're just looking for a convenience. You're looking for

00:56:10.530 --> 00:56:14.050
maybe a skews, right? And whatever is going to give you a

00:56:14.050 --> 00:56:16.030
discipline, whatever is going to give you a fruitful result,

00:56:16.230 --> 00:56:19.730
you will always be all for that. So live class or like a

00:56:19.730 --> 00:56:22.810
recorded was never a part of our discussion. The discussion

00:56:22.810 --> 00:56:26.030
was that content, whether my students are able to get a

00:56:26.030 --> 00:56:29.650
content or not. Uh, the premium one, obviously, uh, the

00:56:29.650 --> 00:56:33.110
updated one, not the two year old or one year old. Recorded

00:56:33.110 --> 00:56:35.690
content. Uh, so that's the reasons I have taken this

00:56:35.690 --> 00:56:38.290
initiative that, okay, let's launch it in a hybrid mode so

00:56:38.290 --> 00:56:42.150
that I will make it keep like, uh, updating the content, uh,

00:56:42.310 --> 00:56:45.310
all like a five days, six days in a week on the different,

00:56:45.370 --> 00:56:49.510
different batches. And uh, like we, we have OTT of

00:56:49.510 --> 00:56:53.230
education, right? So none of my students are supposed to buy

00:56:53.230 --> 00:56:57.390
one single batch or one single services, whatever you want,

00:56:57.510 --> 00:57:00.290
even if you want only one thing, you have to go for like a

00:57:00.290 --> 00:57:03.110
subscription, a whole subscription. And even if you want all

00:57:03.110 --> 00:57:05.570
things, you have to go for all the subscription as simple as

00:57:05.570 --> 00:57:08.870
that. It means everything is available to everyone, right?

00:57:08.890 --> 00:57:12.090
Everything is available to everyone. So now my objective is

00:57:12.090 --> 00:57:15.890
to produce as many content as possible. And I believe

00:57:15.890 --> 00:57:19.410
everyone can't become a mentor. I, there are, there are a

00:57:19.410 --> 00:57:21.750
lot of mentor out there, even like, uh, in my previous

00:57:21.750 --> 00:57:26.090
company, I have built many mentors. So I believe in creating

00:57:26.090 --> 00:57:29.070
a lot of like, uh, people. So obviously I have created so

00:57:29.070 --> 00:57:30.910
many mentors, they are teaching here and there obviously,

00:57:30.910 --> 00:57:36.250
right. But at the end of the day, uh, somewhere I feel that,

00:57:36.250 --> 00:57:39.610
uh, I should go and I should like a deliver the content I

00:57:39.610 --> 00:57:42.850
should go and I should teach right. As much as possible, at

00:57:42.850 --> 00:57:46.650
least for next couple of more years, not like after five, 10

00:57:46.650 --> 00:57:49.630
year, maybe like, uh, but yeah, at least for next five

00:57:49.630 --> 00:57:54.010
years. So, uh, I can teach and, uh, yeah. So now things are

00:57:54.010 --> 00:57:56.650
becoming very, very interesting, right. The way, like the

00:57:56.650 --> 00:57:58.850
kind of a development that we are able to see in IT industry

00:57:58.850 --> 00:58:01.210
in a tech industry. It's amazing. Right. That's amazing.

00:58:01.730 --> 00:58:04.290
And, uh, yeah, it's, it's giving me a lot of learning. So

00:58:04.290 --> 00:58:07.250
same learning, I'm just trying to share with my students. So

00:58:07.250 --> 00:58:10.630
keeping that in our mind, we have a hybrid batch now and

00:58:10.630 --> 00:58:13.290
back to back, I'll keep on launching hybrid batch. So, so

00:58:13.290 --> 00:58:16.270
far we have launched, I think 20 hybrid batches in all the

00:58:16.270 --> 00:58:20.950
segments again, 2020, 2020. So 24 project, 24 interview,

00:58:21.150 --> 00:58:23.210
I'll keep on bringing it. I'll keep on providing you the

00:58:23.210 --> 00:58:27.150
content and, uh, yeah, along with the services, all the

00:58:27.150 --> 00:58:30.390
other added services, which is again, very much required.

00:58:31.530 --> 00:58:36.290
And, uh, then, uh, sometime we will try to connect anyhow.

00:58:36.470 --> 00:58:38.510
We are connected over a WhatsApp group, but yeah. So

00:58:38.510 --> 00:58:41.370
sometime we'll try to connect maybe via zoom and then we can

00:58:41.370 --> 00:58:42.310
have some sort of a discussion.

00:58:45.920 --> 00:58:48.380
I think hybrid approach is the best to learn quick and

00:58:48.380 --> 00:58:50.960
revision to, and raise a question when live zoom, you don't

00:58:50.960 --> 00:58:55.280
have to wait for, see in case of zoom. So I'm not expecting

00:58:55.280 --> 00:58:57.920
a small, small question because for that, we have already

00:58:57.920 --> 00:59:01.720
given you URI. Now, no one should come and say that, uh, you

00:59:01.720 --> 00:59:04.320
are not providing a support or you're not giving a

00:59:04.320 --> 00:59:06.860
handholding because you are living in an age of AI. If you

00:59:06.860 --> 00:59:10.780
think that, uh, for your small question, let's suppose you

00:59:10.780 --> 00:59:12.920
are getting an error, right? If you have not declared a

00:59:12.920 --> 00:59:15.680
variable, or if you are getting a file, not found kind of a

00:59:15.680 --> 00:59:19.220
error. And if you think that someone should come and solve

00:59:19.220 --> 00:59:22.800
your error, then believe me, you are not meant for it

00:59:22.800 --> 00:59:25.340
industry. You will not be able to do anything in the

00:59:25.340 --> 00:59:28.360
industry. You should look for some different options in your

00:59:28.360 --> 00:59:32.320
career. Right? If you're looking for a person, so those

00:59:32.320 --> 00:59:36.040
kinds of error, you should be able to solve by yourself by

00:59:36.040 --> 00:59:40.980
using AI, right? By using AI, basically that is the reason.

00:59:41.120 --> 00:59:44.200
So as a part of ecosystem, we have given you URI that, okay,

00:59:44.240 --> 00:59:47.260
don't go outside. Don't like try to spend another $20 per

00:59:47.260 --> 00:59:50.500
month, which is too much, right? So everything is available

00:59:50.500 --> 00:59:54.700
over here. Use it, learn it at the end of the day. The only

00:59:54.700 --> 00:59:58.940
thing which matters is a result. So the zoom session, so

00:59:58.940 --> 01:00:01.160
I'm, I'm looking for like a big problem. I'm looking for a

01:00:01.160 --> 01:00:04.080
big discussion over there, right? That, okay. You will come

01:00:04.080 --> 01:00:06.340
and ask a big question over there. Maybe a big problem

01:00:06.340 --> 01:00:08.920
statement. You will try to put up in, in front of me, not

01:00:08.920 --> 01:00:11.520
like, okay, I'm not able to like a, I'm getting this error,

01:00:11.600 --> 01:00:15.500
like a file not found, right? Those days was different five

01:00:15.500 --> 01:00:18.340
years back when I was running a tech. So we had a big

01:00:18.340 --> 01:00:20.840
support team day and night. They will be available whenever

01:00:20.840 --> 01:00:23.580
you are going to ping, they will respond back immediately.

01:00:24.420 --> 01:00:27.920
Right. And I had that team. I had run that kind of a, like a

01:00:27.920 --> 01:00:30.140
startup as well. Right. We just sold to some different

01:00:30.140 --> 01:00:33.560
company, but today environment is different. It's not the

01:00:33.560 --> 01:00:35.900
same environment you are living into. You should not wait

01:00:35.900 --> 01:00:36.920
for the people, a person.

01:00:40.430 --> 01:00:43.130
Don't worry. We'll not leave. You will catch you in a yearly

01:00:43.130 --> 01:00:45.910
subscription. Thank you. I'll, I'll try to make it better

01:00:45.910 --> 01:00:49.990
and better so that you can't leave. Even if you want, how

01:00:49.990 --> 01:00:52.430
would it does it? Can someone who is not a part of group can

01:00:52.430 --> 01:00:57.130
apply? No. So like for an internship, uh, you, again, you

01:00:57.130 --> 01:01:00.750
don't play. Everything comes with a down plus. How you keep

01:01:00.750 --> 01:01:05.990
upselvdated if that's fine to share from you. Uh, see, I

01:01:05.990 --> 01:01:09.130
keep on building things. Uh, my very simple approach is that

01:01:09.130 --> 01:01:12.550
I built things like I never believe in learning, even until

01:01:12.550 --> 01:01:15.830
today. Right. If you'll sit with me for a one, a state day,

01:01:15.910 --> 01:01:19.510
right. Uh, even like a day when I'm taking a leave, when I'm

01:01:19.510 --> 01:01:23.750
like off, basically from all the work, I just sit in front

01:01:23.750 --> 01:01:28.230
of system. I built things. things. Right? So that's the

01:01:28.230 --> 01:01:30.290
reason on a Euron platform and even in my previous company,

01:01:30.390 --> 01:01:32.690
you were able to see a lot of like an ecosystem. That's the

01:01:32.690 --> 01:01:35.570
reason I keep on saying that it's an ecosystem I'm trying to

01:01:35.570 --> 01:01:40.350
build. So I'm not a guy who learn, who read, I read, I read

01:01:40.350 --> 01:01:43.890
philosophy books, but not a technical things. Tech wise, I

01:01:43.890 --> 01:01:46.810
just build it. And that is the source of my knowledge. I

01:01:46.810 --> 01:01:51.170
just keep on experimenting it. Okay. Now I'll, I'll try to

01:01:51.170 --> 01:01:54.230
answer all the other questions guys, but before that focus

01:01:54.230 --> 01:01:57.910
on the topic first. Okay. Let me teach you how to do a fine

01:01:57.910 --> 01:02:01.470
tuning, LoRaBase fine tuning, how to do it. Then how to push

01:02:01.470 --> 01:02:05.610
this model that you have fine tuned into hugging phase so

01:02:05.610 --> 01:02:08.270
that other people will be able to use your fine tune model.

01:02:08.710 --> 01:02:13.330
Yeah. Then I will teach you open AI. So how to like a,

01:02:13.410 --> 01:02:16.550
prepare a data set for open AI because when you do a fine

01:02:16.550 --> 01:02:19.430
tuning for open AI or any fine tuning, any model, you have

01:02:19.430 --> 01:02:22.370
to prepare a data in a respective manner. Otherwise you will

01:02:22.370 --> 01:02:24.290
not be able to do a fine tuning. So for open AI model. I'm

01:02:24.290 --> 01:02:27.190
going to show you then hugging phase where you can like a

01:02:27.190 --> 01:02:29.250
fine tune any of the model. So I'm going to show you. So

01:02:29.250 --> 01:02:31.870
let's go with the demo and then I'm here. I'll try to answer

01:02:31.870 --> 01:02:35.090
all of your questions. Don't worry. Yes. So let's try to

01:02:35.090 --> 01:02:37.770
focus. And I'm going to share this entire file with all of

01:02:37.770 --> 01:02:41.730
you now itself. Yeah. So that you all will be able to

01:02:41.730 --> 01:02:49.820
execute it. So here guys, this folder, let

01:02:56.410 --> 01:02:57.890
me share this folder first of all.

01:03:04.070 --> 01:03:08.630
Okay. So model fine tuning. And let me check what is the

01:03:08.630 --> 01:03:09.010
size.

01:03:12.610 --> 01:03:17.370
Okay. It's a 17 MB of a folder. Model fine tuning D drive.

01:03:18.950 --> 01:03:22.810
So just do one thing. Model. Model.

01:03:31.000 --> 01:03:33.940
Okay. So I have just uploaded this particular folder guys.

01:03:34.140 --> 01:03:36.940
So please try to download this folder. First part. Second

01:03:36.940 --> 01:03:40.360
part is, so there is a requirement.txt file. I have just

01:03:40.360 --> 01:03:43.400
like done the freeze, pip freeze and then from there I have

01:03:43.400 --> 01:03:47.580
generated the requirement.txt file. So just try to install a

01:03:47.580 --> 01:03:52.300
new environment right inside your VS code. I believe we all

01:03:52.300 --> 01:03:55.260
know in every class I was doing that. So conda create hyphen

01:03:55.260 --> 01:03:57.420
end and the environment name. So just try to create the new

01:03:57.420 --> 01:04:02.120
environment with Python 3.10. Yeah. With Python 3.10

01:04:02.120 --> 01:04:07.340
activate that environment and then do pip install hyphen R

01:04:07.340 --> 01:04:10.160
requirement.txt. Requirement.txt I have already attached

01:04:10.160 --> 01:04:14.100
inside that one so that your environment and my environment

01:04:14.100 --> 01:04:16.680
is going to be same. Otherwise it will give you a lot of

01:04:16.680 --> 01:04:19.360
issues. A lot of issues. I have like a struggled a lot and

01:04:19.360 --> 01:04:22.100
then I have fixed all the issues and then it's running

01:04:22.100 --> 01:04:25.440
perfectly fine in my system. Right. Otherwise it will give

01:04:25.440 --> 01:04:27.580
you a hell lot of issue. Believe me. And you will feel

01:04:27.580 --> 01:04:31.640
frustrated. So simple. Create a new environment with Python

01:04:31.640 --> 01:04:36.740
3.10 a fresh environment inside that. Just try to do pip

01:04:36.740 --> 01:04:39.320
install requirement.txt and then everything will work.

01:04:39.400 --> 01:04:41.840
Everything means literally everything is going to work for

01:04:41.840 --> 01:04:45.900
all of you. As simple as that. Now come to this file. First

01:04:45.900 --> 01:04:49.960
of all, loracoa.py file. Now what we are trying to do over

01:04:49.960 --> 01:04:52.740
here. Let me explain you that part that how we are able to

01:04:52.740 --> 01:04:57.220
like achieve a fine tuning with the help of this one. Yeah.

01:04:57.720 --> 01:05:01.280
So here what we are trying to do is so we are trying to call

01:05:01.280 --> 01:05:04.540
all the hugging face libraries. Simple. And then we are

01:05:04.540 --> 01:05:08.120
trying to call pfit parameter efficient fine tuning. So this

01:05:08.120 --> 01:05:11.960
library is also available. p e f t p fit. Just now we have

01:05:11.960 --> 01:05:14.800
discussed. Right. So parameter efficient fine tuning. Then

01:05:14.800 --> 01:05:18.120
we are trying to call a Lora configuration from here and

01:05:18.120 --> 01:05:21.360
then get a p fit model, prepare a model and then task type

01:05:21.360 --> 01:05:25.180
data set wise. So I'm going to use a IMDB data set. So

01:05:25.180 --> 01:05:28.560
basically this data set is all about a review of the data.

01:05:28.680 --> 01:05:32.900
Right. So there will be like this, this kind of a data. You

01:05:32.900 --> 01:05:37.800
will be able to see basically inside this one. Let me give

01:05:37.800 --> 01:05:42.660
you the sample of the data for this. So

01:05:46.180 --> 01:05:52.110
here inside this IMDB, you will be able to see basically

01:05:52.110 --> 01:05:57.430
this kind of a data here.

01:05:59.040 --> 01:06:04.820
So there will be like a text and

01:06:06.480 --> 01:06:15.320
text is let's suppose this movie was not good and then you

01:06:15.860 --> 01:06:22.640
will be able to see label. So label is like one zero.

01:06:22.640 --> 01:06:25.960
Positive negative. Right. So this is a kind of a data which

01:06:25.960 --> 01:06:28.960
is there inside this IMDB. If you would like to change this

01:06:28.960 --> 01:06:31.040
data, you can change it. You can do it with your own data.

01:06:31.180 --> 01:06:34.320
That's completely fine. Yeah, that's completely fine. And in

01:06:34.320 --> 01:06:36.680
this format, you have to take the data. Now this is again a

01:06:36.680 --> 01:06:38.960
data which you will be able to find out on a hugging phase.

01:06:39.140 --> 01:06:42.080
So similar kind of a data can try to create now here. So

01:06:42.080 --> 01:06:46.360
what we are trying to do is that that we are not going to

01:06:46.360 --> 01:06:50.280
use a label. I'm not going to use a label. Now what kind of

01:06:50.280 --> 01:06:53.120
a training or what kind of a fine tuning? I'm going to

01:06:53.120 --> 01:06:57.360
perform. Let's try to understand that one. So here I'm

01:06:57.360 --> 01:07:01.920
trying to use this model and I'm trying to train this model

01:07:01.920 --> 01:07:05.460
for a casual inferencing. So basically this is a casual

01:07:05.460 --> 01:07:09.180
language model. What is the meaning of this casual language

01:07:09.180 --> 01:07:12.960
model? By the way, the meaning of this casual language model

01:07:12.960 --> 01:07:16.800
is just like a chat GPT means I'll give you something and

01:07:16.800 --> 01:07:19.700
then you are going to generate the next one that is called

01:07:19.700 --> 01:07:24.060
as casual model. Yeah. Making sense guys. So basically

01:07:24.060 --> 01:07:26.960
casual model training I'm going to do. Now you can ask me a

01:07:26.960 --> 01:07:30.500
question, then why you are taking this IMDB data? Because in

01:07:30.500 --> 01:07:34.000
this IMDB data, you have a text means you have a data plus

01:07:34.000 --> 01:07:37.020
you have a label, you have a review. So are you going to use

01:07:37.020 --> 01:07:42.340
a label while training a simple thing is no, I'm not going

01:07:42.340 --> 01:07:45.620
to use it. I'm just going to use this part of the data, not

01:07:45.620 --> 01:07:48.140
the other part of the data, because I'm going to train my

01:07:48.140 --> 01:07:52.040
model for a casual modeling. Casual modeling means just like

01:07:52.040 --> 01:07:54.880
a chat GPT. So I'm going to enter something and then it is

01:07:54.880 --> 01:07:57.260
going to complete, right? It is going to basically complete,

01:07:57.520 --> 01:07:59.940
is it going to generate the next tokens basically just like

01:07:59.940 --> 01:08:02.520
a chat GPT kind of a model or any other model that you see.

01:08:02.640 --> 01:08:06.000
So every model is basically a casual model in a tech term.

01:08:06.120 --> 01:08:09.560
So we try to like say that as a casual model, a model which

01:08:09.560 --> 01:08:14.520
predicts our next token, right? So in IMDB data, this will

01:08:14.520 --> 01:08:17.540
be available, but I'm not going to use this one. I'm just

01:08:17.540 --> 01:08:20.760
using this part, only this part. Yeah. Now we have. We are

01:08:20.760 --> 01:08:24.800
going to use a very simple Falcon model, a very small model

01:08:24.800 --> 01:08:27.300
for a training because if model is going to be big,

01:08:27.380 --> 01:08:30.420
obviously I need a big machine. It is going to take, it has

01:08:30.420 --> 01:08:33.800
taken half an hour. It will take like a days and days and

01:08:33.800 --> 01:08:38.460
that too with H 100 H 200 kind of a machine I need. So I'm

01:08:38.460 --> 01:08:41.480
doing all this training or like a fine tuning in my local

01:08:41.480 --> 01:08:45.800
machine, keeping that in a mind. I'm not using a big model.

01:08:46.020 --> 01:08:48.220
I will try to show you even with the big model, like a llama

01:08:48.220 --> 01:08:51.120
in hugging phase, right in hugging phase. I'm going to show

01:08:51.120 --> 01:08:54.640
you right after this. I'll give you that demo as well. Now

01:08:54.640 --> 01:08:58.440
here. So this is the model, a simple casual model. I'm

01:08:58.440 --> 01:09:01.640
trying to use a chat GPT like model, simple chat GPT like

01:09:01.640 --> 01:09:04.640
model exactly right. Then tokenizer and then padding token.

01:09:04.820 --> 01:09:07.300
So this is the model load that we have done. Then this is

01:09:07.300 --> 01:09:09.460
the data load I'm doing. Like I said, data will be in a,

01:09:09.480 --> 01:09:12.460
this format. I'm not using this label part. I'm just using

01:09:12.460 --> 01:09:15.740
from every data, only the text part I'm using. So whatever

01:09:15.740 --> 01:09:18.740
tokenization, whatever data that we are going to take, so we

01:09:18.740 --> 01:09:22.400
are going to convert that into a token length of one 28, as

01:09:22.400 --> 01:09:26.280
simple as that, yeah, one 28, basically we are going to

01:09:26.280 --> 01:09:29.700
convert it into that particular part. Then once that is

01:09:29.700 --> 01:09:32.940
done, right, once that is done. So we are trying to do a

01:09:32.940 --> 01:09:36.700
mapping of the data with a tokenizer. And then we are trying

01:09:36.700 --> 01:09:40.660
to basically create a column, input ID, attention, mask, and

01:09:40.660 --> 01:09:45.740
the labels. Now, so here, let me do this particular part. So

01:09:45.740 --> 01:09:49.080
here we are trying to give a model. Main task is going to

01:09:49.080 --> 01:09:51.620
start from here, rest of the part, you will be able to find

01:09:51.620 --> 01:09:54.680
out even our hugging phase. So major part is going to start

01:09:54.680 --> 01:09:57.680
from here. So here, what we are trying to call auto model

01:09:57.680 --> 01:10:00.860
for casual LLM. This is the library we are trying to call

01:10:00.860 --> 01:10:04.940
casual elements of LLM, which can try to produce a next

01:10:04.940 --> 01:10:08.820
basically, right. Which can try to predict the next one from

01:10:08.820 --> 01:10:11.340
a pre-trained from pre-trained means the model, which has

01:10:11.340 --> 01:10:13.560
already been trained. So here a model name I'm trying to

01:10:13.560 --> 01:10:16.200
give model name is what this Falcon model that I have, like

01:10:16.200 --> 01:10:18.260
a, I'm going to load. I'm going to load the code device map

01:10:18.260 --> 01:10:22.260
is auto means if inside your device, if you have a GPU, it

01:10:22.260 --> 01:10:25.700
will be able to consume a GPU resources. If you don't have a

01:10:25.700 --> 01:10:30.480
GPU, this one is going to work even on a CPU, right? CPU,

01:10:30.580 --> 01:10:33.560
even if you don't have a GPU, it is going to work. Now touch

01:10:33.560 --> 01:10:37.320
remote code through now, but we're a model for the eight bit

01:10:37.320 --> 01:10:40.460
training. So here, what we are trying to do is, so we are

01:10:40.460 --> 01:10:46.540
trying to say that we will try to write, we will try to do.

01:10:46.540 --> 01:10:50.880
A eight bit of a training, eight bit of the precision

01:10:50.880 --> 01:10:54.980
training so that my memory will be reduced, right? So eight

01:10:54.980 --> 01:10:57.600
bit simply means that, that obviously instead of 32 bits, so

01:10:57.600 --> 01:11:00.380
I'm doing a eight bit and eight bit will be lesser. So I'm

01:11:00.380 --> 01:11:03.980
trying to like introduce a Q factor over here. And then I'm

01:11:03.980 --> 01:11:06.200
trying to like a set a lot of configuration. So I'm trying

01:11:06.200 --> 01:11:09.300
to say that R is equals to eight. What is the meaning of R?

01:11:09.520 --> 01:11:13.260
So rank, we are trying to say, right, a rank over here. So

01:11:13.260 --> 01:11:16.540
at the time of discussion, at the time of this discussion. I

01:11:16.540 --> 01:11:19.660
have used rank is equals to basically four, right? So four,

01:11:19.720 --> 01:11:22.940
I have used now here, so I can try to change it as a four. I

01:11:22.940 --> 01:11:25.900
can try to change it as a, but like a eight, whatever I

01:11:25.900 --> 01:11:30.000
want, Laura alpha is 16 Laura dropout is this one. So these

01:11:30.000 --> 01:11:32.520
are just a parameter, which will go ahead with the Laura

01:11:32.520 --> 01:11:35.220
configuration. There are more, you can try to configure more

01:11:35.220 --> 01:11:39.900
now. So here I'm trying to call a get preferred model. So

01:11:39.900 --> 01:11:42.320
model I'm going to pass and Laura configuration. I'm going

01:11:42.320 --> 01:11:45.500
to pass as simple as that. So model I'm going to pass and

01:11:45.500 --> 01:11:47.720
then configuration. I'm going to pass and then model dot

01:11:47.720 --> 01:11:50.380
print trainable parameters. So all this trainable parameter

01:11:50.380 --> 01:11:54.480
will be print and here. So for a model training argument,

01:11:54.680 --> 01:11:58.900
I'm trying to pass. So here the Laura configuration, right?

01:11:58.940 --> 01:12:02.140
A lot of configuration from the original model, whatever

01:12:02.140 --> 01:12:06.580
model that we had, right? And then here to train the model,

01:12:06.700 --> 01:12:09.660
whatever configuration is required. So output directory. So

01:12:09.660 --> 01:12:11.780
where it is going to store all the output in this directory,

01:12:11.920 --> 01:12:16.380
uh, per device train batch size to the accumulation step. So

01:12:16.380 --> 01:12:19.720
this is the normal, normal things, right? Normal things that

01:12:19.720 --> 01:12:22.320
we try to do. So each and everything we are trying to like,

01:12:22.320 --> 01:12:24.980
uh, do it even over here. And then we are trying to call a

01:12:24.980 --> 01:12:27.540
trainer. So model or trainer training argument, it will

01:12:27.540 --> 01:12:31.260
take, and then it is going to take the complete data set, a

01:12:31.260 --> 01:12:33.820
small data set, thousand data set. I'm trying to pass inside

01:12:33.820 --> 01:12:37.500
this one and then trainer dot train. So this is going to

01:12:37.500 --> 01:12:41.220
invoke the entire training step. Now the major takeouts,

01:12:41.260 --> 01:12:46.140
right? The major takeout from here is. Okay. Okay. Any model

01:12:46.140 --> 01:12:48.580
that you are trying to train any means literally any, which

01:12:48.580 --> 01:12:52.320
is available over the internet, right? Load the model with a

01:12:52.320 --> 01:12:55.840
tokenizer, obviously, right? Because whatever tokenizer that

01:12:55.840 --> 01:12:59.140
model has used, you have to use the same, uh, so that you

01:12:59.140 --> 01:13:03.020
have to tokenize your input data, right? Define the task. So

01:13:03.020 --> 01:13:06.100
I'm trying to do a casual modeling over here, casual

01:13:06.100 --> 01:13:08.200
learning over here. So I have defined the task. Okay.

01:13:08.280 --> 01:13:11.300
Prepare the data accordingly. Uh, because every model is

01:13:11.300 --> 01:13:13.780
going to accept a different, different kind of a length of

01:13:13.780 --> 01:13:18.720
this token. Then. Set your parameter. So let's suppose if

01:13:18.720 --> 01:13:20.780
I'm trying to do a Laura. So obviously for Laura, whatever

01:13:20.780 --> 01:13:24.020
parameters required, set that parameter, set a parameter for

01:13:24.020 --> 01:13:27.820
the model training, and then call the trainer as simple as

01:13:27.820 --> 01:13:31.460
that. Now, if you will start executing this one, right? So

01:13:31.460 --> 01:13:34.920
just execute Python, Laura underscore Q Laura, like a dot

01:13:34.920 --> 01:13:37.840
PI, and it will be able to execute. And finally, it is going

01:13:37.840 --> 01:13:41.480
to give you these main number of files. These main number of

01:13:41.480 --> 01:13:44.180
files it is going to give you. So everything will be

01:13:44.180 --> 01:13:47.500
available inside this one. So this is the complete file for

01:13:47.500 --> 01:13:50.480
our model. And this is the PT file. You, as you can see

01:13:50.480 --> 01:13:53.820
optimizer for optimizer, this is the PT file. And for us, we

01:13:53.820 --> 01:13:56.760
have a PT file. So we have this combined things as a

01:13:56.760 --> 01:14:00.200
complete model. You will be able to get it. Now I have to

01:14:00.200 --> 01:14:03.000
test this one. I have to test this one. So how I can test

01:14:03.000 --> 01:14:05.800
it. So there is a test file I have already attached. So the

01:14:05.800 --> 01:14:09.380
entire model is available over here, the entire model is

01:14:09.380 --> 01:14:13.220
available over here. Now I have to test it. So let me just

01:14:13.220 --> 01:14:15.720
remove this part guys. I have deleted it in a later stage.

01:14:16.840 --> 01:14:19.760
Yeah. So Falcon Laura output, just try to keep it only this

01:14:19.760 --> 01:14:23.680
much adapter path. So basically it is going to call the

01:14:23.680 --> 01:14:27.100
adapter so that it will be able to do a training. It will be

01:14:27.100 --> 01:14:31.340
able to do a, like a inferencing basically. So here, what

01:14:31.340 --> 01:14:34.160
are we trying to do? So in case of like a Laura inferencing,

01:14:34.260 --> 01:14:36.680
so we are trying to like a load the model, load the model

01:14:36.680 --> 01:14:40.280
from where? My local, right? Falcon Laura output directly

01:14:40.280 --> 01:14:42.020
that I've created. So from there, I'm trying to load the

01:14:42.020 --> 01:14:45.600
model. And then. Okay. So I'm going to load a configuration.

01:14:45.860 --> 01:14:48.260
So I'm trying to load the configuration basically, and then

01:14:48.260 --> 01:14:51.560
load our base model. So I'm loading a base model over here.

01:14:52.100 --> 01:14:54.300
As simple as that, from

01:14:56.630 --> 01:14:59.430
this adapter path, I'm loading a base model as you can see.

01:14:59.510 --> 01:15:03.610
So if it, and then it is loading basically adapter path. So

01:15:03.610 --> 01:15:07.330
from here, I'm trying to load basically this base model. And

01:15:07.330 --> 01:15:10.930
then once base model is been like a loaded basically, so

01:15:10.930 --> 01:15:13.770
base model adapter, it's loaded. So we are trying to call

01:15:13.770 --> 01:15:16.350
eval. And then we are trying to call even a tokenizer.

01:15:16.350 --> 01:15:18.830
Because whatever data that you are going to pass, obviously

01:15:18.830 --> 01:15:22.970
it should be available with the same tokenizer. And then we

01:15:22.970 --> 01:15:26.450
are going to call the inferencing pipeline. Now here you can

01:15:26.450 --> 01:15:29.330
control a multiple parameter. For example, temperature. I

01:15:29.330 --> 01:15:32.050
think we all know that what is the meaning of a temperature

01:15:32.050 --> 01:15:34.930
parameter? So basically it will try to increase or decrease

01:15:34.930 --> 01:15:38.470
the hallucination, right? Model is basically the model that

01:15:38.470 --> 01:15:41.350
we have loaded our local model now that we have trained

01:15:41.350 --> 01:15:43.910
already. And then

01:15:46.790 --> 01:15:50.230
I'm trying to give a prompt. Okay. So inside this pipe,

01:15:50.430 --> 01:15:53.190
inside this like a pipe, I'm trying to give a prompt. The

01:15:53.190 --> 01:15:56.810
movie was absolute wonderful because, so this is my prompt,

01:15:56.910 --> 01:16:01.150
right? So it should be able to generate our next data. So

01:16:01.150 --> 01:16:03.710
this is what I'm, I was like expecting that. Okay, fine. So

01:16:03.710 --> 01:16:06.630
it's generate our next data. So how much next data I'm

01:16:06.630 --> 01:16:08.710
expecting maximum number of tokens. So in a pipe, I have

01:16:08.710 --> 01:16:11.470
given that, that generate a hundred, generate a hundred

01:16:11.470 --> 01:16:14.390
number of token next, right? Max to max hundred number of

01:16:14.390 --> 01:16:18.170
token, next token generated after this one. So now I can try

01:16:18.170 --> 01:16:20.810
to show you the testing. Testing at least, right? So here,

01:16:20.910 --> 01:16:25.730
if I'm going to like a clean it and DIR and a test LoRa

01:16:25.730 --> 01:16:33.270
inferences. So Python test LoRa inferences now here. So I

01:16:33.270 --> 01:16:35.970
have given the movie was absolutely wonderful. It is trying

01:16:35.970 --> 01:16:40.390
to do a inferencing. As you can see, I'm not initiating a

01:16:40.390 --> 01:16:42.330
training again, training wise, like just, you have to call

01:16:42.330 --> 01:16:45.550
Python, LoRa, QLoRa, PI, and it will be able to do a

01:16:45.550 --> 01:16:50.430
training automatically. If your environment is set. But it

01:16:50.430 --> 01:16:52.590
will take half an hour of time. So for me, it took a half an

01:16:52.590 --> 01:16:55.330
hour of time. So for you, obviously it will take more and

01:16:55.330 --> 01:16:57.490
more with these parameters. Otherwise you can reduce even

01:16:57.490 --> 01:16:58.130
the number of parameter.

01:17:01.500 --> 01:17:04.220
Okay. So let's see. So it will be able to do a inferencing

01:17:04.220 --> 01:17:07.060
and all this inferencing is happening from my own fine tuned

01:17:07.060 --> 01:17:10.500
model with my own IMDb data set. So see the movie was

01:17:10.500 --> 01:17:14.480
absolutely wonderful till this because of the actor in it

01:17:14.480 --> 01:17:18.180
and the way the story was done. I just love the way it was

01:17:18.180 --> 01:17:21.460
done. The B52 are back with a new. I mean, I don't know.

01:17:22.360 --> 01:17:22.840
It's been sitting for about three and a half years now, but

01:17:22.840 --> 01:17:23.100
usually it does not fit And when you look at the video with

01:17:23.100 --> 01:17:27.200
the help of the legendary, so now see if you look, I need to

01:17:27.200 --> 01:17:29.840
read out this entire thing, right. You'll be able to feel

01:17:29.840 --> 01:17:33.340
that it's a wonderful outcome, right? It's a wonderful

01:17:33.340 --> 01:17:37.040
outcome. Because the base model that I have already used, it

01:17:37.040 --> 01:17:39.060
was already trained. Right? Although it's a small model

01:17:39.060 --> 01:17:42.180
Falcon model, right? But it was already trained and it was

01:17:42.180 --> 01:17:45.420
good with respect to giving the output. Now, the only matter

01:17:45.420 --> 01:17:47.740
of fact that I have changed over here is that, that I have

01:17:47.740 --> 01:17:50.360
given on my own data, right? I.M.D and movie data I have

01:17:50.360 --> 01:17:52.740
given artillery. Mm. just a review I have given and then

01:17:52.740 --> 01:17:56.440
data whatever like a review people had talked about so we

01:17:56.440 --> 01:18:01.160
have we have like a given that basically and now like it is

01:18:01.160 --> 01:18:04.340
able to like do some sort of a response and that response is

01:18:04.340 --> 01:18:07.180
better right I am able to understand the grammar I am able

01:18:07.180 --> 01:18:10.600
to understand all the punctuation it is perfect right so

01:18:10.600 --> 01:18:13.500
this is the like advantage that you will be able to get with

01:18:13.500 --> 01:18:15.340
respect to fine tuning and this is something that we are

01:18:15.340 --> 01:18:16.340
able to do it

01:18:21.010 --> 01:18:23.790
where you pass a lot of configuration I don't see it is it

01:18:24.610 --> 01:18:31.610
see lot of configuration right get preferred model here is a

01:18:31.610 --> 01:18:33.730
lot of configuration model plus configuration both I am

01:18:33.730 --> 01:18:39.340
trying to pass see so this model will become this model

01:18:39.340 --> 01:18:41.780
variable will become combination of model plus a lot of

01:18:41.780 --> 01:18:45.900
configuration and then we are trying to call what inside a

01:18:45.900 --> 01:18:48.900
trainer we are calling model now inside a model we have a

01:18:48.900 --> 01:18:51.740
lot of configuration plus a base model both by the way and

01:18:51.740 --> 01:18:55.080
then for this model we have a training argument and a data

01:18:55.080 --> 01:19:01.470
right fine can it accurately provide the review summaries of

01:19:01.470 --> 01:19:04.410
the specific movie yeah it will be obviously so if that is a

01:19:04.410 --> 01:19:07.090
part of your data you can try to print even your imdb data

01:19:07.090 --> 01:19:10.750
and then try to check and it will be for sure and we had we

01:19:10.750 --> 01:19:14.010
are taking only thousand only thousand so till thousand only

01:19:14.010 --> 01:19:16.790
just try to do the cross check it will be able to provide it

01:19:16.790 --> 01:19:22.490
in a best possible way yeah so just run this one guys once

01:19:22.490 --> 01:19:25.010
again and then this is just a template which I have shared

01:19:25.010 --> 01:19:27.130
you will be able to now do a training. could work if you

01:19:27.130 --> 01:19:28.990
want to do training and the inferencing after that with any

01:19:28.990 --> 01:19:31.970
model any model is literally any bigger small model you will

01:19:31.970 --> 01:19:35.210
be able to do our training at least for a casual modeling in

01:19:35.210 --> 01:19:39.170
strategy pretty kind of a task okay now I am able to build

01:19:39.170 --> 01:19:43.590
this entire model I have shared even like a Jupiter notebook

01:19:43.590 --> 01:19:48.330
over here so where you can you can try to push your like a

01:19:48.330 --> 01:19:52.530
model the entire model that you have over here into hugging

01:19:52.530 --> 01:19:57.010
phase so that it will be global and anyone can use it. yeah

01:19:57.010 --> 01:19:59.590
it will be global and anyone will be able to use it you can

01:19:59.590 --> 01:20:03.770
share a public link for example this is a public link that i

01:20:03.770 --> 01:20:06.010
have posted i am sharing it with all of you and you can

01:20:06.010 --> 01:20:08.830
check it now itself right you can check it now itself so

01:20:08.830 --> 01:20:11.450
this is the public link you will be able to see my name

01:20:11.450 --> 01:20:13.790
lanchu kumar and lanchu kumar has pushed this particular

01:20:13.790 --> 01:20:17.170
model uh i think today i have or maybe yesterday i don't

01:20:17.170 --> 01:20:20.010
remember uh i'll have to check the date yeah 20 hour ago

01:20:20.010 --> 01:20:26.330
fine so uh yeah i don't remember maybe i was doing yesterday

01:20:26.330 --> 01:20:30.410
so here is a preparation which i have done so where this uh

01:20:30.410 --> 01:20:32.930
this is going to help you out in terms of pushing a model

01:20:32.930 --> 01:20:37.570
into your own hugging phase and so that anyone can access it

01:20:37.570 --> 01:20:39.790
now i have shared my link and now you can try to open up

01:20:39.790 --> 01:20:42.570
this link and you will be able to access it part number one

01:20:42.570 --> 01:20:46.910
now how you can do it let's talk about that so here what you

01:20:46.910 --> 01:20:50.650
have to do is guys first of all go to hugging phase go to

01:20:51.570 --> 01:20:55.930
hugging phase basically and then inside that go to your

01:20:55.930 --> 01:20:59.490
account first yeah go to your account profile so here is our

01:20:59.490 --> 01:21:03.010
account here is the profile so just go inside that one and

01:21:03.010 --> 01:21:08.870
then once you will be like uh here so you have to create a

01:21:08.870 --> 01:21:13.230
api let me i

01:21:18.190 --> 01:21:21.910
just forgot okay setting yeah go to setting yeah go to

01:21:21.910 --> 01:21:25.390
setting so go to profile simple go to profile first of all

01:21:25.390 --> 01:21:29.470
so here then go to setting uh and then inside a setting you

01:21:29.470 --> 01:21:32.530
will be able to find out the access token yeah access token

01:21:32.530 --> 01:21:36.710
now here i have created the access token about 21 hour ago

01:21:36.710 --> 01:21:39.270
the access token which i have already mentioned inside your

01:21:39.270 --> 01:21:43.970
jupiter notebook which i am going to delete it now so that

01:21:43.970 --> 01:21:47.370
you will not be able to use my access token yeah so i have

01:21:47.370 --> 01:21:49.950
deleted my access token so i have already shared so i have

01:21:49.950 --> 01:21:52.170
deleted it so that you will not be able to push because that

01:21:52.170 --> 01:21:54.850
is the only thing which is required to push anything in

01:21:54.850 --> 01:21:56.430
anyone's hugging face repository permission from katar

01:21:56.430 --> 01:21:56.430
Eles website barrage analog may be helpful um uh but you

01:21:56.430 --> 01:21:58.790
will actually tree. So here you can go and you can try to

01:21:58.790 --> 01:22:01.150
create a new token. I'm going to create a new token once

01:22:01.150 --> 01:22:05.630
again, so token name. So maybe like a test or maybe like a

01:22:05.630 --> 01:22:12.310
so you're on something like this and then user permission.

01:22:12.610 --> 01:22:15.070
So what kind of a permission you would like to give? So I

01:22:15.070 --> 01:22:18.590
would like to give all the right access by the way, right?

01:22:18.710 --> 01:22:22.630
All the right access. So there are a lot of like a

01:22:22.630 --> 01:22:25.530
permission which has been given. You can try to create a N

01:22:25.530 --> 01:22:28.210
number of token for you, for your entire team member,

01:22:28.330 --> 01:22:31.750
whatever you want. So I just have to give a right access of

01:22:31.750 --> 01:22:34.430
the content setting all the repo. So I'll just try to do

01:22:34.430 --> 01:22:37.290
check, check, check for repository, but only right access is

01:22:37.290 --> 01:22:39.890
required by the way, right? Read access is fine. Right

01:22:39.890 --> 01:22:42.150
access is the only thing which is required. And then I can

01:22:42.150 --> 01:22:45.570
click on create token, right? Create token. Now this is my

01:22:45.570 --> 01:22:50.650
token. Yeah, this is my token. So copy it done. And once

01:22:50.650 --> 01:22:53.670
this token is created, what you have to do is you have to

01:22:53.670 --> 01:23:01.730
come. Yeah. And then here, so token will start with HF. So

01:23:01.730 --> 01:23:05.450
you have to run this code first of all. So hugging face hub

01:23:05.450 --> 01:23:09.290
dot import login and then login. So this token will be able

01:23:09.290 --> 01:23:12.550
to understand your account and you will be able to log in

01:23:12.550 --> 01:23:15.550
immediately. So now if I'm going to execute it, yes, I'm

01:23:15.550 --> 01:23:18.610
able to log in, right? Immediately I'm able to log in. I

01:23:18.610 --> 01:23:20.890
have changed my previous token so you can create your own

01:23:20.890 --> 01:23:25.510
token guys, just do it and let me know. Yes or no. If you're

01:23:25.510 --> 01:23:29.110
able to create it. So simple. Go to your profile, then go to

01:23:29.110 --> 01:23:31.750
setting and then access token and then one click create a

01:23:31.750 --> 01:23:31.950
token.

01:23:36.860 --> 01:23:41.060
Yes, everyone. So I think a couple of days back, so someone

01:23:41.060 --> 01:23:43.760
from a group in any group, someone has asked me even that

01:23:43.760 --> 01:23:46.860
how to publish something in a hugging phase. So I, I told

01:23:46.860 --> 01:23:50.840
them, I replied to them in, I don't know whether it was your

01:23:50.840 --> 01:23:53.360
group or someone else. Uh, but yeah, I have replied that,

01:23:53.420 --> 01:23:57.100
uh, in a couple of days I'm going to discuss. So that's the

01:23:57.100 --> 01:24:01.320
reason. I thought of discussing this one. Yeah, because we,

01:24:01.400 --> 01:24:04.060
we are now going to tune a lot of models, right? Fine tune a

01:24:04.060 --> 01:24:06.180
lot of models. So obviously push it inside the hugging

01:24:06.180 --> 01:24:08.780
phase, make it publicly available. Even if you are going to

01:24:08.780 --> 01:24:10.520
create a machine learning model, push it inside hugging

01:24:10.520 --> 01:24:16.380
phase. Simple. With the proper tagging. I have requested

01:24:16.380 --> 01:24:20.100
you. Okay. Okay. Dave was okay. So it was Dave. Yeah, this

01:24:20.100 --> 01:24:22.220
is, this is what, uh, when, when I was preparing this

01:24:22.220 --> 01:24:26.080
material, right? Uh, so, um, I was not able to recall the

01:24:26.080 --> 01:24:28.900
group name. And the person name, uh, it was Dave by the way,

01:24:28.940 --> 01:24:32.580
but yeah, so I was able to recall that, uh, statement that,

01:24:32.580 --> 01:24:35.020
uh, if you can show me how to push something into hugging

01:24:35.020 --> 01:24:39.520
phase. So I thought, okay, fine, let's, let's do it. Do we

01:24:39.520 --> 01:24:43.640
need to create a new token in HF hugging phase? Yes. Hugging

01:24:43.640 --> 01:24:45.520
phase. You have to create the new token, create a new token.

01:24:45.640 --> 01:24:46.380
Click over here.

01:24:49.610 --> 01:24:53.050
I have, I have given you my token, uh, but, uh, I have just

01:24:53.050 --> 01:24:55.210
like a deleted that token. So you will not be able to use it

01:24:55.210 --> 01:24:59.610
now. So I have deleted this. Uh, the previous one. I have

01:24:59.610 --> 01:25:03.250
created even new for me. So create it. Now, once it is done,

01:25:03.390 --> 01:25:06.390
then what you have to do is so adapter path means wherever

01:25:06.390 --> 01:25:08.850
your adapter is, means wherever your entire model is

01:25:08.850 --> 01:25:12.110
available. So just try to give that directory, right? And

01:25:12.110 --> 01:25:15.290
then repo ID. So where you would like to like store this

01:25:15.290 --> 01:25:18.710
entire thing, right? Where you would like to hold this

01:25:18.710 --> 01:25:20.790
entire thing, just like GitHub repository, by the way,

01:25:20.830 --> 01:25:24.690
right? So this is my source. So here in my local system

01:25:24.690 --> 01:25:28.110
where the model is available now, the entire folder and then

01:25:28.110 --> 01:25:31.230
repo ID. So I will create a repo, very simple once again,

01:25:31.310 --> 01:25:36.050
right? So I'll go to this one. I'll go to profile. Yeah. And

01:25:36.050 --> 01:25:43.010
then I can try to create a, so here I have already created a

01:25:43.010 --> 01:25:49.930
one of my repo. So Sudhanshu Kumar and just do one thing.

01:25:50.010 --> 01:25:54.270
I'll just, this repo is not available. So I'll just change

01:25:54.270 --> 01:25:57.330
this name. I'll just make it as a Sudhanshu Kumar. Sudhanshu

01:25:57.330 --> 01:26:01.830
Kumar is my basically. Uh. This one, uh, my username. So

01:26:01.830 --> 01:26:04.890
your username is must, you have to give a username. So here

01:26:04.890 --> 01:26:07.770
you will be able to find out your username or here. So this

01:26:07.770 --> 01:26:10.850
below one, not the above one, the below one is your username

01:26:10.850 --> 01:26:14.230
by the way. Yeah. So below one is a username by the way. So

01:26:14.230 --> 01:26:18.550
you have to use this, uh, username and then let me, let me,

01:26:18.570 --> 01:26:21.470
let me, yeah. So this is the username slash. Let's suppose

01:26:21.470 --> 01:26:26.950
if I'm going to give a repo name, uh, Falcon, Falcon fine

01:26:26.950 --> 01:26:32.010
tuned. Yeah. So execute now. So this is going to my repo ID

01:26:32.010 --> 01:26:35.990
and this is going to my, so just, just change your name

01:26:35.990 --> 01:26:39.770
guys. Just change this name. If you have not changed this

01:26:39.770 --> 01:26:42.650
one, then this repository will be created automatically, but

01:26:42.650 --> 01:26:46.150
you have to change the username first. So, and then this is

01:26:46.150 --> 01:26:48.930
your local. So wherever you have the, like a models, which

01:26:48.930 --> 01:26:51.170
is available, whatever model is available. So you are just

01:26:51.170 --> 01:26:54.070
pushing the entire folder. It never understands this models

01:26:54.070 --> 01:26:57.110
basically. It just understand the file. So folder. It will

01:26:57.110 --> 01:26:59.830
try to push entire folders. Whatever you are keeping inside

01:26:59.830 --> 01:27:03.010
the folder, it will be published automatically. Okay. So

01:27:03.010 --> 01:27:05.790
load a lot of adapter configuration. So we are trying to

01:27:05.790 --> 01:27:09.050
like, uh, load it and then load the base model. So loading a

01:27:09.050 --> 01:27:13.030
base model pre-trained and then simple model dot push. So

01:27:13.030 --> 01:27:16.270
this is a small operation after loading each and everything.

01:27:18.390 --> 01:27:21.930
So load a base model and then load the adapter and then

01:27:21.930 --> 01:27:27.810
model dot push to hub, simple and repo ID. What is my repo

01:27:27.810 --> 01:27:30.850
ID? This one. Yeah. Adapter path. Anyhow, we are trying to

01:27:30.850 --> 01:27:32.610
use it. So it will be able to understand that what we are

01:27:32.610 --> 01:27:35.410
trying to push. So this model object we have created and

01:27:35.410 --> 01:27:39.190
then model object dot push to hub execute. And let's see, it

01:27:39.190 --> 01:27:43.290
will try to push it. Now it is pushing it. Yeah. And now I'm

01:27:43.290 --> 01:27:46.110
able to get the new, uh, like a fine, a Falcon fine tune.

01:27:46.190 --> 01:27:48.890
See Falcon fine tuned. This was the name, which I have

01:27:48.890 --> 01:27:52.390
changed, right? Falcon fine tuned. So just click over here.

01:27:52.550 --> 01:27:58.510
And this is the adapter.json. This is adapter model tensor.

01:27:58.690 --> 01:28:03.150
So I'm able to upload adapter.json, adapter.safetensors,

01:28:03.190 --> 01:28:06.210
which is required for the inferencing, right? Which is

01:28:06.210 --> 01:28:08.690
basically required for the inferencing. So you can even go

01:28:08.690 --> 01:28:11.970
and check what is there inside this one. So these two things

01:28:11.970 --> 01:28:14.250
are required for the inferencing. If you would like to push

01:28:14.250 --> 01:28:16.550
your tokenizer, you can try to push your tokenizer as well.

01:28:16.630 --> 01:28:20.490
That's not an issue. Yeah. So you can push whatever you want

01:28:20.490 --> 01:28:23.150
at any point of a time and it's available inside this

01:28:23.150 --> 01:28:26.730
particular repo. Yeah. That's available inside. So model

01:28:26.730 --> 01:28:30.270
card, uh, you can, you can try to even fill all of these

01:28:30.270 --> 01:28:33.110
information. So hugging face provides you this entire

01:28:33.110 --> 01:28:36.430
template, right? This entire template. And you can click

01:28:36.430 --> 01:28:38.870
over here. So for example, my model card is completely

01:28:38.870 --> 01:28:42.710
empty, right? It's empty. I have not done anything. Just I

01:28:42.710 --> 01:28:45.730
have pushed the file. So these files are available, right?

01:28:45.790 --> 01:28:49.070
These files are actually available, but inside a model card,

01:28:49.150 --> 01:28:52.410
I have not done anything. So those who try to maintain the

01:28:52.410 --> 01:28:55.310
repository, so they try to edit the model card. So here you

01:28:55.310 --> 01:28:58.270
can go and just feel like a form, or maybe you can try to

01:28:58.270 --> 01:29:01.870
create a ready me IMD and then update this entire things in

01:29:01.870 --> 01:29:06.390
one sort in one go. And uh, people who are, so just update

01:29:06.390 --> 01:29:08.730
your ready me IMD. Otherwise you can try to go in a manual

01:29:08.730 --> 01:29:12.430
way, your wish, right? And then people will be able to see a

01:29:12.430 --> 01:29:17.030
beautiful definition and anyone and everyone who is going to

01:29:17.030 --> 01:29:19.210
use your model. So they can just go through your repository,

01:29:19.490 --> 01:29:22.450
whatever you have mentioned. And uh, accordingly they will

01:29:22.450 --> 01:29:26.150
be able to use it. Is it making sense to all of us guys?

01:29:27.590 --> 01:29:30.050
Yeah. So how to maintain a repository inside hugging face,

01:29:30.210 --> 01:29:32.250
how to push a model inside a hugging face.

01:29:43.220 --> 01:29:46.300
Can you also show how can we use this HF model for

01:29:46.300 --> 01:29:50.100
inferencing? Obviously I have shown you, okay. Hugging face

01:29:50.100 --> 01:29:54.060
model for the inferencing you're talking about. Okay. In a

01:29:54.060 --> 01:29:56.140
local, I have shown you, right? Same adapter I'm trying to

01:29:56.140 --> 01:29:58.500
use, so you don't have to do anything. You just have to like

01:29:58.500 --> 01:30:00.880
a load it. And then with the help of hugging face pipeline,

01:30:01.040 --> 01:30:05.180
and then you have to call, you have to pass the data. In a

01:30:05.180 --> 01:30:06.700
local, I have already shown you the inferencing. So the

01:30:06.700 --> 01:30:11.220
same, same thing. Okay. Now. So now we know that, uh, okay.

01:30:11.300 --> 01:30:13.840
In a hugging face, how we can try to push the model, just

01:30:13.840 --> 01:30:16.820
like other people are trying to maintain the model. So see,

01:30:16.960 --> 01:30:18.940
they are trying to maintain the beautiful documentation,

01:30:19.240 --> 01:30:23.420
even for your own model push. And they are maintaining the

01:30:23.420 --> 01:30:25.500
file version, as you can see that they're maintaining the

01:30:25.500 --> 01:30:28.320
file version. Uh, and then there is a community discussion

01:30:28.320 --> 01:30:30.680
where people can come and people can start discussing about

01:30:30.680 --> 01:30:34.900
it. So you have the exact same option. You don't have less,

01:30:35.040 --> 01:30:37.900
or you don't have a more, right? You have exact same option,

01:30:38.040 --> 01:30:41.460
everything you have right in, in your repository. So you can

01:30:41.460 --> 01:30:43.940
go, you can try to maintain it. You can do whatever you

01:30:43.940 --> 01:30:47.180
want, and then you can try to like make it public. You can

01:30:47.180 --> 01:30:50.060
try to make it private, whatever you want. It's your wish.

01:30:50.240 --> 01:30:54.140
It's up to you basically, right? It's up to you and you will

01:30:54.140 --> 01:30:58.760
be able to share the model, your credit model. So it is, it

01:30:58.760 --> 01:31:02.880
will be good. That if you are going to attach some of the

01:31:02.880 --> 01:31:06.940
hugging. Face URL in your resume that I have fine tuned this

01:31:06.940 --> 01:31:09.840
model for this particular task. I have fine tuned this model

01:31:09.840 --> 01:31:12.760
for this particular task. Now what kind of a task? So so far

01:31:12.760 --> 01:31:15.580
I have talked about a casual modeling, but very soon today

01:31:15.580 --> 01:31:18.240
itself, I'm going to talk about other tasks as well. So now

01:31:18.240 --> 01:31:21.400
you will be able to understand that what else I can do,

01:31:21.460 --> 01:31:26.440
right? What else I can do except this simple fine tuning. So

01:31:26.440 --> 01:31:29.700
just try to like, uh, upload a couple of models over here,

01:31:29.780 --> 01:31:32.840
uh, maintain the complete, like a details of the model.

01:31:32.840 --> 01:31:36.540
Maintain the proper read me file over here, right? Ask your

01:31:36.540 --> 01:31:39.800
friend to download it so that, uh, probably you can say

01:31:39.800 --> 01:31:42.580
that, okay, my model has been used by a hundred people. At

01:31:42.580 --> 01:31:44.660
least my a hundred people, a hundred, at least a hundred

01:31:44.660 --> 01:31:46.600
people are using my model because anyone is going to

01:31:46.600 --> 01:31:49.420
download it, right? Uh, you, you will be able to see like a

01:31:49.420 --> 01:31:51.880
number of downloads, the hugging face is going to maintain

01:31:51.880 --> 01:31:55.540
it. See, it's, it's going to maintain it. Yeah. So it is

01:31:55.540 --> 01:31:57.060
going to maintain each and everything that how many

01:31:57.060 --> 01:31:59.380
downloads has happened, everything, everything. Yeah.

01:31:59.780 --> 01:32:02.820
Everything. Uh, you will be able to, uh, like, uh, see, and

01:32:02.820 --> 01:32:05.480
otherwise people will be able to see it. So it is going to

01:32:05.480 --> 01:32:08.540
build your credit, a real one that yes, I have really

01:32:08.540 --> 01:32:12.320
worked, right? I have really worked and there is something

01:32:12.320 --> 01:32:16.240
which I have produced, uh, which people are using by the

01:32:16.240 --> 01:32:20.360
way. Yeah. So this is all about the hugging face, uh, where

01:32:20.360 --> 01:32:23.220
you can try to push the model. Now coming to the next

01:32:23.220 --> 01:32:26.600
section, again, I'll come back to hugging face, right? Just

01:32:26.600 --> 01:32:28.880
wait for some time. Again, I'll come back to hugging face.

01:32:28.880 --> 01:32:35.160
But now it's time, uh, to discuss something more, uh, like,

01:32:35.220 --> 01:32:39.580
uh, in terms of, uh, model training, basically. So there are

01:32:39.580 --> 01:32:41.620
like what, what kind of a, what an all kind of a training

01:32:41.620 --> 01:32:45.380
that we try to perform. So here I would like to like open up

01:32:45.380 --> 01:32:48.300
my scribbling and I would like to discuss, and again, this

01:32:48.300 --> 01:32:50.680
point is very much important from an interview perspective.

01:32:52.860 --> 01:32:55.520
So there are different, different kinds of training, which

01:32:55.520 --> 01:32:59.360
you can perform. So there is something called as. There is

01:32:59.360 --> 01:33:03.260
something called as SFT, SFT. Now what is the meaning of

01:33:03.260 --> 01:33:06.620
this? So SFT means supervised,

01:33:07.820 --> 01:33:12.520
supervised fine tuning.

01:33:14.340 --> 01:33:18.840
Yeah. There is something called as, right? So there is

01:33:18.840 --> 01:33:25.780
something called as like a GT, GT it's called as generic

01:33:27.190 --> 01:33:28.370
trainer.

01:33:30.330 --> 01:33:35.930
Yeah. Yeah. Yeah. There is something called as RT reward

01:33:39.260 --> 01:33:40.600
trainer.

01:33:42.300 --> 01:33:48.760
There is something called as DPO, DPO trainer. So it's

01:33:48.760 --> 01:33:54.360
called as direct D I R E C T direct preference optimization,

01:33:57.380 --> 01:33:59.620
preference optimization.

01:34:04.600 --> 01:34:08.260
There is something called as O

01:34:11.230 --> 01:34:16.890
R P O. What is the meaning of this? So basically like a.

01:34:16.890 --> 01:34:21.750
It's, it's more like a DP one, but basically optimized one

01:34:21.750 --> 01:34:25.890
optimized one, basically. So online DPU, you can say O R P O

01:34:25.890 --> 01:34:33.530
it's called as online, online DPO right now. So these are

01:34:33.530 --> 01:34:36.030
the different, different kinds of training that we try to

01:34:36.030 --> 01:34:40.170
perform now. How does, how does this matter basically,

01:34:40.290 --> 01:34:43.210
right? How does this matter by the way, and, uh, which one

01:34:43.210 --> 01:34:47.050
I'm supposed to choose in which situation. Okay. So let's

01:34:47.050 --> 01:34:49.970
try to understand this part. And then I'm going to talk

01:34:49.970 --> 01:34:54.230
about, uh, open AI model. So to train the open AI model, you

01:34:54.230 --> 01:34:57.290
have to prepare the data first of all. So let's try to

01:34:57.290 --> 01:34:59.690
understand. It's a very easy concept, but yeah, important

01:34:59.690 --> 01:35:03.130
one. It's a very, very easy, believe me. So the very first

01:35:03.130 --> 01:35:06.130
one, the supervised fine tuning, which you are going to do,

01:35:06.190 --> 01:35:10.410
right? Supervised fine tuning that you are going to do. So

01:35:10.410 --> 01:35:14.290
over there. So basically all of this training that I'm going

01:35:14.290 --> 01:35:16.830
to talk about. Okay. So basically we have to talk about this

01:35:16.830 --> 01:35:20.390
training things with respect to a data set preparation. So

01:35:20.390 --> 01:35:24.410
what kind of a data set we try to prepare in which kind of a

01:35:24.410 --> 01:35:27.250
training. So with respect to a data set preparation, this

01:35:27.250 --> 01:35:30.350
training approach has been divided. So let's suppose if I'm

01:35:30.350 --> 01:35:32.670
talking about a supervised training now in case of

01:35:32.670 --> 01:35:36.330
supervised training, what we try to do is, so we try to

01:35:36.330 --> 01:35:39.630
prepare our data set, which is basically a text. You can

01:35:39.630 --> 01:35:44.830
say, which is a combination of instruction, instruction plus

01:35:44.830 --> 01:35:50.110
response. Okay. As it's a supervised, right? Supervised

01:35:50.110 --> 01:35:52.350
means obviously I will be having like an input and output,

01:35:52.530 --> 01:35:57.410
right? For example, so in case of SFT, supervised training,

01:35:57.590 --> 01:36:00.050
if you are preparing your data, so you should prepare in

01:36:00.050 --> 01:36:03.190
this way, which I'm going to show you practically. So here

01:36:03.190 --> 01:36:10.810
let's suppose text question is sample question is what is

01:36:10.810 --> 01:36:15.070
AI? Let's suppose this is the question. Then you have to

01:36:15.070 --> 01:36:16.530
even prepare answer.

01:36:19.610 --> 01:36:27.250
So answer is what artificial or you can say AI is a text,

01:36:27.310 --> 01:36:30.190
something like this, right? So now here you must be able to

01:36:30.190 --> 01:36:34.710
see that we have instruction means question and we have a

01:36:34.710 --> 01:36:37.210
response. We have an answer. So this is called a supervised.

01:36:37.410 --> 01:36:39.290
This is the data that we are trying to prepare. So text,

01:36:39.370 --> 01:36:42.350
question and answer, both will be available. So whenever you

01:36:42.350 --> 01:36:45.950
are doing a SFT kind of a training, so whenever you are

01:36:45.950 --> 01:36:48.330
going to do a safety training. So you will always try to

01:36:48.330 --> 01:36:50.770
prepare in this way. How does this matter? Where I'm going

01:36:50.770 --> 01:36:52.910
to use it? Very soon I'm going to teach you practically

01:36:52.910 --> 01:36:57.790
today itself. Now there is something called as GT, right? So

01:36:57.790 --> 01:37:01.510
there is something called as a GT. Now what is the meaning

01:37:01.510 --> 01:37:06.170
of a GT? So here the meaning of a GT generic trainer is

01:37:06.170 --> 01:37:10.110
nothing but, so basically you are going to train the model,

01:37:10.290 --> 01:37:13.230
right? But it is going to be unsupervised, unsupervised

01:37:13.230 --> 01:37:17.290
means you are just going to give a text, a data, right? So

01:37:17.290 --> 01:37:28.650
here the data will be text, text means, so maybe my name is

01:37:31.660 --> 01:37:35.820
Sudhanshu, right? There is no response. It's unsupervised,

01:37:35.940 --> 01:37:39.320
right? It's completely unsupervised. So can you tell me that

01:37:39.320 --> 01:37:43.220
the training that we have done just now, is it a SFT or is

01:37:43.220 --> 01:37:46.720
it a GT? The LoRa training that we have done with the help

01:37:46.720 --> 01:37:51.020
of IMDB data set. So is it a SFT? Or is it a GT? Anyone?

01:37:54.760 --> 01:37:56.660
Yeah. Is it a SFT or is it a GT?

01:38:04.260 --> 01:38:04.880
Yes, guys.

01:38:08.190 --> 01:38:12.990
Yes. Santosh is giving me as a GT. Great. Yeah. Because what

01:38:12.990 --> 01:38:16.630
I've done, so I have just taken the text out of this IMDB

01:38:16.630 --> 01:38:19.210
data set. I'm just trying to train the model for the casual

01:38:19.210 --> 01:38:22.490
learning. So which will, Joey is saying SFT, how Joey, how

01:38:22.490 --> 01:38:25.230
it is going to be a SFT. Although my data, I have already

01:38:25.230 --> 01:38:27.590
made myself very clear, right? I'm not taking a labels,

01:38:27.670 --> 01:38:30.490
although there is a label in IMDB, I have clearly mentioned

01:38:30.490 --> 01:38:33.530
that I'm not going to take it. Right? What I'm trying to

01:38:33.530 --> 01:38:36.550
take, I'm just trying to take the text part of it. So it

01:38:36.550 --> 01:38:40.390
will be GT in case of SFT, I will be having a like a input

01:38:40.390 --> 01:38:43.350
and as well as output means X and Y both I will be having,

01:38:43.490 --> 01:38:46.310
right? So that is called as a safety supervised, supervised

01:38:46.310 --> 01:38:48.730
GT is basically unsupervised. I think we all understand

01:38:48.730 --> 01:38:52.330
meaning of supervised and unsupervised, right? Now there is

01:38:52.330 --> 01:38:54.770
something called as a reward trainer. So whenever you are

01:38:54.770 --> 01:38:59.170
trying to prepare a data set for a reward trainer for RT, so

01:38:59.170 --> 01:39:01.650
how your data set should look like, it will be very

01:39:01.650 --> 01:39:05.170
different, right? So basically the reward trainer model that

01:39:05.170 --> 01:39:09.310
you are going to train, so it will, it will always try to

01:39:09.310 --> 01:39:12.470
look for the reward, right? It will always look for maybe

01:39:12.470 --> 01:39:17.850
like a rank the output as a better or worse, right? Better

01:39:17.850 --> 01:39:22.550
and worse. So here, this is also called as RHFL. So RL,

01:39:22.550 --> 01:39:26.830
sorry, RLHF reinforcement learning with the human

01:39:26.830 --> 01:39:30.930
interference. Yeah. So generally we heard about the term

01:39:30.930 --> 01:39:37.550
called as RH, sorry, again, I'm making a mistake RLHF,

01:39:37.730 --> 01:39:40.470
right? So basically a reward learning based like a

01:39:40.470 --> 01:39:43.230
reinforcement learning based a training. So where you can

01:39:43.230 --> 01:39:46.530
try to give a human feedback. So reinforcement learning with

01:39:46.530 --> 01:39:51.570
a human feedback, RLHF basically. So how does this happen by

01:39:51.570 --> 01:39:53.870
the way, right? How does this happen? How we are going to

01:39:53.870 --> 01:39:56.650
train this model and nowadays everyone is doing, doing the

01:39:56.650 --> 01:40:00.230
same thing. So here the data set that, because everything is

01:40:00.230 --> 01:40:03.890
falls down to a data set preparation. At the end of the day,

01:40:03.930 --> 01:40:06.230
you will have to pass the data model is just architecture,

01:40:06.510 --> 01:40:09.430
right? So you have to pass the data. So the game is all

01:40:09.430 --> 01:40:12.970
about a data by the way. So here, whenever you are trying to

01:40:12.970 --> 01:40:16.410
like a train, this kind of a model, RLHF model nowadays,

01:40:16.490 --> 01:40:20.690
which everyone model is by the way, almost. So here we try

01:40:20.690 --> 01:40:24.670
to prepare a data in this way. So we have our text and let's

01:40:24.670 --> 01:40:26.790
suppose I'm writing over here. Okay.

01:40:36.250 --> 01:40:41.490
So this is

01:40:42.900 --> 01:40:45.900
basically a text, right? This is basically a text. And then

01:40:45.900 --> 01:40:49.460
along with that, so I'm going to pass a rejected text, R E J

01:40:49.460 --> 01:40:54.740
E C T E D rejected underscore text, right? Just to counter

01:40:54.740 --> 01:41:01.560
this text basically. Right? So. In. Some. Of. The.

01:41:04.230 --> 01:41:10.490
Subject. He. Is. Not. Good. Yeah. So basically just to

01:41:10.490 --> 01:41:12.650
counter, so Nanshu is a good teacher. Now the rejected text

01:41:12.650 --> 01:41:17.270
is what in some of the subject, he is not good. Yeah. So not

01:41:17.270 --> 01:41:19.330
good. So is it like a reinforcement? Exactly. I'm talking

01:41:19.330 --> 01:41:21.310
about the reinforcement actually. So reinforcement learning

01:41:21.310 --> 01:41:23.790
with the human feedback. So this is the feedback. This is

01:41:23.790 --> 01:41:26.630
the feedback. The second line, which I'm trying to pass is

01:41:26.630 --> 01:41:31.150
technically a feedback. Right? So that basically it will be

01:41:31.150 --> 01:41:36.830
able to get some sort of a reward learning over here. Now

01:41:38.490 --> 01:41:42.110
there is something called as a DPO, direct preferences

01:41:42.110 --> 01:41:45.910
optimization. So how do we prepare our data in terms of our

01:41:45.910 --> 01:41:50.470
direct preference optimization? So here, basically for this

01:41:50.470 --> 01:41:57.290
DPO, we try to prepare data, right? So basically what is the

01:41:57.290 --> 01:42:00.670
goal of this DPO? So the goal of this DPO is learning. Learn

01:42:00.670 --> 01:42:05.330
basically a policy that prefers a human preferred output. So

01:42:05.330 --> 01:42:07.910
that is basically goal. So here, whenever we've tried to

01:42:07.910 --> 01:42:10.270
prepare the data, so here we'll be having three parameters.

01:42:10.670 --> 01:42:15.650
So let's suppose prompt, P-R-O-M-P-T, prompt. And let's

01:42:15.650 --> 01:42:21.910
suppose I'm writing, what is a changes

01:42:23.580 --> 01:42:33.140
in class schedule for gen AI. Let's suppose this is my

01:42:33.140 --> 01:42:35.640
prompt. Yeah. So what is the changes in a class schedule for

01:42:35.640 --> 01:42:41.440
a generative AI? Okay. Now there will be a text. There will

01:42:41.440 --> 01:42:46.100
be a text, right? So here, not

01:42:48.280 --> 01:43:00.750
much. It's same, but just changed for a week. Let's suppose

01:43:00.750 --> 01:43:06.330
this is my text. And then here we try to mention rejected

01:43:06.330 --> 01:43:10.650
text. So whatever we have mentioned in RLHF. So R-E-J-E-C-T

01:43:10.650 --> 01:43:16.690
-E-D rejected underscore text, yeah, rejected text. So are

01:43:20.150 --> 01:43:37.370
you talking about a time changes in gen AI, right? So here,

01:43:37.430 --> 01:43:39.830
as you can see that we try to pass three things, prompt,

01:43:39.990 --> 01:43:43.090
text, and the rejected text. So here, basically it's the

01:43:43.090 --> 01:43:46.610
goal, like I said, in a beginning itself, that the objective

01:43:46.610 --> 01:43:49.850
of DPO training. So direct preference optimization training

01:43:49.850 --> 01:43:54.090
is a very simple. So it will always try to learn the policy,

01:43:54.310 --> 01:43:57.430
right? It will always try to learn the policy. So which

01:43:57.430 --> 01:44:01.550
will, which will be like a going up preference to a human

01:44:01.550 --> 01:44:04.830
output. So human preferred output, basically. So here, like,

01:44:04.890 --> 01:44:07.710
I'm just trying to ask like a prompt and based on the

01:44:07.710 --> 01:44:10.850
prompt, there is a text and there is a rejected text as

01:44:10.850 --> 01:44:13.650
well. Right? So based on the quotient, it is going to give

01:44:13.650 --> 01:44:16.490
me answer. And then while giving an answer, it will also try

01:44:16.490 --> 01:44:19.470
to like check that whether it falls in the rejected text or

01:44:19.470 --> 01:44:25.390
not. So here now, so this, this one is going to be much

01:44:25.390 --> 01:44:29.390
faster than RLHF basically. So this one is basically like a

01:44:29.390 --> 01:44:32.570
much faster than RLHF that we will be able to find out in

01:44:32.570 --> 01:44:36.430
that one, the previous one, RT. Now there is something

01:44:36.430 --> 01:44:39.890
called as online DPO. So online DPO, what it does. So same

01:44:39.890 --> 01:44:44.070
as the before. Very different. I would say. Right. But yeah,

01:44:44.190 --> 01:44:48.030
so it will be like a faster to like update basically. So it

01:44:48.030 --> 01:44:51.770
is always going to work with the streaming data as simple as

01:44:51.770 --> 01:44:54.270
that, right? So basically it has been optimized for the

01:44:54.270 --> 01:44:55.950
streaming data and it is always going to work for the

01:44:55.950 --> 01:44:59.410
streaming data. That is something called as ORPO. Now why,

01:44:59.450 --> 01:45:03.270
why I talked about it and where this terms are going to come

01:45:03.270 --> 01:45:05.850
now, my handwriting is very bad guys. I'll try to prepare

01:45:05.850 --> 01:45:09.690
the entire document and then upload, uh, today I think it's

01:45:09.690 --> 01:45:15.750
worse. I don't know why. Yeah. So these are the different,

01:45:15.810 --> 01:45:17.930
different, like a type of the model that we can try to

01:45:17.930 --> 01:45:22.990
train. Now what I will do is I will try to go to a platform

01:45:22.990 --> 01:45:27.870
.openai.com. So please go to platform.openai.com. If you

01:45:27.870 --> 01:45:29.470
don't have an account, please try to create one.

01:45:39.360 --> 01:45:44.440
Yeah. So just go to an open AI and here, so what we will do,

01:45:44.500 --> 01:45:47.600
so go to your dashboard, by the way. So inside our

01:45:47.600 --> 01:45:51.180
dashboard, you will be able to find out. Yeah. Uh, one, uh,

01:45:51.400 --> 01:45:55.040
tab, one section called as fine tuning. Yeah. You will be

01:45:55.040 --> 01:45:57.760
able to find out a section called as fine tuning. Now here

01:45:57.760 --> 01:46:00.680
you can try to call all of these things with the help of

01:46:00.680 --> 01:46:04.660
API's part number one. Uh, and then you can do a fine

01:46:04.660 --> 01:46:09.020
tuning. Otherwise open AI is providing you a dashboard. So

01:46:09.020 --> 01:46:11.460
from a dashboard itself, with the help of UI, you will be

01:46:11.460 --> 01:46:14.080
able to do a fine tuning and I'll show you how to do a fine

01:46:14.080 --> 01:46:16.660
tuning quickly, right? Quickly how I will be able to do a

01:46:16.660 --> 01:46:20.520
fine tuning. So here click on this fine tuning. And then

01:46:20.520 --> 01:46:24.180
click on this create. So click on create. Now once you are

01:46:24.180 --> 01:46:27.640
going to create, you have to select a method. So which

01:46:27.640 --> 01:46:31.800
method you would like to prefer? So see, supervise DPO or

01:46:31.800 --> 01:46:37.280
RF. This is something which I just talked about, right? So

01:46:37.280 --> 01:46:40.080
what is the meaning of a DPO? What is the meaning of a SFT?

01:46:40.240 --> 01:46:42.380
What is the meaning of a generic or what is the meaning of

01:46:42.380 --> 01:46:45.780
basically reward trainer? So basically RLHF, right? So

01:46:45.780 --> 01:46:49.160
whenever you are trying to go ahead with the training. So

01:46:49.160 --> 01:46:51.620
let's suppose. If I'm doing a supervise, so I should prepare

01:46:51.620 --> 01:46:55.500
a data as per supervised training. If I'm going for the DPO,

01:46:55.620 --> 01:46:59.400
I should prepare a data as per DPO. If I'm doing a RLHF, so

01:46:59.400 --> 01:47:02.520
I should prepare a data as per RLHF. That's the reason. So I

01:47:02.520 --> 01:47:06.560
talked about those things, right? And again, you just have

01:47:06.560 --> 01:47:09.360
to like know about it again, data preparation wise, you can

01:47:09.360 --> 01:47:11.520
prepare it with the help of like couple of line of code.

01:47:11.780 --> 01:47:15.980
Yeah. So here you can try it. I can select a supervised. Now

01:47:15.980 --> 01:47:19.500
here you will be able to find out almost all the models.

01:47:19.500 --> 01:47:22.780
Plus you will be able to find out the model, which I have

01:47:22.780 --> 01:47:26.380
fine tuned. Yeah. All the list of the models. So I have fine

01:47:26.380 --> 01:47:28.820
tuned some model. And on top of that, again, I can fine

01:47:28.820 --> 01:47:31.420
tune. That's completely fine, right? That's completely fine.

01:47:31.580 --> 01:47:35.920
So I can like find all the models. So I can try to like, you

01:47:35.920 --> 01:47:39.200
know, fine tune any of these models, which is available over

01:47:39.200 --> 01:47:42.560
here with respect to supervise with respect to DPO. So

01:47:42.560 --> 01:47:44.660
again, it is going to give you a list. So with respect to

01:47:44.660 --> 01:47:47.680
DPO, only these main models are available with respect to

01:47:47.680 --> 01:47:52.300
RLHF. So only this model Omni is available, right? Omni is

01:47:52.300 --> 01:47:55.400
available. Apart from that, none is available. Now these

01:47:55.400 --> 01:47:58.460
part is important because accordingly you have to prepare

01:47:58.460 --> 01:48:01.180
the data, whatever data based on that you are doing a fine

01:48:01.180 --> 01:48:03.200
tuning, you have to prepare that data accordingly. Otherwise

01:48:03.200 --> 01:48:06.640
it will not work means it will not work very simple. So base

01:48:06.640 --> 01:48:11.060
model. Okay. So here I'm going to take maybe a, like a turbo

01:48:11.060 --> 01:48:15.480
3.5, any, anything I can take anyone, maybe like I can even

01:48:15.480 --> 01:48:18.700
like a train four. Let's see. This is the latest one I can,

01:48:18.720 --> 01:48:21.640
I can try to train it. So maybe nano mini, whatever I want.

01:48:21.800 --> 01:48:25.420
So maybe let's take nano yeah. Then suffix. So here I can

01:48:25.420 --> 01:48:33.300
try to give a name. So my training, okay. Now seed random

01:48:33.300 --> 01:48:36.380
sub random number, just try to place it over here. The major

01:48:36.380 --> 01:48:40.920
part is a data preparation and see it is trying to look for

01:48:40.920 --> 01:48:47.320
what J S O N L file. So JSON L file you have to provide.

01:48:47.580 --> 01:48:51.320
Then only it is going to work. And that too in a proper

01:48:51.320 --> 01:48:54.920
format as per your method selection, if you are not doing

01:48:54.920 --> 01:48:58.260
it, it is not going to work. You will not be able to do a

01:48:58.260 --> 01:49:01.920
fine tuning. So I'm doing a supervised, right? I'm doing a

01:49:01.920 --> 01:49:04.480
supervised and I have already discussed what should be the

01:49:04.480 --> 01:49:07.740
type of the data. So I'm doing basically SFT by the way, I'm

01:49:07.740 --> 01:49:10.020
doing SFT. So I know that, that there will be instruction,

01:49:10.300 --> 01:49:12.160
there will be a response. So in this manner, I have to

01:49:12.160 --> 01:49:15.560
prepare the data at the end of the day, and then I have to

01:49:15.560 --> 01:49:20.560
save my data with a extension. Again, with a extension. J S

01:49:20.560 --> 01:49:24.280
O N L. So this is what I have done. Let me show you that

01:49:24.280 --> 01:49:28.460
part. So here is my data. As you can see guys, right here is

01:49:28.460 --> 01:49:32.280
my data. So I have prepared my data the way system will be

01:49:32.280 --> 01:49:36.880
looking for, right? So here content, what is AI, right? And

01:49:36.880 --> 01:49:40.220
then I'm trying to like give a content. So AI stands for

01:49:40.220 --> 01:49:42.500
artificial intelligence, refer to the machine that mimic the

01:49:42.500 --> 01:49:47.600
human intelligence and prefer perform the task. So question,

01:49:47.700 --> 01:49:51.760
answer, question, answer, question, answer. Right? So in

01:49:51.760 --> 01:49:55.800
this manner, I have just prepared the entire content and

01:49:55.800 --> 01:49:59.620
then eventually I have saved this entire content, right?

01:49:59.920 --> 01:50:03.500
Entire content. So see here, the role is user and the role

01:50:03.500 --> 01:50:05.920
is assistant. So user will ask this. So this is how it will

01:50:05.920 --> 01:50:08.200
be able to understand that it is supervised. So this is a

01:50:08.200 --> 01:50:11.020
question and assistant will answer. User will ask question,

01:50:11.160 --> 01:50:12.920
assistant will answer, user will ask question, assistant

01:50:12.920 --> 01:50:16.220
will answer. So in this manner, we have to prepare the

01:50:16.220 --> 01:50:19.600
complete data set and this data set, unless, unless you're

01:50:19.600 --> 01:50:22.620
not preparing for this, it is not going to work, right? It

01:50:22.620 --> 01:50:25.160
will reject all the time and many people get confused even

01:50:25.160 --> 01:50:29.080
over there. So here I have prepared the data set and then

01:50:29.080 --> 01:50:32.720
that is the first part. Then you have to save it in a not

01:50:32.720 --> 01:50:37.500
JSON, JSON, JSON L basically. So in a JSON L format, you

01:50:37.500 --> 01:50:41.520
have to save this particular data set. So I'm just giving

01:50:41.520 --> 01:50:44.600
you this data. So let's take this data, right? I have

01:50:44.600 --> 01:50:47.520
already pinged you inside your chat box. So you can take

01:50:47.520 --> 01:50:50.880
this data. Now save with any name. Name can be anything.

01:50:51.000 --> 01:50:53.360
Data or your name, my name, doesn't matter. Extension should

01:50:53.360 --> 01:50:57.280
be JSON L, always, right, always as per the instruction

01:50:57.280 --> 01:51:00.680
given over here. So I can just click and then I can try to

01:51:00.680 --> 01:51:04.980
upload a data, JSON L, 3kb file. And one more thing, a

01:51:04.980 --> 01:51:08.180
minimum 10 data is required, minimum, less than 10 if you're

01:51:08.180 --> 01:51:10.800
going to pass, again it will fail. Yeah. Minimum 10 data is

01:51:10.800 --> 01:51:15.340
required. So here JSON L and then I'm going to upload it.

01:51:15.420 --> 01:51:19.220
See my data set is uploaded. Yeah, my data set is uploaded

01:51:19.220 --> 01:51:22.480
over here. And then my

01:51:24.720 --> 01:51:27.180
previous data and this data is same. So because of that, it

01:51:27.180 --> 01:51:31.320
is like giving me this one, like select existing. So I have

01:51:31.320 --> 01:51:34.120
already uploaded the same data, right? Because of that, it

01:51:34.120 --> 01:51:39.560
is like giving me this one. Maybe I can try to show you by

01:51:39.560 --> 01:51:48.000
creating new file. So new file, data1.JSONL. JSON L. And in

01:51:48.000 --> 01:51:54.780
data one. I'll try to like, take this one. And maybe I'll

01:51:54.780 --> 01:52:00.180
try to copy couple of more, yeah, couple of more record. So

01:52:00.180 --> 01:52:06.660
data1.JSON and I'll try to like now upload new data one. And

01:52:06.660 --> 01:52:09.300
now it will show you here. Yeah. So it's like, I think,

01:52:09.300 --> 01:52:13.380
yeah, it's, it's been uploaded now. So no,

01:52:16.510 --> 01:52:19.130
I'm not going to use anything configuration parameters. So

01:52:19.130 --> 01:52:22.470
batch size, you can try to customize it. If you want. So if

01:52:22.470 --> 01:52:24.370
you would like to change the batch size, you can try to

01:52:24.370 --> 01:52:26.390
control it. I believe we all know what is the meaning of

01:52:26.390 --> 01:52:29.270
batch size, by the way. So auto means automatically will

01:52:29.270 --> 01:52:31.370
choose, otherwise you can configure it, learning rate

01:52:31.370 --> 01:52:35.530
multiplier. So you can again, configure this one. So in most

01:52:35.530 --> 01:52:37.790
of the cases, range will be this to this right recommended

01:52:37.790 --> 01:52:41.450
now. So you can keep it in auto number of epoch for which

01:52:41.450 --> 01:52:43.690
you would like to train this. So you can try to control

01:52:43.690 --> 01:52:47.130
everything. So whatever that for that you write a code,

01:52:47.290 --> 01:52:51.550
everything, you can do it just by selecting. This. This

01:52:51.550 --> 01:52:54.110
component does by selecting this component. Now once this is

01:52:54.110 --> 01:52:57.690
done, click on create, right? Click on create. And if

01:52:57.690 --> 01:53:01.050
everything is good data, just on it has taken. So it will

01:53:01.050 --> 01:53:05.110
start validating the file, whether this file is as per your

01:53:05.110 --> 01:53:10.050
SFT or not supervised training, fine tuning or not. If it

01:53:10.050 --> 01:53:12.290
does not, then it will go give you immediately the error.

01:53:12.490 --> 01:53:15.350
And if everything is fine, then in that case, it is going to

01:53:15.350 --> 01:53:18.470
start training the model. It will not take more than two,

01:53:18.550 --> 01:53:20.950
three minutes of time. I have a very small data. And I'm

01:53:20.950 --> 01:53:24.690
training it on a like open ID source itself. So it is not

01:53:24.690 --> 01:53:27.350
going to take more than one or two minute of time, but

01:53:27.350 --> 01:53:29.950
obviously it is going to charge me. It is going to build me

01:53:29.950 --> 01:53:31.150
basically.

01:53:33.130 --> 01:53:36.410
Now I got the meaning of SFT. Yeah. Supervised fine tuning

01:53:36.410 --> 01:53:40.450
by the way. So are you able to do it guys, anyone who is

01:53:40.450 --> 01:53:44.270
doing it with me and can I, can I say that it's very easy to

01:53:44.270 --> 01:53:47.310
do a fine tuning. Now you can do a fine tuning with any of

01:53:47.310 --> 01:53:52.670
your data set. Yeah. Just take any data set, maybe your

01:53:52.670 --> 01:53:55.490
finance data set, maybe your HR data set, anything right and

01:53:55.490 --> 01:53:59.730
pass some sample of this data set to maybe a URI and just

01:53:59.730 --> 01:54:02.810
ask URI that can you please try to give me a script which

01:54:02.810 --> 01:54:06.290
can read this data and convert it into this format means a

01:54:06.290 --> 01:54:09.930
format which I can use for a supervised SFT for my GPT.

01:54:10.510 --> 01:54:13.010
Yeah. So what it will do, it will try to give you the

01:54:13.010 --> 01:54:15.970
script, Python script. So it doesn't matter how much data

01:54:15.970 --> 01:54:19.330
you have. Maybe you have a tons of data, right? It will be

01:54:19.330 --> 01:54:22.450
able to prepare and just pass the data and you can do the

01:54:22.450 --> 01:54:24.310
fine tuning and then you can go and show it to a manager

01:54:24.310 --> 01:54:28.410
that, okay, this is the new model, take it and just ask any

01:54:28.410 --> 01:54:33.500
question that you want. Yeah. So see fine tuning is

01:54:33.500 --> 01:54:37.080
happening and two, three minutes it will take. So see like a

01:54:37.080 --> 01:54:39.700
fine tuning job has started then validation, then matrixes

01:54:39.700 --> 01:54:42.380
also. Yeah. The beautiful part is it will show you the

01:54:42.380 --> 01:54:45.540
graph. I'll show you like just wait for some time. Yeah. It

01:54:45.540 --> 01:54:47.100
will show you the entire graph curve.

01:54:50.700 --> 01:54:54.140
It's paid or free. Obviously. Why do you charge you like a,

01:54:54.140 --> 01:54:56.000
this open AI, why

01:55:00.320 --> 01:55:04.020
you think that everything should be free? So like, like I

01:55:04.020 --> 01:55:06.780
said in the beginning, I think, I think I talked about the

01:55:06.780 --> 01:55:10.120
same thing in my previous class that generally we never

01:55:10.120 --> 01:55:14.120
hesitate to like, you know, spend like a thousand thousand

01:55:14.120 --> 01:55:18.980
so rupees for like a partying or maybe giving a gift to a

01:55:18.980 --> 01:55:21.860
girlfriend or some X, Y, G things. But when it comes to

01:55:21.860 --> 01:55:26.280
learning, I have seen that people even hesitate to apply

01:55:26.280 --> 01:55:30.020
their card on AWS. And then the thing that they will be able

01:55:30.020 --> 01:55:31.920
to learn the real thing, it's, it's not going to happen. So

01:55:31.920 --> 01:55:35.560
if you're a serious learner, at least to spend five, $10,

01:55:35.580 --> 01:55:39.700
right. On these platforms, because the kind of a learning

01:55:39.700 --> 01:55:42.840
that you will be able to get will be a lifetime and those

01:55:42.840 --> 01:55:48.380
investment of five or $10 will give you a million dollar

01:55:48.380 --> 01:55:51.020
return. But the investment that you are doing on your

01:55:51.020 --> 01:55:53.880
girlfriend, maybe on a party, I'm not saying that don't do

01:55:53.880 --> 01:55:56.980
it, do it. Obviously that is also important. Yeah. Obviously

01:55:56.980 --> 01:56:00.020
as a human being, you have to like enjoy a life. You have to

01:56:00.020 --> 01:56:03.960
chill out, right. Because this is how we human works, right.

01:56:04.800 --> 01:56:09.340
But if you are compromising with five, $10 on AWS and then

01:56:09.340 --> 01:56:12.540
GCP or taking a Jio subscription, taking a OpenAI

01:56:12.540 --> 01:56:14.860
subscription, then that's not good. Then you are not a

01:56:14.860 --> 01:56:15.320
serious learner.

01:56:18.970 --> 01:56:22.830
Yeah. So now you can see it's illustrating and now we have a

01:56:22.830 --> 01:56:26.150
graph. So loss is decreasing with respect to my data loss is

01:56:26.150 --> 01:56:29.710
decreasing, accuracy is increasing. It's still, it is into

01:56:29.710 --> 01:56:32.770
us. It's still a training phase. Yeah. It's still, it is

01:56:32.770 --> 01:56:36.310
into a training phase. Just wait for some time. Fine tuning.

01:56:36.590 --> 01:56:39.390
Right. And my model will be available. I can consume my

01:56:39.390 --> 01:56:42.690
model just like a GPT model. Just like a GPT model. So just,

01:56:42.730 --> 01:56:45.370
I have to change my model ID. I have to give a model ID of

01:56:45.370 --> 01:56:45.970
fine tune model.

01:56:49.150 --> 01:56:52.910
Yes. So now like, as you can see, accuracy is almost tending

01:56:52.910 --> 01:56:57.690
to a hundred percent on steps. This one train accuracy and a

01:56:57.690 --> 01:57:01.090
loss has decreased down to this one is still fine tuning is

01:57:01.090 --> 01:57:05.640
going on. So anyone guys who is doing it with me, anyone,

01:57:05.760 --> 01:57:11.070
not even a single, that's sad because

01:57:23.390 --> 01:57:26.230
these are the real time, real thing, real time stuff,

01:57:26.450 --> 01:57:28.810
basically. So if you can, because whenever you will go for

01:57:28.810 --> 01:57:31.190
an interview, you will mention these things that I do these

01:57:31.190 --> 01:57:34.010
kinds of things on a regular basis, people will be amazed

01:57:34.010 --> 01:57:40.130
and they're going to hire you otherwise, like things will go

01:57:40.130 --> 01:57:44.190
in a different way. So now successfully, right? Successfully

01:57:44.190 --> 01:57:46.750
file validated, moving job to a QA state, validated

01:57:46.750 --> 01:57:48.630
training. Yeah. This, this, this, this created fine tuning

01:57:48.630 --> 01:57:52.890
job. Now everything is done. I can click on playground,

01:57:53.170 --> 01:57:57.550
right? I can click on playground and I can even try to test

01:57:57.550 --> 01:58:01.670
it. Yeah. I can even try to test it. So see, this is my fine

01:58:01.670 --> 01:58:06.050
tune model, FT, FT GPT for nano, right? This is my fine tune

01:58:06.050 --> 01:58:08.970
model. By the way, I can try to maintain my temperature. I

01:58:08.970 --> 01:58:11.450
can try to maintain maximum token each and everything. And

01:58:11.450 --> 01:58:16.610
then I can start chatting with this one. And maybe I can

01:58:16.610 --> 01:58:21.030
look into my data. The data set, which I have given. So data

01:58:21.030 --> 01:58:23.970
set was what is a black hole? What is a Newton's third law

01:58:23.970 --> 01:58:27.890
summarize the summarize the water cycle. Yeah. Maybe what

01:58:27.890 --> 01:58:29.810
kind of water cycle? I don't know. Summarize the water

01:58:29.810 --> 01:58:32.570
cycle. Maybe I can ask this kind of a question, which, which

01:58:32.570 --> 01:58:38.190
was available. And here, this is the response. So summarize

01:58:38.190 --> 01:58:40.410
the water cycle. Our water cycle includes a evaporation,

01:58:40.450 --> 01:58:42.950
condensation, dissipation and collaboration. Water moves

01:58:42.950 --> 01:58:46.610
continuously through this stage. And now here I can give a

01:58:46.610 --> 01:58:49.490
human feedback. Okay. That's good. Okay. Tell us what you

01:58:49.490 --> 01:58:52.390
would like to response. How? So this is a response that I'm

01:58:52.390 --> 01:58:57.510
getting from my fine tuned model. Yeah. And here, so I can

01:58:57.510 --> 01:58:59.910
try to even give a system message. This is my own model,

01:59:00.010 --> 01:59:03.250
right? This is my newly created fine tune model. So I can

01:59:03.250 --> 01:59:07.170
try to give a, like a, I can try to set a tone. I can try to

01:59:07.170 --> 01:59:10.090
set a tool uses a response style that what kind of a

01:59:10.090 --> 01:59:12.970
response you should give at the end of the day, detailed

01:59:12.970 --> 01:59:16.870
one, a sort one, whatever. Right? So see, user is asking

01:59:16.870 --> 01:59:19.390
this question. And assistant is giving this answer now go

01:59:19.390 --> 01:59:23.090
and check. So assist. So what was the answer by the way, for

01:59:23.090 --> 01:59:26.750
this one, the water cycle include the evaporation, a

01:59:26.750 --> 01:59:29.130
condensation, this, this, this, this, this, and water moves

01:59:29.130 --> 01:59:33.210
continuously through these stages. Yeah. As we move through

01:59:33.210 --> 01:59:36.050
this system is so yes, it is able to understand it is, it is

01:59:36.050 --> 01:59:38.810
able to like a give me an answer, summarize our water cycle.

01:59:39.010 --> 01:59:44.950
Now what is water cycle? This question was not available,

01:59:45.170 --> 01:59:48.330
right? This question was not available. Okay. Now the water

01:59:48.330 --> 01:59:50.950
cycle is a continuous movement of a water on earth,

01:59:51.030 --> 01:59:53.350
including the process like a evaporation. So see now it is

01:59:53.350 --> 01:59:56.730
able to change the format. This is not the exact. This was

01:59:56.730 --> 01:59:59.430
not the exact question. And this was not an exact answer,

01:59:59.550 --> 02:00:02.970
which was available. So my model is able to do a fine tuning

02:00:02.970 --> 02:00:07.130
and as a part of fine tuning, it is able to understand like

02:00:07.130 --> 02:00:12.070
my context. This is the one. And this is from basically

02:00:12.070 --> 02:00:15.930
what, so this is basically from your GPT, the original one,

02:00:15.930 --> 02:00:19.190
right? And this is from my fine tuned one. So I'm able to

02:00:19.190 --> 02:00:22.910
see that yes, my fine tuned model is able to understand the

02:00:22.910 --> 02:00:25.730
context and based on that context, it is able to give me the

02:00:25.730 --> 02:00:29.970
answer. So my fine tuning is now successful. Can I say that

02:00:29.970 --> 02:00:30.170
guys?

02:00:43.350 --> 02:00:46.190
So Mohit is asking me a question that, sir, I wanted to

02:00:46.190 --> 02:00:49.710
know, how do you know the data you are using in fine-tuning

02:00:49.710 --> 02:00:53.930
GPT-1, nano model is similar to the data on which model is

02:00:53.930 --> 02:00:55.950
pre-trained so that after fine tuning it perform

02:00:55.950 --> 02:01:00.210
effectively. Okay. So. So basically guys see, there is a

02:01:00.210 --> 02:01:03.130
document you will be able to find out for any models, right?

02:01:03.190 --> 02:01:06.450
Obviously you have to go through a document now here inside

02:01:06.450 --> 02:01:09.570
a document, if you'll come down. So there is a fine tuning

02:01:09.570 --> 02:01:12.930
tab. You have to follow along with that. Now see here, they

02:01:12.930 --> 02:01:16.110
have, I talked about SFT, right? I talked about a DPO. I

02:01:16.110 --> 02:01:18.930
talked about RFT. All these things are mentioned over here.

02:01:19.010 --> 02:01:22.170
Plus they have also mentioned, if you will come over here,

02:01:22.210 --> 02:01:24.350
supervised fine tuning, right? Supervised fine tuning. So

02:01:24.350 --> 02:01:26.730
you will be able to see that they have also mentioned the

02:01:26.730 --> 02:01:30.890
data format. See data format. Yeah. This is a different

02:01:30.890 --> 02:01:32.850
data. I have taken a different data, but format is same.

02:01:33.410 --> 02:01:36.630
Yeah. Format is same. So you have to go through a

02:01:36.630 --> 02:01:39.150
documentation. That's the reason. So whoever is going to

02:01:39.150 --> 02:01:42.130
release whatever model, they release a proper documentation

02:01:42.130 --> 02:01:45.510
as well. Yeah. There is a proper documentation. And we, as a

02:01:45.510 --> 02:01:47.890
techie, we always try to follow the official documentation

02:01:47.890 --> 02:01:51.150
that, okay, fine. So this is like a format, whenever I'm

02:01:51.150 --> 02:01:54.070
preparing it, let's, let's prepare it on that way. So I'm

02:01:54.070 --> 02:01:58.470
able to make your, like give your answer. Okay. Okay. So if

02:01:58.470 --> 02:02:00.650
someone has sent me trained method, supervised this, this,

02:02:00.670 --> 02:02:04.090
this, this, this, this. Okay. So great. Eric, you are, you

02:02:04.090 --> 02:02:07.650
are able to do the training. Amazing. Amarnath is saying

02:02:07.650 --> 02:02:10.830
network interruption earlier, consider this, you know, I'm

02:02:10.830 --> 02:02:13.010
going to work in a medical related task and I need to

02:02:13.010 --> 02:02:15.450
prepare the data in the medical domain. There are various

02:02:15.450 --> 02:02:17.870
categories such as this, this, this, this, this, this will

02:02:17.870 --> 02:02:20.650
provide the labels for, see Amarnath. This is what I was

02:02:20.650 --> 02:02:24.990
trying to teach you, right? That if I'm using SFT, right? If

02:02:24.990 --> 02:02:28.350
I'm using SFT, then what is the data format? If I'm using a

02:02:28.350 --> 02:02:29.570
data format. If I'm using a DPO, what is the data format?

02:02:29.670 --> 02:02:32.290
And if I'm using a RF, then what is the data format? That is

02:02:32.290 --> 02:02:34.430
the reason. So I have explained you this one. So it doesn't

02:02:34.430 --> 02:02:37.330
matter for which domain you are working, the things which

02:02:37.330 --> 02:02:40.190
matters is what, what kind of a training you are doing.

02:02:42.320 --> 02:02:48.540
Okay. Great Eric. Amazing. Got it. Amarnath doesn't matter

02:02:48.540 --> 02:02:51.260
whether you are training it for oncology or dermatology or

02:02:51.260 --> 02:02:54.380
anything, what kind of a training you are trying to do,

02:02:54.460 --> 02:02:58.200
model will try to understand. See for model, text is text.

02:02:58.380 --> 02:03:02.260
Simple. This department, that department doesn't matter at

02:03:02.260 --> 02:03:06.520
all. It's just a text. It's a LLM, right? Just a LLM. So it

02:03:06.520 --> 02:03:09.780
is like a, not going to bother your departments. Technically

02:03:09.780 --> 02:03:13.000
it is going to bother that kind of a training that you are

02:03:13.000 --> 02:03:15.560
going to do. And accordingly you had to prepare the data. So

02:03:15.560 --> 02:03:19.380
for SFT, I'm showing you, and for all the other format, I

02:03:19.380 --> 02:03:21.980
have written that right for GT. This is the format for RT.

02:03:22.100 --> 02:03:25.680
This is the format for DPO. This is the format for RPO means

02:03:25.680 --> 02:03:29.060
online DPO. So this is the format. Yeah. And same thing you

02:03:29.060 --> 02:03:32.280
will be able to find out even inside that documentation. You

02:03:32.280 --> 02:03:35.600
will find less over here by the way. Right. I talked more.

02:03:36.160 --> 02:03:38.340
So because they are giving you only three options, but

02:03:38.340 --> 02:03:43.700
technically there are more options. Got it Amarnath, I'm

02:03:43.700 --> 02:03:47.060
able to answer your question. Yeah. So for reinforcement

02:03:47.060 --> 02:03:49.820
again, which, what kind of a data it is going to take, they

02:03:49.820 --> 02:03:52.460
have given you the data side. See, this is the data sample

02:03:52.460 --> 02:03:55.320
data they have given you. Right. So I will be using this

02:03:55.320 --> 02:03:57.520
one. And this is, this is coming from my discussion.

02:03:58.060 --> 02:03:58.920
Discussion that I've done.

02:04:02.520 --> 02:04:05.900
Okay. Not, not an issue. Yeah. Thanks Amarnath. Okay. So I'm

02:04:05.900 --> 02:04:08.620
able to do a training as you can see, and I'm able to do a

02:04:08.620 --> 02:04:10.920
testing as well. Right. This fine tuning model, I'm able to

02:04:10.920 --> 02:04:15.880
do a testing and maybe I can try to like save it basically.

02:04:16.060 --> 02:04:19.600
So name and descriptions are not a prompt by the way. Right.

02:04:20.320 --> 02:04:24.980
And I can, I can try to like, you know, create an API and

02:04:24.980 --> 02:04:27.600
then I can try to like consume this model. I can try to host

02:04:27.600 --> 02:04:31.080
this model anywhere I want. Because this is my now own

02:04:31.080 --> 02:04:35.720
private fine tuned model on GPT as simple as that. So

02:04:35.720 --> 02:04:39.880
likewise, I can try to train as many things as I want. Now

02:04:39.880 --> 02:04:46.660
let me check how much, how many, how much like a money it

02:04:46.660 --> 02:04:51.900
took. So billing, how much balance I have, Oh, it's, it has

02:04:51.900 --> 02:04:56.260
not even taken like a cent, I would say. So it was, it was

02:04:56.260 --> 02:04:56.740
like a.

02:05:00.700 --> 02:05:05.680
Oh. So I had like $350 in my account, uh, in morning and I

02:05:05.680 --> 02:05:10.700
think, yeah, so $348 only, which is like $2 consumption. Not

02:05:10.700 --> 02:05:15.980
much. Yes. So users wise, I can go and check the users that

02:05:15.980 --> 02:05:20.100
what was the actual users like, uh, yeah, it was, it was

02:05:20.100 --> 02:05:24.620
very less June 8 today. So $1.25, not much. So only a

02:05:24.620 --> 02:05:27.860
hundred rupees around like 110 rupees. So this is the only

02:05:27.860 --> 02:05:30.980
thing that they do. Oh. This is the only like a kind of a

02:05:30.980 --> 02:05:34.620
money takes guys only a hundred rupees, right? Uh, to see

02:05:34.620 --> 02:05:38.180
something in real. And if you're, if you're not doing it

02:05:38.180 --> 02:05:41.620
simply means that you are missing a big part of the life,

02:05:41.760 --> 02:05:46.060
the real life, right? Uh, so I, I recommend everyone that at

02:05:46.060 --> 02:05:49.320
least, uh, try to invest a hundred, 200, 500 thousand rupees

02:05:49.320 --> 02:05:53.280
because we, we all do that kind of investment on like

02:05:53.280 --> 02:05:56.840
unnecessary things. So do it here as well. It will give you

02:05:56.840 --> 02:05:58.360
like some, uh, fruitful result.

02:06:01.130 --> 02:06:04.190
In general prompt, we also give some example and ask the

02:06:04.190 --> 02:06:06.350
question, referring to the example, that example are also

02:06:06.350 --> 02:06:12.150
kind of, uh, fine tuning as well. Right? Yes. Yeah. Now, so

02:06:12.150 --> 02:06:15.210
this is done. Uh, so now we are able to understand that how

02:06:15.210 --> 02:06:18.730
we can do a fine tuning supervise. Now similarly, you can go

02:06:18.730 --> 02:06:20.670
with a direct, similarly, you can go with the reinforcement

02:06:20.670 --> 02:06:24.250
learning. Uh, now we know that how to prepare the data set

02:06:24.250 --> 02:06:27.650
and all those things, right? So now any given model, you

02:06:27.650 --> 02:06:30.290
will be able to train it, right? You will be able to train

02:06:30.290 --> 02:06:33.310
it. Right. You will be able to consume it. So this is your

02:06:33.310 --> 02:06:35.530
model, fine tune model. So you will be able to train it and

02:06:35.530 --> 02:06:38.030
you will be able to consume it at any point of time by the

02:06:38.030 --> 02:06:43.830
APIs, uh, easily now coming to the next part. So this is all

02:06:43.830 --> 02:06:46.690
about the open AI. So whatever model is available in open

02:06:46.690 --> 02:06:50.690
AI, but most not of the, none of the model, which is open

02:06:50.690 --> 02:06:53.350
source by other organizations are available in open AI,

02:06:53.450 --> 02:06:56.050
right? None of the model, which is open source are available

02:06:56.050 --> 02:06:59.930
on open AI. Then what, then how I can train it, right? So

02:06:59.930 --> 02:07:04.710
obviously one approach is this one I have told you, right?

02:07:05.150 --> 02:07:09.930
By code, by using this code, yeah, by using this code, I can

02:07:09.930 --> 02:07:13.090
try to do a fine tuning, but you can come to me and you can

02:07:13.090 --> 02:07:16.270
ask me a question that, uh, I'm a manager, I'm not a techie

02:07:16.270 --> 02:07:20.410
guy, but still I have a data, right? I have a data and I

02:07:20.410 --> 02:07:24.590
would like to do a fine tuning. So can you suggest me some

02:07:24.590 --> 02:07:27.350
like a platform apart from open AI? Because yeah, you know,

02:07:27.390 --> 02:07:31.130
open AI, click, click, upload the data. Okay. I can get the

02:07:31.130 --> 02:07:34.990
model easily, right? But do we have any platform? So where,

02:07:35.110 --> 02:07:39.070
uh, uh, I can do a fine tuning of a Lama model, a Mistral

02:07:39.070 --> 02:07:44.050
model, maybe like a deep seek model, yeah, all the open

02:07:44.050 --> 02:07:47.550
source model, big or small. So I'm not, so maybe you are not

02:07:47.550 --> 02:07:50.030
a techie guy. You don't understand this kind of a code,

02:07:50.190 --> 02:07:53.910
right? So without writing even a single line of a code, will

02:07:53.910 --> 02:07:57.590
I be able to, because with code it's possible I've shown

02:07:57.590 --> 02:08:01.310
you, right? So. Even if it's possible for one, it will be

02:08:01.310 --> 02:08:05.170
possible for all. Doesn't matter which kind of a model you

02:08:05.170 --> 02:08:08.950
are like, uh, going to use it, right?

02:08:10.470 --> 02:08:14.450
Someone is saying go for RAG, I'm like, I'm talking about

02:08:14.450 --> 02:08:19.450
fine tuning. So without writing a code, how I can do a fine

02:08:19.450 --> 02:08:24.780
tuning except open AI. So here I can do it without writing a

02:08:24.780 --> 02:08:27.460
single line of a code, right? So even I can do the same

02:08:27.460 --> 02:08:30.780
thing, exact same thing, even by writing a code. I mean my

02:08:30.780 --> 02:08:34.100
local and by calling the API of open AI, I can do that as

02:08:34.100 --> 02:08:40.080
well now. So there is a platform where you don't have to

02:08:40.080 --> 02:08:42.700
write even a single line of a code, not even a single line,

02:08:42.840 --> 02:08:48.120
but still you will be able to do a training and that is

02:08:48.120 --> 02:08:52.480
available on where hugging face. So there is a, something

02:08:52.480 --> 02:08:54.740
called as space, right? There is something called as

02:08:54.740 --> 02:08:58.160
basically a space. So just go to hugging face, click on a

02:08:58.160 --> 02:09:02.000
space, right? So they have given you a space for image

02:09:02.000 --> 02:09:04.280
generation, video generation, text generation. So space is

02:09:04.280 --> 02:09:07.620
nothing but a kind of a task. And for that task, there is a

02:09:07.620 --> 02:09:10.360
template which is available. Image upskilling, data

02:09:10.360 --> 02:09:12.920
visualization, voice cloning, text analysis, object

02:09:12.920 --> 02:09:16.380
detection, and then like a document analysis, image

02:09:16.380 --> 02:09:19.920
captioning, visual chat bots. So these are the different,

02:09:20.000 --> 02:09:21.920
different, different, different kind of a space which has

02:09:21.920 --> 02:09:23.900
been given to you. So there are tons of space which people

02:09:23.900 --> 02:09:30.220
have already created. Yeah. Now. What I'm supposed to

02:09:30.220 --> 02:09:34.480
choose, which kind of a space I'm supposed to choose. So

02:09:34.480 --> 02:09:37.420
Azure AI studio. Yeah, that's true. You can use Azure AI

02:09:37.420 --> 02:09:41.180
studio as well. So even Adulus has a service for that. So

02:09:41.180 --> 02:09:43.100
you can choose. So you can choose any of these cloud

02:09:43.100 --> 02:09:45.820
platform where just plug and play. And then as a manager,

02:09:45.960 --> 02:09:48.680
you will be able to train it and you are not supposed to be

02:09:48.680 --> 02:09:51.300
techie. You just have to get the data. That's it. And you

02:09:51.300 --> 02:09:53.980
will be able to like a train and fine tune your model and

02:09:53.980 --> 02:09:57.440
then anyone can call it. Right. No. Now there is a place,

02:09:57.560 --> 02:09:59.840
even inside the hugging phase as we are talking about

02:09:59.840 --> 02:10:02.220
hugging phase and we all are aware about hugging phase. So

02:10:02.220 --> 02:10:04.600
let's go ahead. I'll try to show you something. Right. And

02:10:04.600 --> 02:10:06.860
it's the best one, I would say better than, I would say like

02:10:06.860 --> 02:10:12.200
Azure AI studio and AWS for model training at least, not for

02:10:12.200 --> 02:10:14.760
all the tasks, but yeah, especially for model training. I'm

02:10:14.760 --> 02:10:17.100
talking about maybe you can host it over there, but yeah,

02:10:17.160 --> 02:10:20.760
hugging phase is the best. So here you can try to like a

02:10:20.760 --> 02:10:26.460
search for auto, auto, train, auto T R A I N training.

02:10:26.500 --> 02:10:30.640
train. Yeah. You can search for auto train by the way, fine.

02:10:30.820 --> 02:10:34.500
You can try to search for auto train and then just try to

02:10:34.500 --> 02:10:38.900
copy or maybe we just click on new space, click on new

02:10:38.900 --> 02:10:43.200
space, right? And then give a space name, give a space name

02:10:43.200 --> 02:10:47.300
over here. So maybe I'll try to give a space name as a, uh,

02:10:47.580 --> 02:10:54.200
training HF is the space name sort description. I'm not

02:10:54.200 --> 02:10:56.920
going to give right. Right. And then a Docker seven

02:10:56.920 --> 02:11:01.140
template, uh, Gila, Mario evidence, even I can deploy a

02:11:01.140 --> 02:11:03.300
stimuli tab over here. Even I can like a call this one

02:11:03.300 --> 02:11:09.220
static, or this is going to create the space. Let me do one,

02:11:09.320 --> 02:11:12.340
just go in this way, by the way. So come over here and just

02:11:12.340 --> 02:11:18.280
call for auto, uh, auto, auto train. Yeah. So here you will

02:11:18.280 --> 02:11:20.220
be able to find out the multiple template, which other

02:11:20.220 --> 02:11:23.640
people are using, right? Auto train template. So just try to

02:11:23.640 --> 02:11:27.300
click on any. Any means any. Now someone else is using this

02:11:27.300 --> 02:11:31.580
one, uh, object detection, transformers, JS. What are the

02:11:31.580 --> 02:11:36.900
space or to train or to train for LLM unreal engine or to

02:11:36.900 --> 02:11:39.100
train machine learning or

02:11:42.970 --> 02:11:48.590
to train advance. I'm just looking for a template LLM.

02:11:52.320 --> 02:12:00.720
Sorry. Yeah. So my bad, I believe auto tune. Hmm. I

02:12:04.910 --> 02:12:09.290
have already created it. This auto train, as you can see. So

02:12:09.290 --> 02:12:11.510
auto train, I

02:12:15.290 --> 02:12:19.830
have to search for, I've already done that, like, uh, just

02:12:19.830 --> 02:12:23.950
trying to show you the starting point of this one auto

02:12:23.950 --> 02:12:32.120
train, and then search for auto train projects basically,

02:12:32.140 --> 02:12:37.160
and then try to replicate this auto train advance for this

02:12:37.160 --> 02:12:40.220
auto train advance. Uh, you can. Try to like a click on this

02:12:40.220 --> 02:12:44.980
one, and then it is going to ask you to duplicate means

02:12:44.980 --> 02:12:48.620
someone else is running that, uh, you can't use it. So

02:12:48.620 --> 02:12:50.800
basically you can duplicate it so that it will run for you.

02:12:50.900 --> 02:12:53.880
It will run in your instances. So just duplicate it. So auto

02:12:53.880 --> 02:12:57.280
train duplicate. And now here is the main thing, which is

02:12:57.280 --> 02:13:00.400
going to start. So a space name, auto train advance. Let's

02:13:00.400 --> 02:13:02.840
suppose I already have auto train advance. I'll give one to

02:13:02.840 --> 02:13:06.080
write auto train advance one to now visibility, public,

02:13:06.180 --> 02:13:09.920
private, whatever I want. If public, then all, everyone will

02:13:09.920 --> 02:13:13.100
be able to see it. Now here they are giving you the

02:13:13.100 --> 02:13:16.280
hardware, they are giving you a free version and in free

02:13:16.280 --> 02:13:18.220
version, you will not be able to do a training by the way,

02:13:18.300 --> 02:13:21.540
uh, you can just initiate the training. And, uh, by the time

02:13:21.540 --> 02:13:24.140
I'm going to initiate the training, it will fail. You will,

02:13:24.140 --> 02:13:26.500
you will be able to see it in a sometime means I will be

02:13:26.500 --> 02:13:28.280
able to initiate the training, but it is going to eventually

02:13:28.280 --> 02:13:32.360
fail. So here by default, they're giving you two, uh, like a

02:13:32.360 --> 02:13:36.280
core CPU and 16 GB free, uh, free one. Right. But again,

02:13:36.420 --> 02:13:39.060
it's not much, at least for training, they are giving you

02:13:39.060 --> 02:13:42.360
all kinds of a GPUs as well. So T for a small, and then

02:13:42.360 --> 02:13:46.660
like, uh, there's, there's this, and it is giving you even

02:13:46.660 --> 02:13:50.260
Nvidia a hundred large, right? The biggest one, the biggest

02:13:50.260 --> 02:13:54.420
one, which is going to cost you like a $4 per hour, but yes,

02:13:54.560 --> 02:13:58.660
one 42 GB of Ram and then 12 V core CPU. And then like, uh,

02:13:58.800 --> 02:14:03.040
it is giving you four into eight and a G large as well. So

02:14:03.040 --> 02:14:06.540
this is the heaven. Right? This is the heaven. This is

02:14:06.540 --> 02:14:10.300
something that we all need while doing a training, right?

02:14:10.680 --> 02:14:13.360
Access of the resources. Now, this is not the only platform

02:14:13.360 --> 02:14:15.760
which is giving you a GPU. There are hundreds of other

02:14:15.760 --> 02:14:18.800
platform. There are, they're giving you just a 100, right?

02:14:18.840 --> 02:14:21.380
There are platform, which is giving you like a, uh, uh, H

02:14:21.380 --> 02:14:25.160
100, uh, eight H 200. So all, all those cities they're

02:14:25.160 --> 02:14:28.680
giving you, right. Prices are going to vary, but yeah. So

02:14:28.680 --> 02:14:31.400
let's suppose I'm going to pick for like a free as of now,

02:14:31.480 --> 02:14:35.300
and then I'm going to click on duplicate the space. The only

02:14:35.300 --> 02:14:36.760
way to do that. The only thing which matters in terms of a

02:14:36.760 --> 02:14:41.680
model training is this one, a hardware. And the second thing

02:14:41.680 --> 02:14:44.760
is data. If you don't have resource, if you don't have a

02:14:44.760 --> 02:14:47.080
data, you will not be able to do it. If you have a data, if

02:14:47.080 --> 02:14:49.820
you don't have a, uh, like a machine, a powerful machine,

02:14:49.960 --> 02:14:53.960
again, you will not be able to train the model, right? So

02:14:53.960 --> 02:14:58.440
here, click on this duplicate space, and now it will take

02:14:58.440 --> 02:15:02.100
some time to like a start spin up my space by the way. And

02:15:02.100 --> 02:15:03.220
then I'm going to show you the magic.

02:15:06.890 --> 02:15:08.790
Done guys. Are you able to follow along with this?

02:15:13.920 --> 02:15:17.080
Yup. So anyone is doing it. Anyone is able to like, uh,

02:15:18.180 --> 02:15:23.480
build that space. If not just use this link, click on this

02:15:23.480 --> 02:15:24.560
link, duplicate it immediately.

02:15:30.780 --> 02:15:32.540
So anyone, okay.

02:15:38.070 --> 02:15:40.730
Successfully installed auto train advanced this, this, this,

02:15:40.730 --> 02:15:46.410
or just trying to prepare my entire space basically or

02:15:46.410 --> 02:15:49.610
training. So everything will be done by hugging face. You

02:15:49.610 --> 02:15:52.590
don't have to do anything. See, everything has been done.

02:15:52.630 --> 02:15:56.110
Done by hugging face. Yeah. Now close this and then sign in

02:15:56.110 --> 02:15:58.790
with the hugging face. Only one click. So it will be able to

02:15:58.790 --> 02:16:03.950
do a sign in then authorize yeah. And now this is the panel.

02:16:04.110 --> 02:16:07.210
This is the auto train panel. This is the panel, which I

02:16:07.210 --> 02:16:11.110
wanted you to see, right? This is the actual panel. So where

02:16:11.110 --> 02:16:14.570
you can do a training without even knowing a single line of

02:16:14.570 --> 02:16:18.210
a code, and you will be able to control all kinds of a

02:16:18.210 --> 02:16:22.190
parameter, even more parameter than open AI, right? More.

02:16:22.190 --> 02:16:24.350
More parameter than open AI, you will be able to control it.

02:16:24.450 --> 02:16:27.090
I'll show you that. So parameter mode, I'm going to select

02:16:27.090 --> 02:16:31.330
it as a full. So now all kinds of parameter. Now let's see.

02:16:31.570 --> 02:16:34.990
So first of all, task, what kind of a task I'm doing, doing

02:16:34.990 --> 02:16:42.010
so SFT, online DPO, generic or DPO or reward. Now here we

02:16:42.010 --> 02:16:45.310
have more tasks as compared to open AI. This is what I was

02:16:45.310 --> 02:16:48.250
talking about guys, right? This is what I was talking about

02:16:48.250 --> 02:16:52.170
here. So SFT, then GT, then RT, then DPO, then ORPO. Okay.

02:16:52.190 --> 02:16:54.990
So this is what I was talking about. So fine tuning wise,

02:16:55.110 --> 02:16:57.470
inside of fine tuning categories, we have this five

02:16:57.470 --> 02:17:00.110
categories, right? This five categories in open AI, these

02:17:00.110 --> 02:17:03.710
five categories are not available. Now VLM, right? VLM fine

02:17:03.710 --> 02:17:06.010
tuning wise, I can do that as well. Now sentence transformer

02:17:06.010 --> 02:17:08.510
wise, I can do sentence pair, sentence pair classification,

02:17:08.810 --> 02:17:12.510
pair, scorpion, triplet, quotient answering. Other text

02:17:12.510 --> 02:17:15.890
tasks. So test classification, test relation, this, this,

02:17:15.930 --> 02:17:18.530
this, this, this. Image also I can try to fine tune. Image

02:17:18.530 --> 02:17:20.950
model also. Object direction model also I can try to fine

02:17:20.950 --> 02:17:23.290
tune. Tablet task. Tablet task also I can try to fine tune.

02:17:23.410 --> 02:17:27.270
So not just LLM. Yes, LLM, we have five categories of fine

02:17:27.270 --> 02:17:29.510
tuning, right? So either we can go with the like a

02:17:29.510 --> 02:17:32.130
supervised fine tuning, or maybe we can go with the DPO. We

02:17:32.130 --> 02:17:34.230
can go with the reward learning. We can go with the generic

02:17:34.230 --> 02:17:37.330
one that we have done so far, right? So we can go ahead with

02:17:37.330 --> 02:17:39.470
any of this fine tuning approach. That's completely fine,

02:17:39.670 --> 02:17:43.590
right? But apart from that, there are other type of fine

02:17:43.590 --> 02:17:45.870
tuning also we can do. So let's suppose if I'm going to

02:17:45.870 --> 02:17:50.690
select SFT, right? SFT. Now project name, anything. Now see.

02:17:50.690 --> 02:17:54.510
Let's see how many models are available. Now just imagine

02:17:54.510 --> 02:17:59.430
any models, Llama, Quen, Mistral, Sravan AI also. The Sravan

02:17:59.430 --> 02:18:02.410
AI, the recent launch from India, right? Sravan AI,

02:18:02.670 --> 02:18:07.750
Deepseek, right? Name any model guys. Name any model and

02:18:07.750 --> 02:18:11.830
everything is available just on your click for a fine

02:18:11.830 --> 02:18:15.510
tuning. Every model is available for a fine tuning. So for

02:18:15.510 --> 02:18:18.890
SFT, this one, then what and all model are available for

02:18:18.890 --> 02:18:23.250
DPO. So again, this will change. These model, list will keep

02:18:23.250 --> 02:18:26.970
on changing, right? This model. I can select Quen, let's

02:18:26.970 --> 02:18:30.950
suppose, right? I can select Llama. So for Quen, all the

02:18:30.950 --> 02:18:34.290
parameter I can control. So all this parameter that maybe

02:18:34.290 --> 02:18:38.750
you have not even heard about, right? Yeah. This is basic.

02:18:38.870 --> 02:18:41.150
Basic means only the small parameter it will try to

02:18:41.150 --> 02:18:44.410
showcase. So chat template, then distributed backend, mixed

02:18:44.410 --> 02:18:49.270
precision, optimizer. So Adam, SGD. Now this is going to

02:18:49.270 --> 02:18:50.870
change. This is going to give you the learning that, okay,

02:18:50.910 --> 02:18:54.050
these many parameters even exist, right? These many

02:18:54.050 --> 02:18:56.090
parameters even exist. This is something that I can try to

02:18:56.090 --> 02:18:59.710
tune full, right? This is something which I saw, and this is

02:18:59.710 --> 02:19:01.770
something that you should talk about in your interview or in

02:19:01.770 --> 02:19:04.470
front of anyone that, okay, I have trained this and I have

02:19:04.470 --> 02:19:06.190
used this one, this one, this one. And this is something

02:19:06.190 --> 02:19:08.930
that you should investigate. If you would like to see all

02:19:08.930 --> 02:19:11.630
the parameters in a JSON file, these are the parameters and

02:19:11.630 --> 02:19:13.750
it's editable. You can change it. You can change it

02:19:13.750 --> 02:19:17.190
basically. Right? You can change it. So now copy this one.

02:19:17.310 --> 02:19:19.990
Put it into the URI. So the asset that explained me all the

02:19:19.990 --> 02:19:22.190
parameter with respect to this model, it will explain you.

02:19:22.270 --> 02:19:25.450
And, and again, in all the models, it's going to be almost

02:19:25.450 --> 02:19:29.010
same, right? So at least for once, if you're going to

02:19:29.010 --> 02:19:31.150
understand, it will be amazing. It will be amazing,

02:19:31.250 --> 02:19:34.490
literally, right? So these are the parameter. So I can try

02:19:34.490 --> 02:19:37.890
to choose like a base model from here, right? I can try to

02:19:37.890 --> 02:19:42.010
choose basically any, any base model based on the task. So

02:19:42.010 --> 02:19:44.970
let's suppose if I'm going to do a safety task, right? I'm

02:19:44.970 --> 02:19:48.110
going to do a safety task. Now here, dataset. I can upload

02:19:48.110 --> 02:19:52.810
it from my local. Yeah. For a safety task, I can try to

02:19:52.810 --> 02:19:57.310
upload it, upload a dataset from my local, or I can try to

02:19:57.310 --> 02:20:02.370
be even like, you know, take

02:20:02.370 --> 02:20:05.110
a data which is available inside hugging face itself.

02:20:05.890 --> 02:20:08.850
Because in hugging face, we have a huge data, right? So with

02:20:08.850 --> 02:20:11.250
hugging face data, if I would like to like train something

02:20:11.250 --> 02:20:14.250
from local, just simple drag and drop or upload from hugging

02:20:14.250 --> 02:20:17.490
face, if I have to use some data. Okay. So I have figured

02:20:17.490 --> 02:20:22.690
out for a safety, there was some data. Yeah. So there is a

02:20:22.690 --> 02:20:28.370
no robot data, which is available. I believe, no,

02:20:29.830 --> 02:20:32.390
this one, this one is for a safety. This one is for a

02:20:32.390 --> 02:20:37.530
safety. I can use it, right? So maybe open Bev text 10 K.

02:20:38.210 --> 02:20:42.670
Let me copy, right? So there's me copy this dataset. So just

02:20:42.670 --> 02:20:44.810
this one is required, which is available on a hugging face.

02:20:45.010 --> 02:20:50.730
I can try to give like a. Okay. No IMDb icon. This one I can

02:20:50.730 --> 02:20:55.050
try to give, I'm trying to do what SFT. So for SFT, what is

02:20:55.050 --> 02:20:57.170
the dataset which is required? So accordingly I have to give

02:20:57.170 --> 02:21:00.110
the dataset, then it is going to work. I don't remember.

02:21:00.370 --> 02:21:03.010
I'll have to check again, but yeah, let me go ahead with

02:21:03.010 --> 02:21:07.070
this first. Now column mapping text fine. And then start

02:21:07.070 --> 02:21:11.570
training. So yeah, sure. If success. Yeah. See success

02:21:11.570 --> 02:21:14.190
monitoring your job in local and it will fail immediately.

02:21:14.750 --> 02:21:18.370
It will fail immediately. Right? Uh, so I'm able to submit

02:21:18.370 --> 02:21:21.570
my job as you can see over here, but because of the, yeah,

02:21:21.630 --> 02:21:24.930
so the space has been paused by its owner. This issue you

02:21:24.930 --> 02:21:29.070
are going to get because you are running in a free mode. You

02:21:29.070 --> 02:21:32.450
have, you don't have a sufficient, like a memory for that

02:21:32.450 --> 02:21:35.210
kind of a model that you are trying to use. That is a

02:21:35.210 --> 02:21:37.790
reason. So this is the issue it is giving you. Now you can

02:21:37.790 --> 02:21:41.170
go to setting. You can try to even choose over here, upgrade

02:21:41.170 --> 02:21:44.370
it. So as of now, this is my mode free, right? A basic one.

02:21:44.570 --> 02:21:48.050
Okay. So I can do anything that I want, uh, like, uh, which

02:21:48.050 --> 02:21:50.690
is, which is available over here. And then I can try to

02:21:50.690 --> 02:21:53.070
relaunch it. Everything I can control it from a setting.

02:21:53.410 --> 02:21:56.370
Yeah. But, uh, the main part, which I'm trying to show you

02:21:56.370 --> 02:21:59.810
from here is that, that I'm able to submit my training

02:21:59.810 --> 02:22:02.550
successfully, right? I'm able to submit my training

02:22:02.550 --> 02:22:05.130
successfully. So auto train at once, I'm going to click it,

02:22:05.190 --> 02:22:09.230
but they start this space starting again. It'll follow the

02:22:09.230 --> 02:22:11.690
same loop because it got terminated because of overload

02:22:11.690 --> 02:22:12.990
successfully

02:22:18.780 --> 02:22:20.680
installed auto train at once. Yeah.

02:22:27.460 --> 02:22:29.780
So are you, are you able to do it guys? Are you able to do

02:22:29.780 --> 02:22:34.180
it? Let me, uh, give you this, uh, data set, uh, a link as

02:22:34.180 --> 02:22:37.420
well, just for the submission. There are, uh, so the best

02:22:37.420 --> 02:22:42.580
way is to like, uh, take your own data. Yup. So the best way

02:22:42.580 --> 02:22:44.940
will be to take your own data. And I, that's the reason. So

02:22:44.940 --> 02:22:48.000
I talked about this, that, uh, for a safety, how to create

02:22:48.000 --> 02:22:50.080
the data for this, this, this, this, this, or how to create

02:22:50.080 --> 02:22:52.420
the data. So just try to create that kind of a data and then

02:22:52.420 --> 02:22:57.660
pass those data. Okay. So this one is again like a up. Uh,

02:22:57.980 --> 02:23:00.940
so again, like, uh, if I have to do a DPO, if I have to do a

02:23:00.940 --> 02:23:04.140
safety, if I have to do a generic training, so I can try to

02:23:04.140 --> 02:23:07.760
select any model, which is just at my click. I can try to

02:23:07.760 --> 02:23:10.760
maintain any of these parameter. I can tune any of these

02:23:10.760 --> 02:23:15.220
parameter, and then I can try to train it. That's a power of

02:23:15.220 --> 02:23:18.400
hugging phase auto train, which you will not be able to find

02:23:18.400 --> 02:23:22.200
out anywhere. And that too, in this easiest way, right? So

02:23:22.200 --> 02:23:23.960
even for object detection, right? There are so many models.

02:23:24.440 --> 02:23:27.160
It's a computer vision model by the way. Okay. There are so

02:23:27.160 --> 02:23:29.360
many of these models, right? So that is the main advantage.

02:23:29.500 --> 02:23:31.920
You will be able to find out where you have a proper UI,

02:23:32.260 --> 02:23:35.900
proper compute you have. So at your like a dispose, so you

02:23:35.900 --> 02:23:39.140
can try to take any of the CPUs and GPUs and to start, start

02:23:39.140 --> 02:23:42.260
doing a training, train the model, and then you can try to

02:23:42.260 --> 02:23:45.640
even host the model. So that's the beauty of hugging phase

02:23:45.640 --> 02:23:47.960
space. That's the reason. So hugging phase is like a getting

02:23:47.960 --> 02:23:53.270
so much of popularity. Is it making sense guys to all of us?

02:23:54.390 --> 02:23:57.750
And I can, if I don't want to use a hugging phase, like, uh,

02:23:57.770 --> 02:24:00.530
uh, uh, uh, uh, uh, uh, uh, resources. So what I can do is I

02:24:00.530 --> 02:24:04.890
can even try to do each and every kind of a setup in my

02:24:04.890 --> 02:24:12.200
local and by using a hugging phase API, so I can try to do

02:24:12.200 --> 02:24:13.980
the fine tuning, which I have done in a beginning itself.

02:24:15.180 --> 02:24:18.000
Yeah. So if you, if you don't want to like a go ahead with

02:24:18.000 --> 02:24:22.500
the hugging phase, like a paid one, but yeah, you just pay

02:24:22.500 --> 02:24:26.480
for like a per use. So again, it's just not going to charge

02:24:26.480 --> 02:24:29.400
you for like a more than that, because on an hourly basis,

02:24:29.480 --> 02:24:30.440
they are going to give you the GPU.

02:24:33.520 --> 02:24:35.820
And again, the best part is you don't have to do any

02:24:35.820 --> 02:24:38.320
configuration. Yeah. The best part is you don't have to even

02:24:38.320 --> 02:24:40.900
do a configuration. If you're going to take a bare cell or

02:24:40.900 --> 02:24:43.040
bare metal or bare GPU. So obviously you have to do a

02:24:43.040 --> 02:24:45.520
configuration. So again, you have to write some sort of a

02:24:45.520 --> 02:24:50.300
Linux command, but here, nothing. So model is also available

02:24:50.300 --> 02:24:53.420
over here. Data set. You can upload directly by click. GPU

02:24:53.420 --> 02:24:56.420
is also integrated in this one. So everything in one single

02:24:56.420 --> 02:24:59.360
package, basically. So it's an ecosystem, I would say. So

02:24:59.360 --> 02:25:00.480
ecosystem of model training.

02:25:04.690 --> 02:25:07.250
So hope all of you are able to understand. Guys. And can I

02:25:07.250 --> 02:25:11.310
say that it's very easy to do a fine tuning, right? If you

02:25:11.310 --> 02:25:14.050
understand what task you are doing, if you understand what

02:25:14.050 --> 02:25:15.730
task you are doing and what kind of a data you have to

02:25:15.730 --> 02:25:19.490
prepare. So can I say that model fine tuning is literally a

02:25:19.490 --> 02:25:21.210
very, very, very, very easy task.

02:25:24.360 --> 02:25:28.640
Yes, everyone. Can I say that model fine tuning is one of

02:25:28.640 --> 02:25:31.060
the easiest tasks. Generally people get scared that how I

02:25:31.060 --> 02:25:33.300
will be able to do a model fine tuning. It's a big model.

02:25:33.380 --> 02:25:38.840
There's that, right? A buzzword. But look at this. Look at

02:25:38.840 --> 02:25:41.300
this open AI. And I look at this code that we have written

02:25:41.300 --> 02:25:44.840
today. Right? It's nothing. It's very easy. It's very

02:25:44.840 --> 02:25:47.980
logical. So now you can go ahead and you can do a fine

02:25:47.980 --> 02:25:52.300
tuning. And now what I want you to do is that in your

02:25:52.300 --> 02:25:54.700
resume, next time when you are going to update your resume.

02:25:55.480 --> 02:25:58.920
So try to derive a context that okay, so for healthcare

02:25:58.920 --> 02:26:01.540
industry, for like a finance industry for this, that, and if

02:26:01.540 --> 02:26:03.820
you're not able to get some idea, ask Yuri, Yuri will give

02:26:03.820 --> 02:26:06.980
you idea and try to mention that I have fine tuned this

02:26:06.980 --> 02:26:12.000
model. Okay. Let's say 100 GPU. It took five days of time

02:26:12.000 --> 02:26:16.640
for me with 10 GB of a data or five TV of the data build

02:26:16.640 --> 02:26:20.680
this kind of a story. Yeah. Build this kind of a story and

02:26:20.680 --> 02:26:22.820
mentioned that a story into a resume and then talk about

02:26:22.820 --> 02:26:31.450
that story in an interview. Yes. And then see the magic. You

02:26:31.450 --> 02:26:34.530
will say, wow, you know, a lot of things. Let's let's join

02:26:34.530 --> 02:26:41.070
my company, just join my team. Right? So you have to build a

02:26:41.070 --> 02:26:43.390
story. And then you have to sell the story as simple as

02:26:43.390 --> 02:26:46.750
that. And all those things can be done. See if nothing is

02:26:46.750 --> 02:26:48.710
hard, like, according to me, if you'll ask me like, what is

02:26:48.710 --> 02:26:52.190
tough, I never say like, tough is just a state of mind. Uh,

02:26:52.350 --> 02:26:55.330
so nothing is easy. Nothing is hard. It's just like, uh, you

02:26:55.330 --> 02:26:59.570
have to pay attention for some time. That's it. If you go to

02:26:59.570 --> 02:27:02.910
launch the hugging face model as a team work in local, then

02:27:02.910 --> 02:27:06.290
how I mentioned all the members name here. So they are

02:27:06.290 --> 02:27:08.430
giving you this editing page, right? The very first landing

02:27:08.430 --> 02:27:10.570
page over there. You can try to mention all the

02:27:10.570 --> 02:27:14.430
contributors. Okay. So they are giving you option. So all

02:27:14.430 --> 02:27:19.150
the contributors you can mention. Yeah. So hope all of you

02:27:19.150 --> 02:27:23.750
have enjoyed this entire session and, uh, we are able to

02:27:23.750 --> 02:27:30.970
cover everything from your, uh, let me, where is this? Okay.

02:27:32.070 --> 02:27:37.370
So I'm able to cover everything from your syllabus, by the

02:27:37.370 --> 02:27:49.360
way, generated AI with, uh, with. So hope as a part of the

02:27:49.360 --> 02:27:52.660
syllabus now coming to a conclusion guys. So now look into

02:27:52.660 --> 02:27:55.540
your syllabus of fine tuning, and then tell me whether you,

02:27:55.560 --> 02:27:58.340
we are able to talk about everything or not introduction of

02:27:58.340 --> 02:28:01.040
fine tuning, model optimization, this, this, this, then, uh,

02:28:01.080 --> 02:28:04.340
fine tuning, uh, pre-fit, uh, parameter efficient, Laura and

02:28:04.340 --> 02:28:06.940
Cora. We are able to understand then how to do a fine tuning

02:28:06.940 --> 02:28:09.340
with the GPT model by preparing the data set, performance

02:28:09.340 --> 02:28:12.140
optimization, hyperparameter, everything, then how to fine

02:28:12.140 --> 02:28:15.260
tune any model Lama mistral, whatever Falcon are based on

02:28:15.260 --> 02:28:18.680
that to task. Right? So, uh, like a fine tuning of free

02:28:18.680 --> 02:28:21.420
models, uh, hugging face, we know advanced fine tuning

02:28:21.420 --> 02:28:24.480
approach. So all HFLs, everything we are able to discuss. So

02:28:24.480 --> 02:28:28.120
almost everything we are able to cover except like small,

02:28:28.180 --> 02:28:31.340
small like things. And yesterday I have given you the task

02:28:31.340 --> 02:28:34.240
to build this project. So a couple of people have pinged me

02:28:34.240 --> 02:28:37.240
and they have pinged me with their link, live link of a

02:28:37.240 --> 02:28:39.960
render, and they are able to complete the task. I'm assuming

02:28:39.960 --> 02:28:42.520
that you all will be able to complete the task because now

02:28:42.520 --> 02:28:45.000
we know how, what is tool, what is agent, how to deploy it,

02:28:45.020 --> 02:28:48.220
everything, right? Everything. We know the frameworks. So

02:28:48.220 --> 02:28:51.060
it's just a matter of fact that how many things you are

02:28:51.060 --> 02:28:53.660
going to build and then how many things you are going to

02:28:53.660 --> 02:28:56.280
write it into your resume. So come into a conclusion guys.

02:28:56.540 --> 02:29:01.740
So this is officially a announcement for all of you. So this

02:29:01.740 --> 02:29:07.820
is a final class, uh, official. Obviously we all are

02:29:07.820 --> 02:29:11.260
connected over a WhatsApp and I believe you have the entire

02:29:11.260 --> 02:29:14.240
batch access. So obviously you will, I'm assuming that you

02:29:14.240 --> 02:29:17.220
will try to avail all the features like book, books,

02:29:17.300 --> 02:29:20.160
projects, and whatever is available on your own, right?

02:29:20.180 --> 02:29:23.500
Whatever is available on your own, including URI, resume AI

02:29:23.500 --> 02:29:28.400
and everything, even job portal. But officially, uh, this is

02:29:28.400 --> 02:29:30.820
an announcement for all of you that this is the last class.

02:29:31.020 --> 02:29:34.100
Uh, this journey of like four months, I believe March,

02:29:34.340 --> 02:29:37.560
April, May, June, four month, I believe. Yeah. February,

02:29:37.640 --> 02:29:42.280
March. So, uh, this journey was amazing. Okay. 8th March we

02:29:42.280 --> 02:29:45.160
have started. 8th March was the first date when we have

02:29:45.160 --> 02:29:48.760
started. So March, April, May, June. And then now it's June,

02:29:48.880 --> 02:29:53.840
right? So 8th. Okay. Amazing. It's a 8th June exact date. So

02:29:53.840 --> 02:29:57.820
hope this journey was wonderful. Hope I was able to teach

02:29:57.820 --> 02:30:01.900
you a little bit. At least you are able to learn a little

02:30:01.900 --> 02:30:06.320
bit. Okay. Multi-model. Um, I have already prepared that

02:30:06.320 --> 02:30:09.720
example. Maybe I'll send it to you. Just run it and you will

02:30:09.720 --> 02:30:14.040
be able to understand. Um, so multi-model means I was trying

02:30:14.040 --> 02:30:16.140
to like, I have the example which I have prepared. So where

02:30:16.140 --> 02:30:20.460
I have prepared. Uh, Lang chain plus a Gemini. So Gemini

02:30:20.460 --> 02:30:23.260
will try to basically extract all the information from the

02:30:23.260 --> 02:30:27.540
images and then in a middle. So we are going to place

02:30:27.540 --> 02:30:31.420
basically a Lang chain with the models with LLM access. I'll

02:30:31.420 --> 02:30:34.320
share. I'll share that like a, with all of you, uh, you can

02:30:34.320 --> 02:30:36.860
run it and, uh, it's a simple Python code. You will be able

02:30:36.860 --> 02:30:43.830
to understand not a very lengthy one. Um, so I believe we

02:30:43.830 --> 02:30:46.710
all are now able to understand that, uh, what is generative

02:30:46.710 --> 02:30:53.170
AI? Uh, what is agentic AI? What is RAG? Uh, what is fine

02:30:53.170 --> 02:30:57.070
tuning? What is the difference between all of these, uh,

02:30:57.190 --> 02:31:00.270
plus a framework, right? So whether it's a Lang chain,

02:31:00.410 --> 02:31:03.010
whether it's a Lama index, whether it's a Lang graph,

02:31:03.170 --> 02:31:07.490
whether it's a crew AI and, uh, along with that, a core

02:31:07.490 --> 02:31:11.510
concept, a transformer, right? A core concept, the core NLP

02:31:11.510 --> 02:31:14.990
concept. So hope we all are able to learn, uh, here and

02:31:14.990 --> 02:31:17.850
there. Obviously. Syllabus is very huge. It's like, uh, so

02:31:17.850 --> 02:31:20.650
many number of lines I have mentioned as a part of the

02:31:20.650 --> 02:31:24.350
syllabus. Uh, so maybe one or two topic here and there,

02:31:24.470 --> 02:31:28.250
obviously that that's pretty much obvious that, uh, maybe I

02:31:28.250 --> 02:31:31.630
have not discussed, right. But majority of the topic, uh,

02:31:31.750 --> 02:31:35.930
the major topic, I think we have already discussed, and I

02:31:35.930 --> 02:31:39.810
believe all of you are able to understand it. Now the next

02:31:39.810 --> 02:31:44.290
step for all of you to work on the project now, from where

02:31:44.290 --> 02:31:47.010
you will get the project. So in terms of portal, I have

02:31:47.010 --> 02:31:50.790
created, finally it's launched and inside it does the portal

02:31:50.790 --> 02:31:55.210
in a very, very structured manner, PRD project requirement

02:31:55.210 --> 02:31:59.490
document, HLD, LLD, the document which you will be able to

02:31:59.490 --> 02:32:02.410
get even as a, even if you're going to join the industry. So

02:32:02.410 --> 02:32:04.390
everything is mentioned over here, a lot of projects are

02:32:04.390 --> 02:32:06.730
mentioned over here, a lot of domains are mentioned over

02:32:06.730 --> 02:32:10.110
here. If some domain and some technology is not mentioned,

02:32:10.410 --> 02:32:14.470
you have, uh, access to give a request. So you can request

02:32:14.470 --> 02:32:18.950
for that, right. But try to do a project from the internship

02:32:18.950 --> 02:32:21.670
portal. Even if you're the experienced person, the reason is

02:32:21.670 --> 02:32:24.410
very simple so that you will be able to understand how

02:32:24.410 --> 02:32:29.090
delivery happens. First part, second part is the structure

02:32:29.090 --> 02:32:32.570
you will be able to get, because when you build simple POC

02:32:32.570 --> 02:32:35.630
MVPs, you don't get that structure, but when you solve the

02:32:35.630 --> 02:32:37.950
real problem in a step by step manner, right, a structure

02:32:37.950 --> 02:32:40.530
manner, then you face a lot of different, different kind of

02:32:40.530 --> 02:32:44.650
challenges. Okay. And now that challenge will make you a

02:32:44.650 --> 02:32:47.370
real techie and that challenges are going to help you out

02:32:47.370 --> 02:32:50.750
when you will go for the interview and next one, right? So

02:32:50.750 --> 02:32:53.930
that is the next step, uh, at least try to do one or two,

02:32:53.990 --> 02:32:56.370
not for the sake of getting an internship later, because in

02:32:56.370 --> 02:32:59.350
terms of later is very much important for dropout and as we

02:32:59.350 --> 02:33:01.570
later is very much important for a fresher without that,

02:33:01.630 --> 02:33:06.590
like it's like technically impossible, uh, to get, uh, any

02:33:06.590 --> 02:33:09.330
kind of opportunity, but for an experienced person as well,

02:33:09.430 --> 02:33:12.110
it's my strong recommendation. Okay. Pick one of the

02:33:12.110 --> 02:33:16.670
project, maybe a medium, maybe the hard one, right? And then

02:33:16.670 --> 02:33:20.510
of domain of your choice, simple, right? Score, search the

02:33:20.510 --> 02:33:23.230
project. And if it is not available, there is a request from

02:33:23.230 --> 02:33:25.290
there itself, right? In the dashboard itself, we have given

02:33:25.290 --> 02:33:28.550
you that option, raise a request option. Uh, and again, that

02:33:28.550 --> 02:33:31.050
don't expect that it will be available overnight. It takes

02:33:31.050 --> 02:33:34.230
time even for us. So we are having a limited resource, a

02:33:34.230 --> 02:33:37.790
limited number of like a team member will take 10 days, 15

02:33:37.790 --> 02:33:41.730
days of time. But yeah, if it is a feasible. Again, not all

02:33:41.730 --> 02:33:43.430
the project will be done. Not all the domain will be

02:33:43.430 --> 02:33:46.850
uploaded. If it is feasible, then obviously we are going to

02:33:46.850 --> 02:33:49.990
like, uh, make it available. Yep. And hopefully it will be

02:33:49.990 --> 02:33:52.770
in 99% of the cases it will be available. Maybe in 1% case

02:33:52.770 --> 02:33:55.890
will reject it, will not upload it. So that is something

02:33:55.890 --> 02:33:59.830
that we are going to do. Then the next step is go for the

02:33:59.830 --> 02:34:03.390
interview. Start applying for the job, start preparing the

02:34:03.390 --> 02:34:06.550
resume, start fine tuning your resume parallelly and start

02:34:06.550 --> 02:34:09.570
applying for the job and keep on building now onwards, but

02:34:09.570 --> 02:34:11.970
that's our RIG application, whether it's a agent TKI

02:34:11.970 --> 02:34:16.310
application, whether it's a fine tuning, right? Keep on

02:34:16.310 --> 02:34:21.870
building, never afraid about a framework. See today, some

02:34:21.870 --> 02:34:23.910
people are talking about some framework tomorrow, again,

02:34:24.010 --> 02:34:27.790
some framework will come, but now we are in a position. We

02:34:27.790 --> 02:34:32.210
have seen enough, right? We have seen enough where any new

02:34:32.210 --> 02:34:35.270
framework, just go and touch any new framework. There's go

02:34:35.270 --> 02:34:37.490
and explore any new framework. Believe me, you don't even

02:34:37.490 --> 02:34:40.130
need me or someone else. Yeah. You will be able to explore

02:34:40.130 --> 02:34:43.730
and you will be able to use it. And I believe that kind of

02:34:43.730 --> 02:34:46.310
understanding we already have theoretical as well as in a

02:34:46.310 --> 02:34:48.410
practical manner. This is something, this is how we have

02:34:48.410 --> 02:34:51.810
like a taken and we have like a given the entire batch

02:34:51.810 --> 02:34:55.810
basically. So just prepare for the next step guys. That's my

02:34:55.810 --> 02:35:00.190
advice. And I'm available in your WhatsApp group. Now it's

02:35:00.190 --> 02:35:04.920
time to take some question. Is that has covered all the

02:35:04.920 --> 02:35:09.220
project in MLOps in the first project of this course, MLOps

02:35:09.220 --> 02:35:11.480
in the first project of this course. No, he has not taken

02:35:11.480 --> 02:35:14.860
even a single class here. So he has taken a one class in

02:35:14.860 --> 02:35:18.960
FHDS and over there, he has discussed the MLOps. And even

02:35:18.960 --> 02:35:22.620
like a, you will be able to find out a complete brand MLOps

02:35:22.620 --> 02:35:25.660
brand new MLOps from him. So that course is also available.

02:35:25.860 --> 02:35:28.240
And even over there, project has been discussed. You will be

02:35:28.240 --> 02:35:30.820
able to find out multiple projects inside the, if you'll go

02:35:30.820 --> 02:35:34.300
and search in a project where MLOps is implemented. So

02:35:34.300 --> 02:35:38.580
again, a new batch is coming from my side. So, but again,

02:35:38.720 --> 02:35:40.540
you don't have to wait for MLOps. A new batch is coming. A

02:35:40.540 --> 02:35:43.540
new batch for my batch, especially even that one is a very

02:35:43.540 --> 02:35:46.540
good one. And you can, you can go ahead and start from today

02:35:46.540 --> 02:35:51.500
itself. Yeah. Now, Joy has pinged me this one. Okay. Let me

02:35:51.500 --> 02:35:54.520
check Joy. What you have like a pinged, some rendered URL.

02:35:54.760 --> 02:35:57.640
You have pinged me. You can keep asking questions guys. Now

02:35:57.640 --> 02:35:59.920
I will answer your question. I'm reading out all the

02:35:59.920 --> 02:36:03.820
comments one by one. Thank you. Happy to be the part of this

02:36:03.820 --> 02:36:05.940
batch, really feeling confidence in the face of interviewing

02:36:05.940 --> 02:36:10.620
the future. Build it Amarnath. Build. Build. I've been

02:36:10.620 --> 02:36:12.840
writing you. Imtyj is saying really wonderful journey.

02:36:12.960 --> 02:36:15.420
Thanks a lot. Need to revise our video again and again.

02:36:15.600 --> 02:36:20.280
Okay. That's great. Hope you are able to explore and learn

02:36:20.280 --> 02:36:24.200
something. Amarnath, Imtyj. Avinasi saying- Is MCPs

02:36:24.200 --> 02:36:28.020
mandatory to learn nowadays? See, MCP is not very different.

02:36:28.240 --> 02:36:32.140
Just go and do one thing- I'll advise you to, there is a MCP

02:36:32.140 --> 02:36:36.160
batch I have launched. Right? And there are 10 projects,

02:36:36.540 --> 02:36:40.280
right? So, do one thing. Just try to watch only one project.

02:36:40.300 --> 02:36:44.160
Maybe. one right only one i think 30 or fourth so in a

02:36:44.160 --> 02:36:47.320
beginning i was not like i've just created the first api but

02:36:47.320 --> 02:36:49.560
yeah just try to watch i think third or fourth any third or

02:36:49.560 --> 02:36:53.200
fourth project uh it will not take much of time you will be

02:36:53.200 --> 02:36:56.960
able to get a proper understanding and going forward you

02:36:56.960 --> 02:37:00.360
will not be afraid about mcp right like i said it's a

02:37:00.360 --> 02:37:04.380
protocol it's a protocol so whatever we have built whatever

02:37:04.380 --> 02:37:07.040
tool that we have seen whatever agent that we have seen i'm

02:37:07.040 --> 02:37:09.600
not doing anything i'm just trying to convert that so for

02:37:09.600 --> 02:37:15.200
example flask api right fast api or flask api what we do we

02:37:15.200 --> 02:37:18.460
have a method we have a function and on top of this function

02:37:18.460 --> 02:37:21.480
so what we do we try to bind it with the url this is the

02:37:21.480 --> 02:37:25.840
only thing that we try to do again in mcp same thing so with

02:37:25.840 --> 02:37:28.800
the help of mcp tool we try to bind it and this exact same

02:37:28.800 --> 02:37:31.880
thing you have done even in a lang chain even in lang graph

02:37:31.880 --> 02:37:35.700
you have done the same thing right so it's not very new it's

02:37:35.700 --> 02:37:38.940
not very different it's a protocol just execute one project

02:37:38.940 --> 02:37:42.640
right believe me you don't have to go till all the 10

02:37:42.640 --> 02:37:46.680
project which i have uploaded you will be able to create all

02:37:46.680 --> 02:37:51.140
those 10 projects that i have uploaded out there this is how

02:37:51.140 --> 02:37:54.780
easy it is just have to go and sit and do it at least one

02:37:54.780 --> 02:37:58.360
right so i have created all the 10 videos but even i'm not

02:37:58.360 --> 02:38:00.820
advising you to go through all those 10 hour of videos no

02:38:02.200 --> 02:38:05.440
only one because you are the part of this batch and now you

02:38:05.440 --> 02:38:07.520
are in a position to understand everything so you don't have

02:38:07.520 --> 02:38:11.960
to like again invest that much of time oh let me take some

02:38:11.960 --> 02:38:16.200
more question master prompt engineer just leave it master

02:38:16.200 --> 02:38:18.620
prompt is doing just go to any github repository and then

02:38:18.620 --> 02:38:21.580
download a prompt no one can master prompt engineering it's

02:38:21.580 --> 02:38:29.720
just like a human like a basically intuition right so what

02:38:29.720 --> 02:38:31.100
you will do you know mastering prompt engineering

02:38:34.120 --> 02:38:37.020
these are the consegu like you know things people you will

02:38:37.020 --> 02:38:37.900
do for you here is that hurt you see used to spread this

02:38:37.900 --> 02:38:41.180
prompt engineering, this, that, these things are not real.

02:38:43.000 --> 02:38:45.580
Great learning from Dancer, we'll keep learning from you.

02:38:45.620 --> 02:38:48.620
Thank you, sir. Do you have any example of cybersecurity in

02:38:48.620 --> 02:38:52.860
Gen AI? I have so many examples. Maybe just go and check

02:38:52.860 --> 02:38:55.160
Intensive Portal. Even over there, you will find some like a

02:38:55.160 --> 02:38:58.980
project. Try to build it with the help of Yuri. Looking

02:38:58.980 --> 02:39:01.900
forward to complete many projects as possible, yeah. And

02:39:01.900 --> 02:39:06.780
guys, never underestimate AI. When you are doing any

02:39:06.780 --> 02:39:13.040
project, use AI, even though if you have to pay for it. The

02:39:13.040 --> 02:39:17.380
adoption rate, if you'll go and read out the latest report.

02:39:17.840 --> 02:39:20.920
So adoption rate in India is very high, right? Means

02:39:20.920 --> 02:39:23.760
everyone is talking about AI and everyone has logged in at

02:39:23.760 --> 02:39:28.660
least once. But the payment rate for AI is worst in India.

02:39:29.520 --> 02:39:32.060
Worse than worse. The reason is that, that people are not

02:39:32.060 --> 02:39:35.500
serious. This shows that people are not serious. People are

02:39:35.500 --> 02:39:38.520
not serious about AI. They're not using AI. They just heard

02:39:38.520 --> 02:39:41.380
about AI and they're just using some free tools, free

02:39:41.380 --> 02:39:44.940
sources from somewhere, right? And we all know that those

02:39:44.940 --> 02:39:47.160
free tools, free sources are not going to fulfill the real

02:39:47.160 --> 02:39:47.440
thing.

02:39:51.680 --> 02:39:56.280
And world is behaving just opposite to it. If you'll see

02:39:56.280 --> 02:39:59.940
that data from a USA, UK region and all those regions. So

02:39:59.940 --> 02:40:03.860
just my humble advice that try to adopt AI. Don't just talk

02:40:03.860 --> 02:40:10.060
about AI. If you are not doing it for sure. It is creating a

02:40:10.060 --> 02:40:15.840
big, big concern and for sure, the money that you are able

02:40:15.840 --> 02:40:19.580
to save, maybe $2, $10, whatever it is, right? It is going

02:40:19.580 --> 02:40:23.580
to hit you back badly. If you are into an IT segment, if you

02:40:23.580 --> 02:40:27.660
are into any segment of this entire universe now, even if

02:40:27.660 --> 02:40:31.120
you are a lawyer, even if you're a CA, right? I have seen,

02:40:31.240 --> 02:40:33.700
I, you keep on talking to everyone. I simply ask one

02:40:33.700 --> 02:40:36.380
question that, okay, how, like how much you are using AI,

02:40:36.500 --> 02:40:40.600
like anything. Maybe like. Uh, GPT or cloud or maybe URI or

02:40:40.600 --> 02:40:45.080
anything paid one, right? And I just get amazed that their

02:40:45.080 --> 02:40:47.540
teams are not using a still. They are opening up a document.

02:40:47.680 --> 02:40:49.560
See, I'm talking about C and I'm talking about the lawyers,

02:40:49.740 --> 02:40:52.980
right? They are drafting is still the contract, the same

02:40:52.980 --> 02:40:55.700
contract, which can be drafted by AI just in a 30 second of

02:40:55.700 --> 02:40:58.520
time, right? And that too, without any kind of a mistake,

02:40:58.700 --> 02:41:02.720
but still people are doing that. So, and, and these people

02:41:02.720 --> 02:41:05.620
talk about AI that AI is going to take my job. Obviously it

02:41:05.620 --> 02:41:08.000
will take your job for sure. It is going to take your job.

02:41:08.860 --> 02:41:11.380
Right? You will not be able to save your job. That's a true.

02:41:11.480 --> 02:41:13.800
That's a reality. And as soon as we are going to understand

02:41:13.800 --> 02:41:16.920
this reality, we will be able to prepare ourselves for a

02:41:16.920 --> 02:41:22.000
future. So not just talk about AI, I would say, adopt it in

02:41:22.000 --> 02:41:25.040
your day to day life, whatever task you are doing, use AI

02:41:25.040 --> 02:41:28.920
first, I do look for a solution from an AI, right? There are

02:41:28.920 --> 02:41:32.980
like a cheapest version of AI up like this, uh, uh, like,

02:41:33.080 --> 02:41:37.120
uh, uh, uh, prices on like a cost. Awesome. This is the best

02:41:37.120 --> 02:41:39.740
version of AI, which is everything is available to all of

02:41:39.740 --> 02:41:45.200
us, but yeah, the thing is use it. Let me take some other

02:41:45.200 --> 02:41:48.900
question. So adopt AI guys in your real life as well. Don't

02:41:48.900 --> 02:41:52.240
just talk about AI, uh, and, uh, with the help of AI, start

02:41:52.240 --> 02:41:56.000
building a project as much and as many as possible, even as

02:41:56.000 --> 02:41:59.980
a learning partner, right? Don't look for your friend. Don't

02:41:59.980 --> 02:42:03.860
look after your mentor. Yeah. Mentor means like fine. Like

02:42:03.860 --> 02:42:06.220
you are able to get oral concept. Now you're able to

02:42:06.220 --> 02:42:09.080
understand. Okay. Now if you have to dig deeper, use AI,

02:42:09.280 --> 02:42:11.680
that's the reason. So I've integrated URI as a part of your

02:42:11.680 --> 02:42:16.700
ecosystem, because I know that it's important, right? It's

02:42:16.700 --> 02:42:19.520
important, but if you're not using it, you will be at loss.

02:42:22.520 --> 02:42:25.120
Okay. That's the reason I love every moment of it. Thank

02:42:25.120 --> 02:42:27.620
you, Eric. Santosh Singh, you are very good. Uh, explanation

02:42:27.620 --> 02:42:30.440
style. Thanks a lot. You have learned ML from you. Now this

02:42:30.440 --> 02:42:33.220
generate. Okay. Thank you Santosh. I want to learn time

02:42:33.220 --> 02:42:35.380
series analytics and reinforcement learning, which courses,

02:42:35.500 --> 02:42:38.560
uh, for time series. I don't have like, I have not published

02:42:38.560 --> 02:42:42.000
any specific. Time series today, I have done one project, so

02:42:42.000 --> 02:42:45.020
you can just go and do that project and then it's fine. So

02:42:45.020 --> 02:42:47.920
today in FHDS, I discussed one project with ARIMA and with a

02:42:47.920 --> 02:42:53.370
LSTM model for time series for everything. I'll not launch a

02:42:53.370 --> 02:42:55.170
course. And I don't think that you should look for the

02:42:55.170 --> 02:42:59.430
course or everything looking for agent AI class. Uh, yeah,

02:42:59.530 --> 02:43:02.090
for sure. Are you planning to add the courses on a quantum

02:43:02.090 --> 02:43:05.970
in your own platform? I am planning for like lot of courses,

02:43:06.110 --> 02:43:09.990
but the only thing is I'm the only mentor. I don't want to

02:43:09.990 --> 02:43:13.030
keep any other mentor. Uh, I just wanted to teach

02:43:13.030 --> 02:43:16.210
everything, uh, although it is going to take maybe next six

02:43:16.210 --> 02:43:19.670
months or maybe a year of time, but yeah, I just, because I

02:43:19.670 --> 02:43:24.710
just want it. It's my like a, a very long term dream that

02:43:24.710 --> 02:43:27.730
I'll go and I'll teach all the most, all the tech, uh,

02:43:27.870 --> 02:43:30.690
before digging up on my retirement from a teaching, uh,

02:43:30.790 --> 02:43:32.990
which is, I'm not going to take a retirement by the way,

02:43:33.050 --> 02:43:36.550
very soon, but yeah, I love teaching. So that's the reason.

02:43:36.690 --> 02:43:39.890
So I have launched like a 20 batches and in every batches.

02:43:39.950 --> 02:43:43.090
I'll start. Like I have started creating the videos, AI

02:43:46.390 --> 02:43:50.670
on mobile devices, uh, quantized model. Uh, I think I have

02:43:50.670 --> 02:43:55.910
published one, uh, sorts, uh, I think reels. So where I

02:43:55.910 --> 02:43:59.390
like, I have shown, okay, so there is a, like a Android app

02:43:59.390 --> 02:44:01.290
and then you can download it and then you can run the

02:44:01.290 --> 02:44:02.330
inferencing.

02:44:04.810 --> 02:44:08.170
Okay. So with that, uh, hope I'm able to clarify all of your

02:44:08.170 --> 02:44:10.790
question now, hope all of you are going to implement it. Uh,

02:44:10.970 --> 02:44:14.410
you all are going to get an advantage from the entire your

02:44:14.410 --> 02:44:17.490
own ecosystem. Now you can go and you can generate your

02:44:17.490 --> 02:44:20.510
certificate guys. Yeah. So certificates, uh, you will be

02:44:20.510 --> 02:44:22.690
able to click and download. So from your dashboard itself

02:44:22.690 --> 02:44:28.030
and, uh, yeah, so, uh, start doing intensive, right. Start

02:44:28.030 --> 02:44:32.410
using URI, start using a resume AI, start using a job

02:44:32.410 --> 02:44:32.810
portal.

02:44:37.460 --> 02:44:40.200
So what's all sort development courses are you launching?

02:44:40.380 --> 02:44:45.040
What off sort development, what sort of development courses

02:44:45.040 --> 02:44:47.960
you are launching? It's already launched hybrid. Just go and

02:44:47.960 --> 02:44:49.960
check it out. Just go and check hybrid. Yeah. Only launch

02:44:49.960 --> 02:44:52.000
almost everything. Machine learning, deep learning, computer

02:44:52.000 --> 02:44:55.100
vision, stats, SQL, a Python in Hindi, Python in English

02:44:55.100 --> 02:44:59.060
with DSA, uh, then a big data, big data in a big data

02:44:59.060 --> 02:45:02.980
masters, big data, uh, in Azure, then AWS, then data with

02:45:02.980 --> 02:45:06.740
Databricks, then Power BI, then Tableau, uh, then, uh, agent

02:45:06.740 --> 02:45:10.140
API or like a generative in cloud, everything I've launched

02:45:10.140 --> 02:45:10.500
everything.

02:45:14.450 --> 02:45:17.210
So for hybrid class, I will also ask if possible, please

02:45:17.210 --> 02:45:20.050
create a project using, uh, using

02:45:22.580 --> 02:45:26.300
poetry. What is this? Poetry, like not able to understand

02:45:26.300 --> 02:45:32.520
some of those, if you can rephrase it, maybe. Yeah. So with

02:45:32.520 --> 02:45:38.220
that guys, thank you so much, all of you and, uh, just try

02:45:38.220 --> 02:45:41.160
to build something and try to get into a better and better

02:45:41.160 --> 02:45:46.640
position because that is how I'm going to evaluate myself as

02:45:46.640 --> 02:45:52.540
a successful mentor or as a failure. Yeah. So, um, with that

02:45:52.540 --> 02:45:56.540
from next week onwards, you can. Yeah. Rest. I'm not resting

02:45:56.540 --> 02:45:58.760
because I have a lot of badges. I have launched like a 20

02:45:58.760 --> 02:46:01.980
batches, so I have to prepare a recording. Otherwise, uh,

02:46:02.120 --> 02:46:04.940
you guys will start poking me on a group. We have a group,

02:46:05.000 --> 02:46:08.760
WhatsApp group, right? So guys will start pinging me that,

02:46:08.840 --> 02:46:11.420
okay, recording is not coming because since last two weeks,

02:46:11.460 --> 02:46:14.200
so I was not able to, uh, like I was not that regular in

02:46:14.200 --> 02:46:17.520
terms of uploading the recordings, uh, because, uh, last

02:46:17.520 --> 02:46:21.660
week we had a launch of Intensive Portal and then, uh, so I

02:46:21.660 --> 02:46:24.320
was busy from last, last week. So till last, last week,

02:46:24.360 --> 02:46:25.240
everything was up and running. Everything was updated. But

02:46:25.240 --> 02:46:29.440
yeah, so in last two weeks, so we had some like a delay, uh,

02:46:29.580 --> 02:46:32.580
some delay, not a big one, small delay. Uh, and I think from

02:46:32.580 --> 02:46:35.060
this week onwards, I'm going to cover all those delays and

02:46:35.060 --> 02:46:38.420
then from next to next week onwards, we'll take a lead, uh,

02:46:38.520 --> 02:46:41.700
so that you will be able to get all the recordings, uh, as

02:46:41.700 --> 02:46:43.500
soon as possible. So you don't have to wait for the

02:46:43.500 --> 02:46:45.980
completion of like two months, three months, please

02:46:49.180 --> 02:46:52.140
share the link for all the Google seat. So Imtiaz, what I'm

02:46:52.140 --> 02:46:55.520
going to do is that, uh, in, I think this week, uh, by the

02:46:55.520 --> 02:46:57.800
end of this week itself. Okay. Let me tell you what is my

02:46:57.800 --> 02:47:01.480
plan and what I'm going to publish. So basically we are

02:47:01.480 --> 02:47:05.520
going to publish our complete roadmap. So attached with the

02:47:05.520 --> 02:47:08.080
courses, URI resume, everything. So something like this

02:47:08.080 --> 02:47:11.240
graphic structure. So do this course and then do this

02:47:11.240 --> 02:47:14.840
particular course and then use this resume AI, this one. So

02:47:14.840 --> 02:47:17.400
in this way, then do this project, this project, this

02:47:17.400 --> 02:47:19.700
project. So this kind of a structure I'm going to release,

02:47:19.900 --> 02:47:22.340
uh, for data science, for machine learning, for deep

02:47:22.340 --> 02:47:25.040
learning, for computer vision, uh, for big data, for the

02:47:25.040 --> 02:47:27.560
power BI, for generative AI, for RIG, for everything, right?

02:47:27.800 --> 02:47:30.760
Separate separate roadmap, a complete roadmap. And over

02:47:30.760 --> 02:47:33.640
there, mapping for the project will be done. Mapping for the

02:47:33.640 --> 02:47:35.980
courses will be done. Mapping for even books will be done,

02:47:36.060 --> 02:47:40.160
right? So that whenever you will start, you don't have to

02:47:40.160 --> 02:47:43.040
start, or even you have to go and search for the courses,

02:47:43.280 --> 02:47:47.680
right? Just follow along the go to that page roadmap. Let's

02:47:47.680 --> 02:47:49.620
suppose you are preparing generative AI, right? Go to the

02:47:49.620 --> 02:47:52.380
generative AI roadmap page and then start tracking it from

02:47:52.380 --> 02:47:55.860
there. So I'm preparing it. I'm already preparing it. I'm

02:47:55.860 --> 02:47:59.400
already working in that on that. So a beautiful, like a

02:47:59.400 --> 02:48:03.080
roadmap page with the attachment of this tree and graph,

02:48:03.220 --> 02:48:06.040
everything you will be able to find out. So in a smoothest

02:48:06.040 --> 02:48:08.580
possible way, without even asking for a roadmap, without

02:48:08.580 --> 02:48:11.920
even asking for a guidance from anyone, you will be able to

02:48:11.920 --> 02:48:16.140
move through it till a job starting from the course

02:48:16.140 --> 02:48:19.040
selection in between URI, then resume, then intensive,

02:48:19.160 --> 02:48:21.940
everything, books, projects, everything, uh, finding,

02:48:22.020 --> 02:48:25.360
because we understand that, uh, as the number of offerings

02:48:25.360 --> 02:48:28.480
is going to increase, it'll become a little bit confusing,

02:48:28.620 --> 02:48:30.900
right? For all of us that, which one I should pick, which

02:48:30.900 --> 02:48:34.940
one I should not. So, uh, like, and, and we will keep on

02:48:34.940 --> 02:48:37.220
bringing more and more offerings, so we are not going to

02:48:37.220 --> 02:48:39.520
stop it. Right. So we are going to like, uh, bring more and

02:48:39.520 --> 02:48:42.220
more offerings. Uh, but yeah, at the same point of time, I

02:48:42.220 --> 02:48:45.340
have to remove my students confusion as well. So that will

02:48:45.340 --> 02:48:47.560
be released next week. It's already planned and we are

02:48:47.560 --> 02:48:51.660
already like, uh, working on that, but I think, uh, 12 or 15

02:48:51.660 --> 02:48:54.080
roadmap, a different, different roadmap. Uh, you will be

02:48:54.080 --> 02:48:55.780
able to see it. Yeah. Yeah. Yeah. In a beautiful manner,

02:48:55.860 --> 02:48:57.940
believe me, you will like it, right. You will like it. And

02:48:57.940 --> 02:49:00.400
after that, you don't have to go anywhere and watch the,

02:49:00.420 --> 02:49:04.000
like how to do this or how to do that. Or roadmap for this

02:49:04.000 --> 02:49:06.500
roadmap for that, you don't have to like, uh, uh, follow

02:49:06.500 --> 02:49:09.820
anything, just one place. And then, because that is the only

02:49:09.820 --> 02:49:14.440
thing which I believe is pending from my side, just, just

02:49:14.440 --> 02:49:18.000
wait till this, this week, uh, because I know that that's a

02:49:18.000 --> 02:49:20.420
real problem. And as the number of courses will increase,

02:49:20.540 --> 02:49:22.940
the problem will increase. I completely understand that

02:49:22.940 --> 02:49:26.560
part. Uh, we will miss the life system. They don't worry

02:49:26.560 --> 02:49:30.200
about the live. So this time, what I will do is that, uh, as

02:49:30.200 --> 02:49:32.440
of now, I'm just speaking, I'm looking into your comments

02:49:32.440 --> 02:49:34.940
and this is how we are doing a live, right. Uh, I have

02:49:34.940 --> 02:49:37.920
decided that going forward, uh, maybe from this month

02:49:37.920 --> 02:49:41.820
itself. So in every two or three week, we'll send a zoom

02:49:41.820 --> 02:49:44.760
link, right. We'll send a zoom link and, uh, for a

02:49:44.760 --> 02:49:48.040
particular time, right. And whoever is available, come and

02:49:48.040 --> 02:49:51.060
let's have a discussion. So going forward, discussion will

02:49:51.060 --> 02:49:54.680
be even like, uh, more engaging. So even, uh, you can unmute

02:49:54.680 --> 02:49:57.740
yourself. Uh, yeah. Uh, you can, you know, like, uh, uh,

02:49:57.880 --> 02:50:01.220
like, uh, on your camera and then we both can have our

02:50:01.220 --> 02:50:04.920
discussion along with other people. So that I will do in

02:50:04.920 --> 02:50:07.900
every two to three weeks, right. And that too, with the zoom

02:50:07.900 --> 02:50:10.600
so that, you know, you can talk and then, because in this

02:50:10.600 --> 02:50:13.460
existing system that I have created, so this is for taking a

02:50:13.460 --> 02:50:16.980
life classes. So in life classes, uh, because just to avoid

02:50:16.980 --> 02:50:20.480
my disturbance for myself, I have not given a, like this,

02:50:20.660 --> 02:50:24.040
uh, unmute option. I can do that, but yeah, I have not done

02:50:24.040 --> 02:50:28.520
that. Uh, purposely. Uh, because, uh, yeah, I just want a

02:50:28.520 --> 02:50:33.280
little bit of peaceful delivery of, uh, lectures. Uh, but,

02:50:33.340 --> 02:50:34.960
uh, now I'll do it.

02:50:38.770 --> 02:50:41.730
Hope we'll get a link over a mail, which, which link, by the

02:50:41.730 --> 02:50:45.470
way, which link, if you can tell me, I can clarify.

02:50:50.150 --> 02:50:53.050
Thank you so much. It's been a great journey. You learn a

02:50:53.050 --> 02:50:55.150
lot, given many interviews and wanted to find out our

02:50:55.150 --> 02:50:57.090
interview in three companies. Soon I will come up with,

02:50:57.090 --> 02:51:00.070
okay. I'm not, I'm waiting for you, man. I'm waiting for

02:51:00.070 --> 02:51:03.850
you. Yeah. Yeah. Yeah. Just waiting, waiting for you.

02:51:08.440 --> 02:51:11.260
A zoom link. I'll ping you in a group itself. So zoom for

02:51:11.260 --> 02:51:14.580
zoom link. So like, uh, uh, it is, it is, it is, there is no

02:51:14.580 --> 02:51:17.560
like a schedule I'm going to set my like, uh, there is no

02:51:17.560 --> 02:51:20.300
like a proper time. I'm going to say that, okay, this time

02:51:20.300 --> 02:51:23.400
or that time, uh, we'll ping you in a WhatsApp group itself.

02:51:23.540 --> 02:51:25.880
And as, and when people will be available, people will say

02:51:25.880 --> 02:51:28.780
yes. So maybe in a weekdays, maybe in a weekend. So we'll

02:51:28.780 --> 02:51:32.440
come together, we'll have a chit chat. So maybe kind of a

02:51:32.440 --> 02:51:35.300
informal discussion. Yeah. So that you will be able to get

02:51:35.300 --> 02:51:37.440
it into a WhatsApp group. Anyhow. We have a WhatsApp group.

02:51:39.740 --> 02:51:42.540
So I'm not, I'm not going to like, uh, keep it like a formal

02:51:42.540 --> 02:51:42.780
way.

02:51:57.240 --> 02:52:00.700
Yeah. So any, any other question for me, please go ahead,

02:52:00.800 --> 02:52:03.480
please like, uh, let me know. I'll answer.

02:52:11.740 --> 02:52:15.940
Super top. Okay. Thank you. I think I have answered all the

02:52:15.940 --> 02:52:19.280
question. I don't think that any is anyone is pending. I

02:52:19.280 --> 02:52:23.340
have been walking before 5am to join your live classes from

02:52:23.340 --> 02:52:25.500
New York. Thank you. Thank you so much Imtiaz. Thank you so

02:52:25.500 --> 02:52:29.480
much. I know that like it's, it's a lot of pain. Like, uh,

02:52:29.640 --> 02:52:34.000
you know, joining from a different time zone. So, uh, really

02:52:34.000 --> 02:52:38.700
appreciate it here and hope, hope, uh, uh, you are able to

02:52:38.700 --> 02:52:41.080
learn at least a little bit, not much, but, uh, yeah, at

02:52:41.080 --> 02:52:42.600
least a little bit from this, these sessions.

02:52:45.360 --> 02:52:48.880
Okay. So shall we end this lecture guys, today's lecture,

02:52:48.980 --> 02:52:52.180
shall we end this class now? Yeah. Say yes. And then we are

02:52:52.180 --> 02:52:56.200
going to end it and we'll see you again. Thanks for the

02:52:56.200 --> 02:52:57.840
great work you're doing. Thank you so much Ranjit. Thank

02:52:57.840 --> 02:52:58.000
you.

02:53:03.200 --> 02:53:06.280
Yeah. So, okay. Fine. Thank you so much, everyone. Thank you

02:53:06.280 --> 02:53:08.500
so much. Uh, you were the wonderful audience, wonderful

02:53:08.500 --> 02:53:12.600
student. Uh, the only thing which matters is that, that try

02:53:12.600 --> 02:53:14.880
to get some sort of a success in terms of building, in terms

02:53:14.880 --> 02:53:17.380
of switching, in terms of getting a growth in a career that

02:53:17.380 --> 02:53:19.640
that's going to be a real success. That's part number one.

02:53:19.960 --> 02:53:23.220
Part number two is, uh, world is very small. Believe me,

02:53:23.240 --> 02:53:26.360
world is very small. And at some point of a time, everyone

02:53:26.360 --> 02:53:29.880
needs someone. That's a reason. So I have created a WhatsApp

02:53:29.880 --> 02:53:33.160
group so that all of you will be connected for a very, very

02:53:33.160 --> 02:53:36.080
long time. And that WhatsApp group is not just for connect.

02:53:36.740 --> 02:53:40.200
That is also for networking, right? That is also for helping

02:53:40.200 --> 02:53:44.980
each other. So actually genuine help. I know that sometime

02:53:44.980 --> 02:53:47.720
what happens in these groups are that a lot of noise, a lot

02:53:47.720 --> 02:53:50.320
of people, and then like a lot of unnecessary discussion

02:53:50.320 --> 02:53:53.840
happens. I truly agree with it. And we all can't avoid it,

02:53:53.900 --> 02:53:57.900
uh, in this world, in this digital world. But yeah, a

02:53:57.900 --> 02:54:00.720
people, a person who is genuine, so try to maintain a

02:54:00.720 --> 02:54:04.700
friendship with those person. Help each other as and when it

02:54:04.700 --> 02:54:06.780
is required. Maybe today, tomorrow, or even after five

02:54:06.780 --> 02:54:09.100
years, right? Because the world is not going to end

02:54:09.100 --> 02:54:12.200
tomorrow. People will need people even after 10 years,

02:54:12.360 --> 02:54:15.740
right? And who knows how this relationship that you are

02:54:15.740 --> 02:54:19.700
trying to build now today, right? Will turn out after five

02:54:19.700 --> 02:54:23.360
years, after 10 years, right? So try to build that kind of a

02:54:23.360 --> 02:54:28.340
relationship. Believe me, you need a human being, right? You

02:54:28.340 --> 02:54:31.780
will need a help. You will need assistance. Maybe not. Maybe

02:54:31.780 --> 02:54:36.720
not today, but maybe after 10 years, right? But yes. So the

02:54:36.720 --> 02:54:38.680
day you are going to need a help, you will not get it

02:54:38.680 --> 02:54:42.920
immediately if you have not worked for it. So try to build a

02:54:42.920 --> 02:54:46.340
good relation, uh, try to like, uh, you know, the good

02:54:46.340 --> 02:54:48.380
relation, not in terms of just a talk, I would say, because,

02:54:48.380 --> 02:54:51.400
uh, that relation never lasts. That's the relation, which I

02:54:51.400 --> 02:54:54.900
always believe in is to the fruitful relation. I'm doing

02:54:54.900 --> 02:54:57.760
something for you, right? I'm building something for you.

02:54:57.800 --> 02:55:01.420
I'm helping like in a real sense. Then I can expect that.

02:55:01.420 --> 02:55:03.740
Okay, fine. I will be able to get help at some point of a

02:55:03.740 --> 02:55:06.840
time someday. So try to build that kind of a relation. We

02:55:06.840 --> 02:55:09.220
have a beautiful group. We have a beautiful people over

02:55:09.220 --> 02:55:13.460
there, right? Use it and leverage it. Even after 10 year

02:55:13.460 --> 02:55:16.760
avoid unnecessary discussion, right? I don't think that

02:55:16.760 --> 02:55:19.440
it's, it's worth of doing unnecessary discussion. And I

02:55:19.440 --> 02:55:22.900
believe in our group, uh, people are very decent. Uh, uh, so

02:55:22.900 --> 02:55:26.100
I think, uh, except one or two incident, which I have seen

02:55:26.100 --> 02:55:29.340
in my group. Uh, so in your group, especially, right? Your

02:55:29.340 --> 02:55:31.680
group. I don't think that we had any kind of discussion. So

02:55:31.680 --> 02:55:36.020
people are literally very genuine, very decent, uh, right?

02:55:36.340 --> 02:55:39.960
So maybe you can connect with them personally, not in a

02:55:39.960 --> 02:55:43.400
group, right? DM them, but don't, don't try to bug them

02:55:43.400 --> 02:55:46.340
unnecessary again. Otherwise they have option to you and

02:55:46.340 --> 02:55:50.240
block you. Right? Uh, so that, uh, try to build a strong

02:55:50.240 --> 02:55:53.140
friendship, a strong relationship, help each other at the

02:55:53.140 --> 02:55:56.380
end of the day. That is something which matters, right? Then

02:55:56.380 --> 02:55:58.920
you will be able to remember your own for a very, very long

02:55:58.920 --> 02:56:01.580
time that, okay, you're on was the reason. Yeah. We are a

02:56:01.580 --> 02:56:07.590
friend and now we are helping each other. Yes. But that, uh,

02:56:07.870 --> 02:56:10.750
uh, thank you so much. I'll keep on building new things for

02:56:10.750 --> 02:56:14.730
all of you. Service project goes everything and yeah. See

02:56:14.730 --> 02:56:16.950
you again. So thank you so much. Everyone take care. .


WEBVTT

00:06:55.630 --> 00:06:58.050
okay so good morning everyone i think i'm audible and

00:06:58.050 --> 00:07:00.610
visible to all of you yeah so we'll start in some time maybe

00:07:00.610 --> 00:07:03.770
in like a next five six minute we are going to start with

00:07:03.770 --> 00:07:09.020
the class hope all of you are enjoying your sunday and uh

00:07:09.020 --> 00:07:11.980
yeah so you already had your morning tea i'm

00:07:14.640 --> 00:07:19.920
having mine now so yeah we'll start in like a five six

00:07:19.920 --> 00:07:22.020
minute yeah okay

00:09:54.370 --> 00:09:58.810
so uh shall we start everyone so any anyone who can tell me

00:09:58.810 --> 00:10:01.190
like what should be the agenda for today so what we are

00:10:01.190 --> 00:10:07.160
going to discuss in today's class yeah anyone okay

00:10:09.520 --> 00:10:13.700
so somebody is saying fine tuning okay yeah yeah so fine

00:10:13.700 --> 00:10:16.180
tuning is something that we are going to discuss we'll start

00:10:16.180 --> 00:10:19.120
discussing so it's not like we are going to complete this

00:10:19.120 --> 00:10:22.640
fine tuning today uh it will take a couple of session for us

00:10:22.640 --> 00:10:25.980
because fine tuning is again a very very important chapter

00:10:25.980 --> 00:10:30.840
and a kind of a chapter uh which you can write directly into

00:10:30.840 --> 00:10:34.120
your resume as an application that okay i have done this

00:10:34.120 --> 00:10:37.620
kind of fine tuning that kind of fine tuning so uh again

00:10:37.620 --> 00:10:40.820
it's very important it's just as important like a rag

00:10:40.820 --> 00:10:43.940
concept or agent concept so rag concept we have already

00:10:43.940 --> 00:10:47.240
discussed a lot uh in the beginning if you remember in this

00:10:47.240 --> 00:10:51.460
batch and then back to back we talked about a lot of agent

00:10:51.460 --> 00:10:54.040
with respect to a different different kind of a like a

00:10:54.040 --> 00:10:57.600
framework now it's time to talk about a fine tuning because

00:10:57.600 --> 00:11:02.380
fine tuning is also a major task that we all as a generative

00:11:02.380 --> 00:11:07.180
ai engineer on any level try to perform and which is again

00:11:07.180 --> 00:11:10.940
very much crucial for any businesses that you will be able

00:11:10.940 --> 00:11:14.700
to find out out there inside a generative ai like a market

00:11:14.700 --> 00:11:15.760
yep

00:11:18.000 --> 00:11:20.940
so that is the reason so we'll try to discuss about this

00:11:20.940 --> 00:11:24.900
entire fine tuning approach uh in a very practical manner

00:11:24.900 --> 00:11:29.040
and not just that so we'll try to even host this time not

00:11:29.040 --> 00:11:33.140
just one single model but a multiple model so last time we

00:11:33.140 --> 00:11:35.540
have already hosted one single model i think with the help

00:11:35.540 --> 00:11:38.820
of vllm right uh vllm was again one of the like-minded ones

00:11:38.820 --> 00:11:42.000
and vllm has been used for like you know a chat gpt or open

00:11:42.000 --> 00:11:46.020
ai compatible model hosting you can say uh here we'll try to

00:11:46.020 --> 00:11:48.380
see that how we can try to host a different different kind

00:11:48.380 --> 00:11:53.460
of a model over a gpu over a cloud how we can try to train

00:11:53.460 --> 00:11:57.040
those model over a gpu so again if you will be having a gpu

00:11:57.040 --> 00:12:02.280
in on premises or maybe over a cloud or in local you will be

00:12:02.280 --> 00:12:05.460
able to do everything means technically you just need a

00:12:05.460 --> 00:12:09.300
machine that's it like machine can be available on aistantly

00:12:09.300 --> 00:12:09.300
you will be able to do everything means technically you just

00:12:09.300 --> 00:12:09.300
need a machine say so we'll definitely feel comfortable

00:12:09.300 --> 00:12:10.580
using it as well hear on a cloud platform or maybe on

00:12:10.580 --> 00:12:13.100
premises maybe in your local system store in your local

00:12:13.100 --> 00:12:15.780
system i will be able to use it i will be able to host it i

00:12:15.780 --> 00:12:20.360
will be able to like you know uh inference it with respect

00:12:20.360 --> 00:12:21.440
to the entire world

00:12:24.040 --> 00:12:28.280
was super affordable also one lakh token is not easy sir you

00:12:28.280 --> 00:12:33.480
are doing awesome thank you so basically uh you will i think

00:12:33.480 --> 00:12:37.000
in couple of week uh not couple of week i would say maybe by

00:12:37.000 --> 00:12:41.300
by next week itself you all will be able to learn that you

00:12:41.300 --> 00:12:45.760
know majorly the back-end part right little bit you all will

00:12:45.760 --> 00:12:49.100
be able to understand that let's suppose if I have to build

00:12:49.100 --> 00:12:52.000
a URI kind of a system right so where I'm not using a

00:12:52.000 --> 00:12:54.940
proprietary model so forget about this chat GPT and all

00:12:54.940 --> 00:12:57.960
let's suppose I'm using Lama series I'm using Mistral series

00:12:57.960 --> 00:13:03.160
and some other series of model which is openly available to

00:13:03.160 --> 00:13:06.800
me which I can download right which I can download so how we

00:13:06.800 --> 00:13:10.340
can like host it on our platform and then how we can like

00:13:10.340 --> 00:13:17.800
give you inside a chat interface for example URI yeah plus

00:13:17.800 --> 00:13:21.780
we are trying to take one more step ahead so I think we all

00:13:21.780 --> 00:13:24.140
are aware about a whatsapp number I believe I have already

00:13:24.140 --> 00:13:29.600
shared inside your group right even yesterday we were

00:13:29.600 --> 00:13:34.540
talking about it yeah so basically we are trying to make it

00:13:34.540 --> 00:13:36.660
in such a way that instead of using a chat interface we are

00:13:36.660 --> 00:13:36.660
trying to make it in such a way that we are trying to make

00:13:36.660 --> 00:13:39.600
it in such a way a URI people can directly interact over a

00:13:39.600 --> 00:13:43.340
whatsapp because that would be even more easy right we don't

00:13:43.340 --> 00:13:47.400
have to come here so on whatsapp we all are available 24 by

00:13:47.400 --> 00:13:51.340
7 and we are trying to make it in such a way that going

00:13:51.340 --> 00:13:54.440
forward if someone is looking for you know like interview

00:13:54.440 --> 00:13:58.260
preparation so it will be so let's suppose we have already

00:13:58.260 --> 00:14:00.780
prepared a lot of interview preparation series and directly

00:14:00.780 --> 00:14:03.760
it will be able to give you you will be even able to search

00:14:03.760 --> 00:14:06.640
a single video on a single topic going forward so let's

00:14:06.640 --> 00:14:06.640
suppose we have already prepared a lot of interview

00:14:06.640 --> 00:14:06.840
preparation series and directly it will be able to give you

00:14:06.840 --> 00:14:06.840
you will be able to search a single video on a single topic

00:14:06.840 --> 00:14:09.520
going forward so we are we are just working on that part it

00:14:09.520 --> 00:14:13.780
will take maybe like a couple of more weeks for us maybe

00:14:13.780 --> 00:14:19.100
like a next whole month but yeah so we'll be able to achieve

00:14:19.100 --> 00:14:24.570
that part all indian language it already supports so don't

00:14:24.570 --> 00:14:27.730
have to worry about indian languages so it already supports

00:14:27.730 --> 00:14:30.550
all the language when you can like even tone not just a

00:14:30.550 --> 00:14:33.570
language I'm talking about just like you know uh change your

00:14:33.570 --> 00:14:37.970
tone right and again just see the response it will be like a

00:14:37.970 --> 00:14:39.270
again just see the response it will be like a amazing so we

00:14:39.270 --> 00:14:42.350
have we have already worked on that part as well a

00:14:46.320 --> 00:14:51.320
real application of you can say agent rag and you know model

00:14:51.320 --> 00:14:58.200
hosting basically like yuri ai the mobile application that

00:14:58.200 --> 00:15:03.120
we are trying to build okay so let's are you mean even we

00:15:03.120 --> 00:15:05.740
will able to learn how to token are working and how to use

00:15:05.740 --> 00:15:07.980
all those things exactly yeah this is what i was talking

00:15:07.980 --> 00:15:11.600
about right so then only i can say or even you can say

00:15:11.600 --> 00:15:15.080
proudly that okay i have built something and then only you

00:15:15.080 --> 00:15:18.540
will be able to write something in your resume yeah if i'm

00:15:18.540 --> 00:15:21.600
going to like you know not teach you those things how you

00:15:21.600 --> 00:15:26.320
will be able to write it inside a resume it won't be real

00:15:26.320 --> 00:15:29.420
right okay so classing what what is your agent approach

00:15:29.420 --> 00:15:33.040
working helping why do we need a fine tuning okay so the

00:15:33.040 --> 00:15:36.360
question is that that if we have rag agentic approach

00:15:36.360 --> 00:15:41.000
working and helping so why do we need a fine tuning so so

00:15:41.000 --> 00:15:44.920
far in a class majorly we have discussed as per the syllabus

00:15:44.920 --> 00:15:49.780
so we talked about rag right and then we talked about a

00:15:49.780 --> 00:15:53.340
agentic approach yeah and then yesterday we have mixed rag

00:15:53.340 --> 00:15:57.000
plus agentic approach both with the help of like autogen so

00:15:57.000 --> 00:15:59.840
when we were trying to you know create a report generator

00:15:59.840 --> 00:16:03.520
and i believe you all have executed that code you all have

00:16:03.520 --> 00:16:06.560
gone through that code agent part is just one single like

00:16:06.560 --> 00:16:09.880
you know python file rest was just a helper file that we

00:16:09.880 --> 00:16:12.720
have created for scheduling and then for sending a mail for

00:16:12.720 --> 00:16:16.460
connecting with the telegram so a question is a valid

00:16:16.460 --> 00:16:20.960
question by the way that if we already have a rag and if we

00:16:20.960 --> 00:16:24.680
already have a agentic approach right then why do we need a

00:16:24.680 --> 00:16:29.800
fine tuning any idea guys yeah any idea so why do we need a

00:16:29.800 --> 00:16:35.010
like fine tuning anyone who can like try to give an answer

00:16:35.010 --> 00:16:40.770
for this scalar charging lot for jni course in less yeah

00:16:40.770 --> 00:16:43.910
like people are charging whatever they want and people

00:16:43.910 --> 00:16:46.870
people are even paying for it. Just to make it more

00:16:46.870 --> 00:16:51.490
accurate, no, not a correct answer for a purpose of a

00:16:51.490 --> 00:16:54.210
specific task, maybe.

00:16:55.950 --> 00:17:01.770
Just try to explain me, you know, as a layman, think like I

00:17:01.770 --> 00:17:04.630
don't understand anything and then maybe try to explain it

00:17:04.630 --> 00:17:09.580
to me. Direct generator response to domain is specific

00:17:09.580 --> 00:17:15.460
without RAG. I mean, like, OK, that's a part, but still, if

00:17:15.460 --> 00:17:19.380
data is won't change frequently, fine tuning is good instead

00:17:19.380 --> 00:17:22.680
of maintaining vector DV. Yeah, that's a correct answer. One

00:17:22.680 --> 00:17:26.680
of the correct answer for output inferences, no, not exactly

00:17:26.680 --> 00:17:29.560
domain specific when data is not changing frequently. Yeah,

00:17:29.560 --> 00:17:31.900
this is also like giving me the same answer, which is the

00:17:31.900 --> 00:17:35.480
correct one. By doing like customization data changing once

00:17:35.480 --> 00:17:38.360
in a while, we can use a fine tuning. Yeah. Tabis is saying

00:17:38.360 --> 00:17:43.000
like he's correct. To reduce the hallucination, no, it never

00:17:43.000 --> 00:17:46.940
guarantees you the reduction in hallucination. So maybe like

00:17:46.940 --> 00:17:51.300
there is a way to control hallucination. So I mean, like,

00:17:51.300 --> 00:17:55.140
not just this way, you're

00:17:56.900 --> 00:17:59.680
going to add knowledge according to my domain. OK, context,

00:17:59.800 --> 00:18:03.220
avoid hallucination, update and retain weight. I mean, like

00:18:03.220 --> 00:18:05.380
this is what we do as a part of fine tuning. We update and

00:18:05.380 --> 00:18:08.600
retain the weights to get a better response as per our data

00:18:08.600 --> 00:18:14.820
rather than guessing the result. OK. So let me like tell you

00:18:14.820 --> 00:18:18.660
one thing, right? So we all understand where RIG fits in,

00:18:18.740 --> 00:18:23.840
right? So RIG is a kind of a technique. So where we will try

00:18:23.840 --> 00:18:28.480
to hold our data in some vector databases in a form, in a

00:18:28.480 --> 00:18:31.020
certain form technically in a embedding format. So we are

00:18:31.020 --> 00:18:34.320
going to hold those data and whenever there will be a query.

00:18:34.400 --> 00:18:38.360
So this will go to our database and then it will try to

00:18:38.360 --> 00:18:41.820
match. It will try to pull n number of record. Top n number

00:18:41.820 --> 00:18:45.920
of record. Maybe it will try to implement a Cohera kind of a

00:18:45.920 --> 00:18:48.760
re-ranking approach or re-ranking precisely. We can try to

00:18:48.760 --> 00:18:53.320
implement and query plus data it will try to bring and then

00:18:53.320 --> 00:18:58.100
combine it and send these data to the LLM. I believe we are

00:18:58.100 --> 00:19:01.540
pretty much clear with RIG approach, right? None of us have

00:19:01.540 --> 00:19:05.800
doubt, yeah, with respect to RIG approach. So I believe even

00:19:05.800 --> 00:19:10.040
in our sleep, we will be able to explain like very, very

00:19:10.040 --> 00:19:13.080
clearly. OK. As an RIG approach, because we have done a lot

00:19:13.080 --> 00:19:16.320
of application, a lot of things. Let me share my screen

00:19:16.320 --> 00:19:20.080
first. Maybe I can draw something and then I can talk about

00:19:20.080 --> 00:19:22.920
it. So

00:19:28.110 --> 00:19:28.630
basically,

00:19:31.570 --> 00:19:37.210
when we talk about RIG approach, so as we have been talking

00:19:37.210 --> 00:19:41.490
about this since a very, very long time. So RIG is nothing

00:19:41.490 --> 00:19:46.630
but we will be having query. And then I will be having a

00:19:46.630 --> 00:19:51.670
data, right. So I will be having a query and then I will be

00:19:51.670 --> 00:19:52.090
having a

00:20:03.700 --> 00:20:12.720
data in vector db. Let's suppose we will be having.

00:20:18.320 --> 00:20:21.600
So whenever we are going to see a query and we will be

00:20:21.600 --> 00:20:24.880
having a data into a vector db. So what we will do? So

00:20:24.880 --> 00:20:30.820
basically, we will try to combine this query plus data. So

00:20:30.820 --> 00:20:35.260
basically, like a query will go to this one query will go to

00:20:35.260 --> 00:20:39.740
a vector db. It will try to fetch any number of record. Let

00:20:39.740 --> 00:20:44.660
me remove this part. So technically, it will go to a vector

00:20:44.660 --> 00:20:49.980
db and this is going to return me top

00:20:58.420 --> 00:20:59.900
end record.

00:21:06.790 --> 00:21:10.010
And what I will do with this top end record, so technically,

00:21:10.110 --> 00:21:12.830
I will try to maybe do a re-ranking,

00:21:16.430 --> 00:21:18.270
just to make my like. OK. So we will try to make the record

00:21:18.270 --> 00:21:23.050
more aligned. So we'll do a re-ranking of the data, for

00:21:23.050 --> 00:21:27.810
example, Kohira re-ranking, BM25 re-ranking, something like

00:21:27.810 --> 00:21:32.930
that we can try to use. And once we will be able to do a re

00:21:32.930 --> 00:21:37.010
-ranking of this data, then what we are going to perform. So

00:21:37.010 --> 00:21:42.790
we are going to basically add a query plus a data output

00:21:42.790 --> 00:21:46.250
that we are able to receive. So technically, we will try to

00:21:46.250 --> 00:21:49.530
over here. So we are going to basically add a query plus a

00:21:49.530 --> 00:21:49.530
data output that we are able to receive.

00:22:00.660 --> 00:22:02.880
So it will try to, we

00:22:20.640 --> 00:22:23.940
will

00:22:23.940 --> 00:22:26.260
try to take query plus previous output, previous output

00:22:26.260 --> 00:22:29.280
means whatever re-ranking output we are going to get. And

00:22:29.280 --> 00:22:33.120
then we are going to send this entire data to our LLM. So

00:22:33.120 --> 00:22:38.300
this is what we generally do in case of RAG operandion. LLM,

00:22:38.380 --> 00:22:45.020
right. Right. we'll try to send this entire data to the llm

00:22:45.020 --> 00:22:49.920
and as per the task so llm is going to or as per the system

00:22:49.920 --> 00:22:52.620
messages that we are going to give the instruction that we

00:22:52.620 --> 00:22:56.100
are going to give right so in case of agents obviously there

00:22:56.100 --> 00:22:58.440
will be a system message otherwise it is going to be just a

00:22:58.440 --> 00:23:02.180
user message that we are going to send and based on the like

00:23:02.180 --> 00:23:05.620
this llm so whatever llm that we are trying to use whatever

00:23:05.620 --> 00:23:09.020
series of llm that we are trying to use so it is going to

00:23:09.020 --> 00:23:13.000
basically like a refine this entire output right so if

00:23:13.000 --> 00:23:16.420
something needs to be added from a internet from the world

00:23:16.420 --> 00:23:20.120
outer world it will try to add it if it is just supposed to

00:23:20.120 --> 00:23:22.600
do a summarization so it will just try to do a summarization

00:23:22.600 --> 00:23:26.140
so if i'm saying that okay fine so whatever output that you

00:23:26.140 --> 00:23:28.600
are able to get so just try to give me in this particular

00:23:28.600 --> 00:23:33.080
format means output format right so this is where llm comes

00:23:33.080 --> 00:23:36.480
into a picture and then finally i will be able to get the

00:23:36.480 --> 00:23:39.420
output and i believe this is our understanding of the l l m

00:23:39.420 --> 00:23:39.420
and i will be able to get the output and i believe this is

00:23:39.420 --> 00:23:45.790
our understanding about rag right everyone yeah so this

00:23:45.790 --> 00:23:50.910
understanding is correct everyone yes now so this is plain

00:23:50.910 --> 00:23:54.510
rag you can say so whenever we again lot goes inside this

00:23:54.510 --> 00:23:57.670
rag so whenever we try to build rag kind of a system so

00:23:57.670 --> 00:24:00.810
metadata filtering again a similarity check goes into a

00:24:00.810 --> 00:24:03.790
picture which kind of embedding we are supposed to use what

00:24:03.790 --> 00:24:07.130
model for our embedding what model for a re-ranking

00:24:07.130 --> 00:24:10.690
basically all of these things what databases again vector

00:24:10.690 --> 00:24:14.430
data bases right so there is a complete ecosystem around rag

00:24:14.430 --> 00:24:19.470
all you all will able to find out yeah so not just one thing

00:24:19.470 --> 00:24:24.650
you an able to find out a multi right things so rag you now

00:24:24.650 --> 00:24:27.840
able to find a multiple things so basically yeah so this is

00:24:27.840 --> 00:24:30.980
like a technically i can say that okay fine this is the rag

00:24:30.980 --> 00:24:36.360
that we are talking about okay that is great now we will

00:24:36.360 --> 00:24:39.980
talk a about the agentic RAG then what is going to change

00:24:39.980 --> 00:24:42.640
over here so whenever we are going to talk about the agentic

00:24:42.640 --> 00:24:48.400
RAG so over here we will be able to see a kind of an entity

00:24:48.400 --> 00:24:52.480
or agent so agent means what agent means a kind of an entity

00:24:52.480 --> 00:24:56.920
which is having a LLM access part number one which is having

00:24:56.920 --> 00:25:00.240
certain memory which is having a n number of tool access

00:25:00.240 --> 00:25:04.140
technically it is a tool which comes into a play like memory

00:25:04.140 --> 00:25:06.340
wise so we can try to use one or two memory that's

00:25:06.340 --> 00:25:10.280
completely fine but when we say anything agentic anything

00:25:10.280 --> 00:25:13.420
agentic simply means that that it will be having a memory

00:25:13.420 --> 00:25:16.600
access it will be having a tool access and it will be having

00:25:16.600 --> 00:25:22.240
a like a basically memory tool and LLM access this is what

00:25:22.240 --> 00:25:27.460
we have seen so whether we are going ahead with n8n or maybe

00:25:27.460 --> 00:25:31.940
like any other platform and we have already used all of

00:25:31.940 --> 00:25:34.980
those platforms so we have used auto gen we have used n8n

00:25:34.980 --> 00:25:39.280
and all n number of platform we have used so everywhere when

00:25:39.280 --> 00:25:42.240
you go and when you try to create an agent you will be able

00:25:42.240 --> 00:25:46.340
to find out the same philosophy right so AI agent simply

00:25:46.340 --> 00:25:51.680
means that that there will be right there will be a model

00:25:51.680 --> 00:25:54.880
there will be memory and there will be a tool couple of more

00:25:54.880 --> 00:25:58.980
thing you will be able to add so here we have like all of

00:25:58.980 --> 00:26:02.400
those options so here we can try to add multiple things

00:26:02.400 --> 00:26:06.380
right but in general when there is a agent we are talking

00:26:06.380 --> 00:26:09.780
about so obviously we talk about majorly three things one is

00:26:09.780 --> 00:26:13.780
a chat basically chat LLM one is a memory right one is

00:26:13.780 --> 00:26:17.220
basically a tool I can try to add as many tool as possible

00:26:17.220 --> 00:26:20.660
then there is a output parser there is a fallback and all

00:26:20.660 --> 00:26:23.860
those things just a additional stuff right but in general

00:26:23.860 --> 00:26:26.400
agent means the kind of an entity which will be having three

00:26:26.400 --> 00:26:31.020
things now altogether what these three things does so

00:26:31.020 --> 00:26:33.440
altogether these three things will try to make a decision.

00:26:33.760 --> 00:26:37.420
What kind of a decision? So basically the very first part is

00:26:37.420 --> 00:26:40.380
that it will be able to understand your natural language

00:26:40.380 --> 00:26:44.100
input right so maybe I can talk to like this particular

00:26:44.100 --> 00:26:48.520
agent in a Hindi in English in Punjabi, Tamil, Telugu

00:26:48.520 --> 00:26:51.600
depends upon the LLM capability right if LLM is not capable

00:26:51.600 --> 00:26:53.920
enough in terms of doing an interpretation of the language a

00:26:53.920 --> 00:26:56.560
different language it will not be able to do it right but

00:26:56.560 --> 00:27:00.200
let us take an example of this URI AI by the way for now

00:27:00.840 --> 00:27:05.380
right so let us suppose I am talking to this URI AI. Now for

00:27:05.380 --> 00:27:10.960
now right this URI AI and maybe I am trying to ask that like

00:27:10.960 --> 00:27:15.900
okay so latest

00:27:17.780 --> 00:27:24.960
course ke baare mein baare mein batao right in Hindi

00:27:24.960 --> 00:27:30.420
language thik hai toh what what it will do so it will try to

00:27:30.420 --> 00:27:34.240
you know understand this entire context and then you know

00:27:34.240 --> 00:27:36.580
you'll know it will so as you can see it's typing so it

00:27:36.580 --> 00:27:39.860
started typing and then it has given me the output in a

00:27:39.860 --> 00:27:43.560
Hindi right it has given me output in a complete Hindi maybe

00:27:43.560 --> 00:27:49.260
I can say that give me in Tamil right give me this in Tamil

00:27:49.260 --> 00:27:52.560
language so it will try to give you in Tamil language I can

00:27:52.560 --> 00:27:55.840
ask in Telugu I can ask in any other languages so

00:27:55.840 --> 00:27:59.700
technically here inside a URI AI so you will be able to see

00:27:59.700 --> 00:28:02.860
that that we are using an agent somewhere right. So whenever

00:28:02.860 --> 00:28:06.180
we are going to send. This kind of a messages it will go to

00:28:06.180 --> 00:28:09.540
agent it takes a decision and not just one decision it is

00:28:09.540 --> 00:28:12.680
taking it is taking a multiple decision by the way so what

00:28:12.680 --> 00:28:15.160
kind of a decision so first of all it is trying to

00:28:15.160 --> 00:28:19.120
understand your question right your question it is trying to

00:28:19.120 --> 00:28:22.400
maybe normalize the entire question or you can say it is

00:28:22.400 --> 00:28:25.980
trying to like a normalize okay why it has not given me

00:28:25.980 --> 00:28:32.940
output in Tamil yeah let's see it should give me so

00:28:32.940 --> 00:28:39.140
basically it is trying to understand. My question Tamil I

00:28:39.140 --> 00:28:41.820
don't know whether it is able to understand it should be

00:28:41.820 --> 00:28:46.020
able to know I have

00:28:48.420 --> 00:28:51.080
asked this question in English and because of that it was

00:28:51.080 --> 00:28:57.240
working well so I don't know like Tamil so maybe tell me

00:28:57.240 --> 00:29:06.920
about latest course launch in Tamil language like it. So

00:29:06.920 --> 00:29:09.360
basically whenever I am trying to send this kind of okay so

00:29:09.360 --> 00:29:14.400
it has written something in Tamil in last yeah yeah it has

00:29:14.400 --> 00:29:17.340
it has written again something in Tamil maybe I can say that

00:29:17.340 --> 00:29:20.000
okay just write everything in Tamil so it will do it in

00:29:20.000 --> 00:29:22.680
Tamil or maybe if you are going to type in Tamil so it will

00:29:22.680 --> 00:29:26.420
automatically respond you back in Tamil yeah so like it is

00:29:26.420 --> 00:29:30.340
it is responding like to me in a Hindi yeah for me so Tamil

00:29:30.340 --> 00:29:33.060
Telugu Uriya Bengali Spanish French everything it will be

00:29:33.060 --> 00:29:35.760
able to understand a multi languages so technically what

00:29:35.760 --> 00:29:38.760
will happen. So whenever I give this input it go to my agent

00:29:38.760 --> 00:29:42.620
by the way agent try to take a decision that okay and agent

00:29:42.620 --> 00:29:46.580
can have a multiple LLM access right so when we say LLM so I

00:29:46.580 --> 00:29:49.320
can give a multiple LLM access to this one maybe a fallback

00:29:49.320 --> 00:29:52.900
LLMs maybe I can attach 10 LLMs over there and I can write

00:29:52.900 --> 00:29:55.900
maybe a conditions with respect to agent that use this LLM

00:29:55.900 --> 00:29:59.020
that LLM in this situation that situation depends context I

00:29:59.020 --> 00:30:01.940
can try to define. So basically agent will be having a

00:30:01.940 --> 00:30:04.900
multiple LLM access and here so we have again the same

00:30:04.900 --> 00:30:08.660
thing. So we will we have like a multiple LLM accesses and

00:30:08.660 --> 00:30:12.300
it try to first of all understand that okay so what user is

00:30:12.300 --> 00:30:15.700
trying to understand so maybe user is looking for some of

00:30:15.700 --> 00:30:21.100
the existing like a knowledge base output or user is looking

00:30:21.100 --> 00:30:24.340
for something from a internet user is looking for something

00:30:24.340 --> 00:30:28.460
from a LLM because in this kind of a question when I say

00:30:28.460 --> 00:30:31.720
tell me something about a course and I am not saying that

00:30:31.720 --> 00:30:35.120
okay. So basically course from which organization. So

00:30:35.120 --> 00:30:35.380
basically course from which organization. So we have

00:30:35.380 --> 00:30:38.500
configured it in such a way that it will be able to

00:30:38.500 --> 00:30:41.580
understand that okay I am talking about a your own courses

00:30:41.580 --> 00:30:44.260
right I could have asked this question with respect to a

00:30:44.260 --> 00:30:47.220
Udemy course with respect to Coursera courses right but no

00:30:47.220 --> 00:30:50.680
it is trying to understand that okay user is asking me and

00:30:50.680 --> 00:30:53.580
user is not asking me a generic question right user is

00:30:53.580 --> 00:30:56.980
asking me certain specific to the organization to a

00:30:56.980 --> 00:31:01.360
knowledge base access that I have basically because I can go

00:31:01.360 --> 00:31:07.280
and I can try to ask a question that. Give me give me

00:31:07.280 --> 00:31:15.800
basically 10 for loop example in maybe python yeah now for

00:31:15.800 --> 00:31:18.200
this kind of a question it will not look into the knowledge

00:31:18.200 --> 00:31:20.480
base so whenever I am asking this kind of a question

00:31:20.480 --> 00:31:22.820
obviously it will not go and look into the knowledge base as

00:31:22.820 --> 00:31:25.860
you can see right so it will it will go to the LLM and it

00:31:25.860 --> 00:31:29.440
will start generating the answer basically yeah it will and

00:31:29.440 --> 00:31:32.600
it is see it is able to understand the Hindi and it is able

00:31:32.600 --> 00:31:35.940
to understand that this user's intent is in Hindi so maybe

00:31:35.940 --> 00:31:38.600
if you will talk in your language it will respond in your

00:31:38.600 --> 00:31:42.060
language yeah we have not integrated a real time search and

00:31:42.060 --> 00:31:44.440
speech so far but yeah very soon you will be able to find

00:31:44.440 --> 00:31:48.100
out that we will end up integrating that part as well lot of

00:31:48.100 --> 00:31:51.140
lot of feature we have like I have planned it has started

00:31:51.140 --> 00:31:54.960
just as a fun project for me one night you can say but yeah

00:31:54.960 --> 00:31:58.800
so we are like I have created a clear roadmap for this

00:31:58.800 --> 00:32:02.460
particular project UDI and WhatsApp so that you know all of

00:32:02.460 --> 00:32:06.120
us can enjoy. So, here you can see that when I say give me

00:32:06.120 --> 00:32:09.500
10 for loop example in python so obviously it will not go to

00:32:09.500 --> 00:32:13.240
my knowledge base it will not do the RAG operation what it

00:32:13.240 --> 00:32:17.620
will do so it will try to do a generation from a LLM now who

00:32:17.620 --> 00:32:21.020
is a decision maker over here right that what type of a

00:32:21.020 --> 00:32:24.860
question what I should do so obviously it is an agent now

00:32:24.860 --> 00:32:27.200
agent is a kind of an entity which will be having a LLM

00:32:27.200 --> 00:32:30.040
access right so with the help of this LLM because LLM is

00:32:30.040 --> 00:32:32.660
very much pretty much good in terms of you know

00:32:32.660 --> 00:32:34.740
understanding you know understanding a natural language

00:32:34.740 --> 00:32:37.540
whatever input I am going to give even if I am going to make

00:32:37.540 --> 00:32:40.240
some sort of a mistake it is completely okay with it and it

00:32:40.240 --> 00:32:43.780
will be able to interpret right so LLMs are powerful then

00:32:43.780 --> 00:32:48.760
based on this understanding it try to call a tools right

00:32:48.760 --> 00:32:52.000
tools means nothing but a function so function so let's

00:32:52.000 --> 00:32:55.600
suppose function wise I have to again call a LLMs or maybe I

00:32:55.600 --> 00:32:58.980
have to do some sort of a calculation or maybe I have to

00:32:58.980 --> 00:33:04.280
basically you know go with the RAG operation yeah. So if

00:33:04.280 --> 00:33:08.920
agent is trying to invoke your RAG means if agent is trying

00:33:08.920 --> 00:33:12.880
to perform these operations means agent is like taking a

00:33:12.880 --> 00:33:16.340
query making a decision and then going to a vector databases

00:33:16.340 --> 00:33:19.920
trying to fetch n number of record doing a re-ranking and

00:33:19.920 --> 00:33:22.960
then query plus like output it is trying to merge and then

00:33:22.960 --> 00:33:26.060
maybe like sending again to the LLMs this is called as what

00:33:26.060 --> 00:33:31.000
agentic RAG if agent is a decision maker there right so if

00:33:31.000 --> 00:33:34.960
RAG concept is has not changed right so if we are trying to

00:33:34.960 --> 00:33:38.960
drive those things with respect to our like agents then we

00:33:38.960 --> 00:33:42.740
say it's a agentic RAG yesterday we did the same thing right

00:33:42.740 --> 00:33:46.060
so we were using a framework called as autogen Microsoft

00:33:46.060 --> 00:33:50.180
autogen and basically we were like holding all the data into

00:33:50.180 --> 00:33:53.440
our vector databases and we were doing a RAG it was trying

00:33:53.440 --> 00:33:56.360
to like agent was trying to fetch the data and then like

00:33:56.360 --> 00:34:00.160
summarize it in my way the way I was looking for the way I

00:34:00.160 --> 00:34:03.140
have written the instruction. Now whenever agent comes in.

00:34:03.280 --> 00:34:06.580
into a picture so it makes our life lot easier because just

00:34:06.580 --> 00:34:10.400
by writing some like a couple of line in my language I can

00:34:10.400 --> 00:34:13.360
do a lot of task for which I will have to probably write a

00:34:13.360 --> 00:34:16.140
code but yeah so with the help of agent so I don't have to

00:34:16.140 --> 00:34:18.160
write the code so what I am trying to explain you is that

00:34:18.160 --> 00:34:21.820
vanilla RAG plain RAG and plus agentic RAG so both the

00:34:21.820 --> 00:34:25.040
approaches we have seen now coming to the next part right

00:34:25.040 --> 00:34:28.860
agentic so agentic is something that we were able to

00:34:28.860 --> 00:34:31.640
understand already so we were able to create a lot of like a

00:34:31.640 --> 00:34:33.960
agent and now we all understand. that what is the actually

00:34:33.960 --> 00:34:37.780
meaning of agent and one more thing you should not call

00:34:37.780 --> 00:34:40.880
agent all the time I have seen like unnecessary people you

00:34:40.880 --> 00:34:43.940
know try to do a over engineering and every time whenever

00:34:43.940 --> 00:34:46.860
like in all kind of automation they say that okay fine I

00:34:46.860 --> 00:34:49.920
will try to use a agent I mean like use it wherever it is

00:34:49.920 --> 00:34:53.700
required because it will come with the overheads it will

00:34:53.700 --> 00:34:57.080
come with some latency right because it is again a process

00:34:57.080 --> 00:35:00.160
right it is like trying to fetch the data trying to you know

00:35:00.160 --> 00:35:03.140
process those data so obviously it requires a compute it

00:35:03.140 --> 00:35:06.120
requires a network bandwidth so it will it comes with the

00:35:06.120 --> 00:35:09.200
overhead so it is not like it is not going to increase your

00:35:09.200 --> 00:35:13.040
latency so wisely you have to use a agent and obviously a

00:35:13.040 --> 00:35:17.180
memory part right so even in case of my URI AI so it

00:35:17.180 --> 00:35:20.780
understands me now right that okay so this user understands

00:35:20.780 --> 00:35:24.220
Hindi so let's try to you know try to explain this user in

00:35:24.220 --> 00:35:27.580
Hindi or maybe in Hinglish and this is where the memory play

00:35:27.580 --> 00:35:31.840
comes into a picture. Now this you know this understands me.

00:35:31.920 --> 00:35:32.420
So this is where the memory play comes into a picture. Now

00:35:32.420 --> 00:35:36.500
when you will start chatting with URI AI in your own tone in

00:35:36.500 --> 00:35:39.640
your own language it will start understanding you and this

00:35:39.640 --> 00:35:42.100
is where memory comes into picture and we have seen lot of

00:35:42.100 --> 00:35:44.920
different kind of a memory a summary memory a buffer memory

00:35:44.920 --> 00:35:49.180
or maybe like a cache a kind of a KV cache a key value pair

00:35:49.180 --> 00:35:52.580
cache a memory right so where we try to you know cache or we

00:35:52.580 --> 00:35:57.120
try to store like entities name of cities name of person

00:35:57.120 --> 00:36:01.140
inside a memory or windowing memory right windowing memory.

00:36:01.140 --> 00:36:03.780
Generally over here you will be able to find out this

00:36:03.780 --> 00:36:05.940
windowing memory a simple memory nothing but just a

00:36:05.940 --> 00:36:08.460
windowing memory right where you can you know try to

00:36:08.460 --> 00:36:11.740
remember couple of stuff from the last conversation. So

00:36:11.740 --> 00:36:14.620
memory wise again you will be able to see like same thing

00:36:14.620 --> 00:36:18.040
everywhere like concept is not very different. So this is

00:36:18.040 --> 00:36:21.280
what we have learnt so far and doesn't matter which

00:36:21.280 --> 00:36:24.740
framework you are going to use this fundamentals is going to

00:36:24.740 --> 00:36:28.580
be same and you will be able to use agent tech right and in

00:36:28.580 --> 00:36:30.840
a similar manner you have to go out and you have to explain.

00:36:31.140 --> 00:36:35.540
Whenever someone is asking about agents now so this agent

00:36:35.540 --> 00:36:40.580
and this RAG approach is completely fine so RAG approach in

00:36:40.580 --> 00:36:43.040
general we are going to use so where my data set is changing

00:36:43.040 --> 00:36:47.200
frequently right data set is changing frequently because in

00:36:47.200 --> 00:36:52.120
that case obviously it's not like a feasible for me to go

00:36:52.120 --> 00:36:55.400
and train the model again and again and again right because

00:36:55.400 --> 00:36:59.320
model training is a costliest approach approach. But let's

00:36:59.320 --> 00:37:03.920
suppose right. But let's suppose I have a kind of a

00:37:03.920 --> 00:37:06.980
situation so where my data is not changing for example HR

00:37:06.980 --> 00:37:09.860
policies obviously it is not going to change on a frequent

00:37:09.860 --> 00:37:13.600
basis right or policy with respect to any organization it is

00:37:13.600 --> 00:37:17.860
not going to change on a daily basis. Maybe some sort of you

00:37:17.860 --> 00:37:22.280
know financial like a report or maybe a financial data or

00:37:22.280 --> 00:37:25.840
maybe financial guidelines regulations it is again not going

00:37:25.840 --> 00:37:30.400
to change right maybe for some sort of you know. Marketing

00:37:30.400 --> 00:37:33.200
strategy so maybe I am not going to change my marketing

00:37:33.200 --> 00:37:36.960
strategy or maybe my sales pitch yeah my product has not

00:37:36.960 --> 00:37:40.320
changed so I will not try to change my sales pitch for a

00:37:40.320 --> 00:37:44.040
customer. So in every domain you will be able to find out a

00:37:44.040 --> 00:37:47.100
certain entities or certain data which is not changing

00:37:47.100 --> 00:37:52.240
frequently. Maybe in that situation so I can try to adopt a

00:37:52.240 --> 00:37:57.240
fine tuning approach yeah. Maybe I can I can go ahead and I

00:37:57.240 --> 00:38:00.000
can try to use agent tech inside a fine tuning that's okay.

00:38:00.080 --> 00:38:02.840
Because agent tech is something which is a decision maker

00:38:02.840 --> 00:38:07.640
unit right. Not output generator unit I mean like based on

00:38:07.640 --> 00:38:09.940
the decision so obviously some other entities are going to

00:38:09.940 --> 00:38:12.480
generate the output but yeah this is where agent tech comes

00:38:12.480 --> 00:38:14.760
into a picture. So person who have asked me question that

00:38:14.760 --> 00:38:16.980
when we have RAG and agent tech so you should not first of

00:38:16.980 --> 00:38:19.440
all compare with agent tech and this fine tuning maybe RAG

00:38:19.440 --> 00:38:22.480
versus fine tuning yeah you should do the comparison. So RAG

00:38:22.480 --> 00:38:24.860
means wherever data is changing frequently I will just go

00:38:24.860 --> 00:38:28.200
ahead with the RAG approach wherever. And again not all the

00:38:28.200 --> 00:38:31.120
time because I will check the cost right. So what is the

00:38:31.120 --> 00:38:35.660
cost for me to you know build one final model that's first

00:38:35.660 --> 00:38:38.960
thing that we all should check. The second thing that we all

00:38:38.960 --> 00:38:44.220
should like check over here the overheads because again and

00:38:44.220 --> 00:38:46.880
again you have to go for the retraining maybe in every month

00:38:46.880 --> 00:38:50.600
every like two month three month in that case I will not

00:38:50.600 --> 00:38:53.380
prefer to go ahead with the fine tuning. And again what kind

00:38:53.380 --> 00:38:56.160
of a fine tuning we are doing that also matters a lot.

00:38:56.460 --> 00:38:59.200
Because not there is not just one single kind of a fine

00:38:59.200 --> 00:39:01.080
tuning you will be able to find out which I am going to

00:39:01.080 --> 00:39:06.020
teach you now yeah. So this is the overall understanding

00:39:06.020 --> 00:39:11.920
that we have so far yes everyone yeah. What if for a weather

00:39:11.920 --> 00:39:14.700
forecast for weather forecast why do you need even a fine

00:39:14.700 --> 00:39:20.060
tuning why do you need even like you know this like a fine

00:39:20.060 --> 00:39:23.460
tuning. So nothing is required so basically whatever data

00:39:23.460 --> 00:39:27.040
that you have so just try to you know create a build up or

00:39:27.040 --> 00:39:30.420
create a forecasting model it will be a very very light

00:39:30.420 --> 00:39:33.180
weighted model for you and then do the prediction this is

00:39:33.180 --> 00:39:36.540
what we do. So it is not like we have agentic and we have

00:39:36.540 --> 00:39:40.140
REG capabilities everywhere I will end up using. Case by

00:39:40.140 --> 00:39:45.680
case you are supposed to take a decision yeah many many

00:39:45.680 --> 00:39:48.640
places not many places in majority of places I have seen

00:39:48.640 --> 00:39:52.280
that that people do not understand the fundamentals and they

00:39:52.280 --> 00:39:55.340
end up doing over engineering and then they regret it. Yeah.

00:39:55.360 --> 00:39:58.060
Right and it happens it happens in all the organizations so

00:39:58.060 --> 00:40:00.940
it is like kind of a universal truth even in your

00:40:00.940 --> 00:40:04.180
organization you will see the similar kind of a things yeah

00:40:05.660 --> 00:40:09.200
parser and fallbacks are not visible in my this one. So

00:40:09.200 --> 00:40:11.860
basically double click and then switch it on this one. So I

00:40:11.860 --> 00:40:14.940
have just like enabled it maybe I will just go and disable

00:40:14.940 --> 00:40:21.180
it so now it is not even visible here yeah in agent. Now so

00:40:21.180 --> 00:40:24.420
basically in layman language fine tuning means a query

00:40:24.420 --> 00:40:27.480
optimization no not at all it's an incorrect statement so

00:40:27.480 --> 00:40:32.520
fine tuning means so let's suppose I have a model right fine

00:40:32.520 --> 00:40:36.040
tuning means let's suppose if I have a model so basically I

00:40:36.040 --> 00:40:40.260
am trying to give an additional knowledge for example if I

00:40:40.260 --> 00:40:44.120
will talk about a chat GPT model right for example chat GPT

00:40:44.120 --> 00:40:48.180
model will not be able to understand about Euron because

00:40:48.180 --> 00:40:52.600
chat GPT is been trained on a generic data yeah generic

00:40:52.600 --> 00:40:55.960
data. Now chat GPT has already opened up some of their

00:40:55.960 --> 00:41:00.560
models. So OSS 20B OSS 120B what I will do so I will try to

00:41:00.560 --> 00:41:03.340
take that data I will try to take that model I will try to

00:41:03.340 --> 00:41:07.460
fine tune it with all the Euron data then if I will go and

00:41:07.460 --> 00:41:12.160
ask a question it will be able to give me a more accurate

00:41:12.160 --> 00:41:16.480
like you know result with respect to Euron. So basically if

00:41:16.480 --> 00:41:19.480
I have a sales like I said if I have a sales data if I have

00:41:19.480 --> 00:41:22.580
a marketing data which is my proprietary data which belongs

00:41:22.580 --> 00:41:26.400
to my company it's my company's HR policies. It's my

00:41:26.400 --> 00:41:30.320
company's financial policies or financial data right and if

00:41:30.320 --> 00:41:33.340
I have to if someone has asked me to build a model right

00:41:33.340 --> 00:41:38.040
which can give an answer based out of my data set then I

00:41:38.040 --> 00:41:41.400
will say I have to go ahead with the fine tuning. So fine

00:41:41.400 --> 00:41:45.320
tuning simply means that that training a model as simple as

00:41:45.320 --> 00:41:50.140
that training a model but with my data that's it. We are not

00:41:50.140 --> 00:41:53.920
going to train it from the scratch right so we are going to

00:41:53.920 --> 00:41:58.700
basically train a some of the best LLM model which already

00:41:58.700 --> 00:42:02.040
understands English or maybe some other languages or which

00:42:02.040 --> 00:42:04.660
is already like you know designed for some of the task and

00:42:04.660 --> 00:42:07.320
trained for some other task basically. So it's called as

00:42:07.320 --> 00:42:12.260
fine tuning as simple as that okay I hope this is like

00:42:12.260 --> 00:42:16.820
making sense to all of us yeah the meaning of fine tuning.

00:42:17.400 --> 00:42:20.320
So I will show you so as we will progress I think our

00:42:20.320 --> 00:42:24.940
understanding will be even more clearer right. So RAG. RAG

00:42:24.940 --> 00:42:29.160
like this is just a summary I was trying to give you by the

00:42:29.160 --> 00:42:32.280
way that what is RAG what is agentic and then why we are

00:42:32.280 --> 00:42:35.580
supposed to use which one we are supposed to use. Fine

00:42:35.580 --> 00:42:39.580
tuning is like optimization for a result I mean like not an

00:42:39.580 --> 00:42:43.400
optimization it's like kind of a line from an internet you

00:42:43.400 --> 00:42:47.820
can say but it's like it's more like training with my data

00:42:47.820 --> 00:42:53.020
that's it right. Optimization for a result will be having a

00:42:53.020 --> 00:42:56.720
vague meaning. For example when you say optimization right

00:42:56.720 --> 00:43:00.760
let's suppose my model is having 400 billion parameter let's

00:43:00.760 --> 00:43:03.380
suppose 120 billion parameter I have done fine tuning right

00:43:03.380 --> 00:43:07.940
and then I am trying to run it on a low some low hardware it

00:43:07.940 --> 00:43:12.020
is not optimized. So optimization is having a vague meaning

00:43:12.020 --> 00:43:14.460
itself optimization in terms of what in terms of hardware

00:43:14.460 --> 00:43:17.440
you are talking about maybe I have done fine tuning but I

00:43:17.440 --> 00:43:19.480
have done maybe full fine tuning. So in optimization in

00:43:19.480 --> 00:43:22.820
terms of maybe a training approach optimization in terms of

00:43:22.820 --> 00:43:25.300
giving you, give you optimization in terms of what. So

00:43:25.300 --> 00:43:28.520
that's the reason I never take this like you know word

00:43:28.520 --> 00:43:31.960
called as optimization with respect to fine tuning simply

00:43:34.130 --> 00:43:38.230
making more model better for desire making model better for

00:43:38.230 --> 00:43:42.150
your data basically yeah your specific data your proprietary

00:43:42.150 --> 00:43:47.010
data by the way. Okay let's like try to understand couple of

00:43:47.010 --> 00:43:50.730
things I think pretty much like things will be clear. So let

00:43:50.730 --> 00:43:54.410
me open up my VS code. I'll just follow along with theory

00:43:54.410 --> 00:43:58.210
and practical both. Parallely I have prepared already a

00:43:58.210 --> 00:44:00.810
beautiful beautiful example for all of you by the way

00:44:03.970 --> 00:44:09.400
yeah don't worry I'll go with the explanation first of all

00:44:09.400 --> 00:44:12.940
I'll just go with the overall understanding. So here what I

00:44:12.940 --> 00:44:16.360
have done so actually I have prepared not just one data for

00:44:16.360 --> 00:44:20.660
domain so basically I have prepared a multiple domain data,

00:44:20.900 --> 00:44:25.020
finance data, healthcare data, HR data, marketing data and

00:44:25.020 --> 00:44:28.580
sales data. So that I will end up covering not just one kind

00:44:28.580 --> 00:44:31.560
of a fine tuning. But a multiple kind of a fine tuning and

00:44:31.560 --> 00:44:35.680
that too a different different kind of a data set yeah

00:44:35.680 --> 00:44:40.060
different different kind of a data set. So and again so here

00:44:40.060 --> 00:44:44.080
when we talk about a fine tuning. So your data set should be

00:44:44.080 --> 00:44:47.740
like you know prepared in a different different way and that

00:44:47.740 --> 00:44:50.820
depends upon the kind of a fine tuning that you are going to

00:44:50.820 --> 00:44:55.440
do by the way yeah and yeah it took almost one and half hour

00:44:55.440 --> 00:44:58.120
of time for me to generate these models. So I have trained

00:44:58.120 --> 00:45:01.320
this model. In my local system I have even created an API

00:45:01.320 --> 00:45:04.800
for that and docker deployment for that for GPU H100

00:45:04.800 --> 00:45:08.180
everything I am not going to discuss today. So step by step

00:45:08.180 --> 00:45:13.780
I will go right so theory and practical both in parallel so

00:45:13.780 --> 00:45:16.320
lot of lot of like understanding we have to like take from

00:45:16.320 --> 00:45:20.500
here. So here I have prepared the data. So whenever we talk

00:45:20.500 --> 00:45:24.720
about a fine tuning. So we have to take a decision in a very

00:45:24.720 --> 00:45:28.200
first place that what kind of a fine tuning we are supposed

00:45:28.200 --> 00:45:32.900
to go ahead with. Now the question arises right and then

00:45:32.900 --> 00:45:36.700
obviously with respect to that kind of a fine tuning I have

00:45:36.700 --> 00:45:40.480
to prepare a data. For example so if I am going with the DPO

00:45:40.480 --> 00:45:44.240
kind of a fine tuning RLHF kind of fine tuning my data set

00:45:44.240 --> 00:45:48.740
format is not going to be same as maybe like some other data

00:45:48.740 --> 00:45:52.480
set see. So here I have some different kind of a format of

00:45:52.480 --> 00:45:56.060
the data instruction input right and here I have a different

00:45:56.060 --> 00:45:58.980
kind of a prompt input choice. Chosen rejected prompt input

00:45:58.980 --> 00:46:02.300
chosen rejected right so different kind of a data and this

00:46:02.300 --> 00:46:04.980
is basically a India centric data by the way yeah it is a

00:46:04.980 --> 00:46:07.660
India centric data I have prepared it is a good amount of

00:46:07.660 --> 00:46:11.100
the data and even when you are going to do a fine tuning

00:46:11.100 --> 00:46:14.920
with respect to your own company data depends upon the fine

00:46:14.920 --> 00:46:18.060
tuning approach you are going to choose you have to prepare

00:46:18.060 --> 00:46:21.420
a data first. This is where this data creator or you can say

00:46:21.420 --> 00:46:24.620
data labeler people comes into a picture or domain expert

00:46:24.620 --> 00:46:27.320
people comes into a picture or functional people comes into

00:46:27.320 --> 00:46:30.740
a picture. So what they do they prepare a data right even in

00:46:30.740 --> 00:46:33.200
all the companies who try to train the model you will be

00:46:33.200 --> 00:46:36.480
able to find out a big big team. So where they just try to

00:46:36.480 --> 00:46:39.740
prepare the data because unless and until your data is not

00:46:39.740 --> 00:46:43.940
prepared you can't go ahead with you know like doing a model

00:46:43.940 --> 00:46:46.500
training training with so again fine tuning right. So you

00:46:46.500 --> 00:46:49.620
will be able to do that and it's a big task obviously you

00:46:49.620 --> 00:46:52.920
must be having a functional expertise someone is supposed to

00:46:52.920 --> 00:46:55.720
validate all of this data that if this is the input then

00:46:55.720 --> 00:46:58.600
this is the valid output. But because if someone is going to

00:46:58.600 --> 00:47:01.880
make a mistake with respect to this data labeling or data

00:47:01.880 --> 00:47:05.560
arrangement your entire model will go for a toss as simple

00:47:05.560 --> 00:47:10.020
as that right your entire model will go for the toss EDA no

00:47:10.020 --> 00:47:12.660
it's not called as EDA, EDA is like different exploratory

00:47:12.660 --> 00:47:15.480
data analysis like that is just like generating some sort of

00:47:15.480 --> 00:47:19.160
a stats out of the data. This is basically a data actual

00:47:19.160 --> 00:47:23.180
data preparation for like a model training yeah. So it's not

00:47:23.180 --> 00:47:27.220
EDA by the way EDA simple go after the word. So it is data

00:47:27.220 --> 00:47:30.140
analysis so EDA has been used for the analysis purpose just

00:47:30.140 --> 00:47:33.260
to understand some stats some meaning some formatting and

00:47:33.260 --> 00:47:36.180
some trend inside the data that is technically called as EDA

00:47:36.180 --> 00:47:40.620
which we keep on doing since our childhood yeah. So we all

00:47:40.620 --> 00:47:44.520
do that EDA part since our childhood right. We all have done

00:47:44.520 --> 00:47:47.840
some like EDA with some like a house price prediction or

00:47:47.840 --> 00:47:53.380
something yeah. So yeah basically yeah this is called as

00:47:53.380 --> 00:47:57.020
data annotation. So data preparation or data annotation. So

00:47:57.020 --> 00:47:59.420
we are trying to annotate a data. So data annotation happens

00:47:59.420 --> 00:48:02.880
even in computer vision and in NLP so again data annotation

00:48:02.880 --> 00:48:05.240
we try to do so where we need some sort of a domain

00:48:05.240 --> 00:48:08.620
expertise. So a person who understands this data a person

00:48:08.620 --> 00:48:12.060
who understands your domain and who or like who have a

00:48:12.060 --> 00:48:14.620
proper instruction that whenever person is going to prepare

00:48:14.620 --> 00:48:18.400
the data always try to prepare in that particular way ETL no

00:48:18.400 --> 00:48:20.960
again it is not a ETL extract transform load yeah it is a

00:48:20.960 --> 00:48:24.080
part of ETL it is one of the part of ETL you will be able to

00:48:24.080 --> 00:48:28.100
find out fine. What is the minimum size of data required to

00:48:28.100 --> 00:48:31.160
increase the model accuracy for a specific domain? I mean

00:48:31.160 --> 00:48:34.260
like at minimum whenever you are trying to provide the data

00:48:34.260 --> 00:48:37.380
so always make sure that it should it must be like more than

00:48:37.380 --> 00:48:41.640
500 unit or maybe 1000 right I think that is a good number

00:48:41.640 --> 00:48:44.800
so that you know your model will be able to at least adjust

00:48:44.800 --> 00:48:51.920
itself yeah. So why JSON we can train LLM on a text data I

00:48:51.920 --> 00:48:55.540
mean like it is a format right it is a format which has been

00:48:55.540 --> 00:48:58.240
defined. So if someone has defined that okay for this model

00:48:58.240 --> 00:49:01.980
you can take a data in a text format take a data into a text

00:49:01.980 --> 00:49:04.920
format it is just like saying that why your name is Yoginder

00:49:04.920 --> 00:49:07.580
Pratap Singh because your parents has defined that name

00:49:07.580 --> 00:49:11.200
right and because of that so we all are able to call you as

00:49:11.200 --> 00:49:15.640
a Yoginder Pratap Singh yeah in a similar manner so whoever

00:49:15.640 --> 00:49:18.900
has defined whatever kind of a data and whatever kind of a

00:49:18.900 --> 00:49:23.860
pattern this is pattern right I just have to use it. I do

00:49:23.860 --> 00:49:29.560
not have any other option. Okay. Yeah so step by step we

00:49:29.560 --> 00:49:32.020
will try to understand right step by step we will try to

00:49:32.020 --> 00:49:35.680
like understand each and everything. So here as you can see

00:49:35.680 --> 00:49:40.140
so first we have to choose what kind of a fine tuning we are

00:49:40.140 --> 00:49:43.760
trying to do part number one part number two depends upon

00:49:43.760 --> 00:49:48.680
that fine tuning I have to pick or I have to prepare the

00:49:48.680 --> 00:49:53.140
data set right that is again a heavy task it is not an easy

00:49:53.140 --> 00:49:55.600
task where like you need a like a big task. You need a team

00:49:55.600 --> 00:49:59.900
and again like as your data will grow so obviously your team

00:49:59.900 --> 00:50:03.080
size and maybe either increase the team or maybe increase

00:50:03.080 --> 00:50:08.580
the time right and then you have to choose basically a

00:50:08.580 --> 00:50:12.280
hardware right that okay fine so this is a hardware on which

00:50:12.280 --> 00:50:16.240
I am going to do a training then we try to evaluate those

00:50:16.240 --> 00:50:20.500
model we try to test those model which is a small part and

00:50:20.500 --> 00:50:24.080
then we try to host those model somewhere. So this is a

00:50:24.080 --> 00:50:27.000
cycle. This is a cycle that we try to follow in the general

00:50:27.000 --> 00:50:30.880
right. So first what we do so first of all we try to you

00:50:30.880 --> 00:50:33.140
know select

00:50:34.580 --> 00:50:43.900
or type of fine tuning.

00:50:45.790 --> 00:50:47.750
So this is something that we try to select and there are

00:50:47.750 --> 00:50:50.870
like so many different kind of a fine tuning approach you

00:50:50.870 --> 00:50:54.610
will be able to find out. Now based on this approach if this

00:50:54.610 --> 00:50:57.090
approach is already defined I have already selected that

00:50:57.090 --> 00:51:00.350
what kind of a fine tuning I am doing. Then what I will do

00:51:00.350 --> 00:51:03.690
so I will try to go ahead with the data preparation data

00:51:03.690 --> 00:51:09.070
preparation yeah so this will be my step number two. Once

00:51:09.070 --> 00:51:12.950
data will be prepared then I will do a math I will do a

00:51:12.950 --> 00:51:18.730
calculation for what so for a hardware by the way hardware

00:51:18.730 --> 00:51:21.730
hardware means a GPU CPU wherever I am going to train it

00:51:21.730 --> 00:51:25.590
because again that plays a crucial role right so I will try

00:51:25.590 --> 00:51:27.790
to pick and choose the hardware. So data preparation is

00:51:27.790 --> 00:51:31.270
done. I will try to pick and choose the hardware right. Code

00:51:31.270 --> 00:51:35.630
part wise it is not going to be difficult so prepare code

00:51:35.630 --> 00:51:37.830
and infra right.

00:51:40.340 --> 00:51:43.520
So code part wise it is not at all difficult you just have

00:51:43.520 --> 00:51:46.320
to you know adjust couple of parameter it is very very easy

00:51:46.320 --> 00:51:50.120
code to understand believe me and all the parameter you all

00:51:50.120 --> 00:51:53.080
will be able to train and tune. So basically type of fine

00:51:53.080 --> 00:51:56.540
tuning I have selected after that data I have to prepare so

00:51:56.540 --> 00:51:59.300
depends upon the fine tuning. Then I have to select the

00:51:59.300 --> 00:52:03.100
hardware. It depends upon the data and the model the base

00:52:03.100 --> 00:52:08.380
model yeah because hardware depends upon both which model I

00:52:08.380 --> 00:52:11.920
am trying to train right and what kind of a fine tuning I am

00:52:11.920 --> 00:52:16.260
trying to do and then what volume of data. So based on all

00:52:16.260 --> 00:52:20.160
three factors my hardware like I have to choose right it is

00:52:20.160 --> 00:52:22.440
not like just on one single factor I will be able to choose

00:52:22.440 --> 00:52:26.980
my hardware. And then like code wise like it is like a very

00:52:26.980 --> 00:52:29.340
basic one code and infra setup I will try to do. Means

00:52:29.340 --> 00:52:31.880
migrate all those code to that particular platform where I

00:52:31.880 --> 00:52:34.800
am doing a training and data and all those things right. And

00:52:34.800 --> 00:52:38.840
then once my model will be ready then I will have to

00:52:38.840 --> 00:52:43.500
evaluate my model or you can say test my model and again so

00:52:43.500 --> 00:52:47.800
that is like again contextual what kind of a model for what

00:52:47.800 --> 00:52:51.640
purposes I am trying to you know create the model. So based

00:52:51.640 --> 00:52:54.840
on that I will try to perform the testing and once this

00:52:54.840 --> 00:52:58.540
testing is done so then what we do. So then we try to send a

00:52:58.540 --> 00:53:03.660
model to us. So basically send the model means inference or

00:53:03.660 --> 00:53:07.480
host a model in a production. So again I have to go ahead

00:53:07.480 --> 00:53:11.300
with the infra calculation and then kind of a input that I

00:53:11.300 --> 00:53:14.400
will be receiving or you can say a kind of a hit right which

00:53:14.400 --> 00:53:18.300
will come on my model per second per minute per hour per day

00:53:18.300 --> 00:53:21.700
basis. So I will do the math over there and based on that I

00:53:21.700 --> 00:53:23.660
will calculate the infrastructure. What is the kind of a

00:53:23.660 --> 00:53:26.760
latency which I am expecting. So let us suppose I am trying

00:53:26.760 --> 00:53:29.880
to create maybe URI kind of a system. So obviously over here

00:53:29.880 --> 00:53:34.120
latency should not be more than maybe like 5 second right 5

00:53:34.120 --> 00:53:37.780
to 6 second. So obviously I have to host kind of that kind

00:53:37.780 --> 00:53:41.020
of a model on like that kind of a infra where it will be

00:53:41.020 --> 00:53:43.740
able to scale or it will be able to give a response with

00:53:43.740 --> 00:53:46.960
that latency. Sometime for example the yesterday's example

00:53:46.960 --> 00:53:50.980
that I have discussed. So over there we need a model once in

00:53:50.980 --> 00:53:54.680
a whole day at 9 o'clock right. This is the schedule this is

00:53:54.680 --> 00:53:56.560
the this is something that we have written in our scheduler

00:53:56.560 --> 00:53:59.020
at 9 o'clock. It is supposed to you know run itself and

00:53:59.020 --> 00:54:02.360
generate the report. So over there I don't need a real time

00:54:02.360 --> 00:54:06.780
model. So even with a very low infra I will be able to host

00:54:06.780 --> 00:54:10.540
that model for that particular use cases. So I will be able

00:54:10.540 --> 00:54:13.980
to use it. So everywhere I don't need a heavy infra it's

00:54:13.980 --> 00:54:17.480
case by case basis right. And this is a decision that we

00:54:17.480 --> 00:54:20.820
always try to take. So it will go to the production. So in

00:54:20.820 --> 00:54:25.500
the general this is a kind of a flow that we try to you know

00:54:25.500 --> 00:54:30.300
follow whenever we talk about basically this fine tuning and

00:54:30.300 --> 00:54:33.820
lot goes inside every step. So many things so many things

00:54:33.820 --> 00:54:38.760
goes inside every step on a case by case basis right. And

00:54:38.760 --> 00:54:41.480
where we try to take a decision. So in general this is

00:54:41.480 --> 00:54:44.460
something that we try to follow. Making sense everyone guys

00:54:44.460 --> 00:54:48.600
yeah. So first coming to a type of fine tuning. Now let's

00:54:48.600 --> 00:54:50.820
start breaking it down into a multiple steps.

00:54:53.600 --> 00:54:56.380
What is the difference between prod and hardware module. So

00:54:56.380 --> 00:54:58.720
see here I have written a hardware for a training purpose.

00:54:58.840 --> 00:55:02.040
Right. And here I have written a production. So once you

00:55:02.040 --> 00:55:04.660
will your model will be tested you will send your model for

00:55:04.660 --> 00:55:08.220
a real inferencing. So this is a hardware which is required

00:55:08.220 --> 00:55:11.480
only one time right. This is a hardware which is required

00:55:11.480 --> 00:55:14.740
daily basis or as per your application right. So if your

00:55:14.740 --> 00:55:17.920
application is running 24 by 7 once in a year once in a week

00:55:17.920 --> 00:55:20.580
once in a day. So this one. So production hardware will be

00:55:20.580 --> 00:55:22.640
different and then this hardware will be different.

00:55:22.940 --> 00:55:27.180
Somewhere we need like heavy hardware over here. So while

00:55:27.180 --> 00:55:30.180
doing a training. So one hardware is part of like a you know

00:55:30.180 --> 00:55:33.640
training one is a final inferencing. So when my model will

00:55:33.640 --> 00:55:37.080
be like a trained and then it will serve the user the end

00:55:37.080 --> 00:55:37.360
user.

00:55:41.360 --> 00:55:48.800
Okay fine everyone yeah. So now we have to understand that

00:55:48.800 --> 00:55:53.500
what is the type of the fine tuning generally we will be

00:55:53.500 --> 00:55:56.260
able to find out. So any idea guys what is what is the type

00:55:56.260 --> 00:55:59.100
of fine tuning any I think I have discussed so many times.

00:55:59.100 --> 00:56:02.280
Even in your interview preparation series. So we had a lot

00:56:02.280 --> 00:56:05.520
of discussion on this one a type of fine tuning. Okay Nares

00:56:05.520 --> 00:56:09.360
is saying like a supervised okay okay unsupervised okay yeah

00:56:09.360 --> 00:56:14.740
that's okay supervise unsupervised. DPO what is what is the

00:56:14.740 --> 00:56:21.620
full form of DPO by the way RLHF okay Qlaura fine any

00:56:25.550 --> 00:56:28.330
any anyone who can give me like you know full form of DPO

00:56:28.330 --> 00:56:29.490
yeah.

00:56:33.800 --> 00:56:37.280
DPO means direct preference optimization. Okay. Paramedic

00:56:37.280 --> 00:56:43.140
perfect yeah message not showing to me okay I think people

00:56:43.140 --> 00:56:46.100
are pinging to host and panelists there are two options

00:56:46.100 --> 00:56:49.420
right so there is a option to ping to everyone you can just

00:56:49.420 --> 00:56:53.060
select and there is option to you know so host or panelist

00:56:53.060 --> 00:56:57.160
means I only I can see the message you have both the options

00:56:57.160 --> 00:56:59.880
by the way yeah guys I think you are able to see all the

00:56:59.880 --> 00:57:02.920
options maybe you can select everyone when you are messaging

00:57:02.920 --> 00:57:08.340
right so two in a two section. Just select everyone so that

00:57:08.340 --> 00:57:11.200
you know everyone will be able to see your messages all all

00:57:11.200 --> 00:57:13.700
of us can see your discussion otherwise only I will be able

00:57:13.700 --> 00:57:17.560
to see your discussions which which many people have like a

00:57:17.560 --> 00:57:23.440
pinged yeah. So Tabis is saying Laura Qlaura DPO RLHF yeah

00:57:23.440 --> 00:57:27.800
that's okay selective adaptive based Laura prefix tuning

00:57:27.800 --> 00:57:32.040
also yeah so there are like a lot of different different

00:57:32.040 --> 00:57:35.160
kind of a fine tuning. Not just one single type of fine

00:57:35.160 --> 00:57:38.560
tuning you will be able to find out in this entire world lot

00:57:38.560 --> 00:57:43.300
of lot of different kind of a fine tuning but overall right

00:57:43.300 --> 00:57:48.560
overall if I have to like you know define and make this fine

00:57:48.560 --> 00:57:52.420
tuning like things pretty much easy for all of us so I can I

00:57:52.420 --> 00:57:58.420
can say that that maybe right so maybe I can categorize a

00:57:58.420 --> 00:58:06.500
fine tuning in like a couple of cases. So one is a full fine

00:58:06.500 --> 00:58:12.320
tuning right now what is the meaning of full fine tuning so

00:58:12.320 --> 00:58:16.200
whatever model that we have whatever model because model is

00:58:16.200 --> 00:58:18.260
nothing but a transformer right this is what our

00:58:18.260 --> 00:58:20.980
understanding is so transformer so whatever transformer

00:58:20.980 --> 00:58:24.460
architecture that we are going to consider we are going to

00:58:24.460 --> 00:58:28.040
change the entire weight means we are going to update the

00:58:28.040 --> 00:58:32.400
entire weight as per my data. Now this is one. This is

00:58:32.400 --> 00:58:32.880
something that we are going to consider. This is something

00:58:32.880 --> 00:58:36.540
called as like a full fine tuning this is this is one of the

00:58:36.540 --> 00:58:40.860
part right so one is like basically full fine tuning

00:58:40.860 --> 00:58:47.920
approach one. Now there could be a second one basically so

00:58:47.920 --> 00:58:53.920
second one can be like a prefet basically pfet so parameter

00:58:53.920 --> 00:58:57.920
efficient fine tuning right parameter efficient fine tuning

00:58:57.920 --> 00:59:02.660
pfet so pfet again another like a kind of a fine tuning.

00:59:02.760 --> 00:59:05.820
That we try to do so where we don't try to you know change

00:59:05.820 --> 00:59:10.520
the entire weight of the model what do we do instead of like

00:59:10.520 --> 00:59:13.760
a changing the entire weight of the model. So we try to

00:59:13.760 --> 00:59:18.900
update just some of the weight for example in a in a layman

00:59:18.900 --> 00:59:21.660
way again if I have to explain it to you so let's suppose

00:59:21.660 --> 00:59:25.860
this is my model right this is my actual model and we have a

00:59:25.860 --> 00:59:29.220
transformer architecture over here this is my actual model

00:59:29.220 --> 00:59:32.700
so in case of parameter efficient fine tuning. What I will

00:59:32.700 --> 00:59:36.660
do. So instead of changing the entire weight of the model I

00:59:36.660 --> 00:59:42.320
will try to maybe add some parallel network yeah I will try

00:59:42.320 --> 00:59:46.040
to add some parallel network in this way maybe I will try to

00:59:46.040 --> 00:59:50.440
add some network over here yeah and instead of changing the

00:59:50.440 --> 00:59:53.680
original weight of the model I will change what I will

00:59:53.680 --> 00:59:57.320
change this one I will change maybe this one depends what

00:59:57.320 --> 01:00:00.700
kind of you know fine tuning I am trying to do and next time

01:00:00.700 --> 01:00:04.460
right so so that you know this big model is having a generic

01:00:04.460 --> 01:00:06.920
understanding yeah this big model is having a generic

01:00:06.920 --> 01:00:10.480
understanding and this is small network a neural network

01:00:10.480 --> 01:00:13.240
right this is small neural network is having a understanding

01:00:13.240 --> 01:00:18.020
about my data yeah now whenever some input will come right

01:00:18.020 --> 01:00:20.640
so whenever someone is going to do or call the inferencing

01:00:20.640 --> 01:00:24.340
right so whenever some input will come technically what it

01:00:24.340 --> 01:00:27.420
will do so whenever some input will come so it will try to

01:00:27.420 --> 01:00:33.100
you know give the output based on the input. put inside my

01:00:33.100 --> 01:00:37.640
big model which is black having understanding about the data

01:00:37.640 --> 01:00:40.480
plus the model which I have trained and it is it is

01:00:40.480 --> 01:00:45.480
basically going to give me the output right from both it is

01:00:45.480 --> 01:00:48.100
going to combine the output and then it is going to give me

01:00:48.100 --> 01:00:52.140
the final output from both the parallel one and the big one

01:00:52.140 --> 01:00:54.180
the big one which understands which is having a universal

01:00:54.180 --> 01:00:57.140
understanding of the data right and the parallel one which

01:00:57.140 --> 01:01:00.920
is having a specific understanding about my data set. So

01:01:00.920 --> 01:01:05.160
this kind of a training so where we try to add a parallel or

01:01:05.160 --> 01:01:08.340
maybe this vertical kind of a layer or maybe just one layer

01:01:08.340 --> 01:01:11.980
at the end we try to add this kind of a fine tuning is

01:01:11.980 --> 01:01:16.820
called as PFIT parameter efficient fine tuning right. So

01:01:16.820 --> 01:01:20.640
where we do not change the weight of original model instead

01:01:20.640 --> 01:01:23.760
of doing that so we try to change a weight of basically

01:01:23.760 --> 01:01:28.180
parallel weights right. We try to add a parallel weight. A

01:01:28.180 --> 01:01:30.740
parallel neural network. So this is how you should

01:01:30.740 --> 01:01:37.740
understand a PFIT parameter efficient fine tuning. Now when

01:01:37.740 --> 01:01:40.800
we talk about a parameter efficient fine tuning so inside

01:01:40.800 --> 01:01:43.820
that you will be able to find out inside this parameter

01:01:43.820 --> 01:01:46.860
efficient fine tuning you will be able to find out in

01:01:46.860 --> 01:01:50.340
general two different different kind of a fine tuning

01:01:50.340 --> 01:01:55.300
approach. One is a LoRa one is a Quora basically right. Now

01:01:55.300 --> 01:01:59.960
what is this LoRa by the way. So it is technically a part of

01:01:59.960 --> 01:02:03.160
basically this PFIT. PFIT is a concept right it is a

01:02:03.160 --> 01:02:05.500
concept. The concept which I was trying to explain it to

01:02:05.500 --> 01:02:09.360
you. So parameter efficient fine tuning it is a concept and

01:02:09.360 --> 01:02:12.880
inside that LoRa and QuLaura comes into a picture. So let me

01:02:12.880 --> 01:02:18.720
write it down over here PFIT and inside that so basically

01:02:18.720 --> 01:02:23.260
LoRa. So this is something that you will be able to find

01:02:23.260 --> 01:02:25.980
out. Now what is the full form of this one. So it is nothing

01:02:25.980 --> 01:02:29.080
but. It is nothing but low rank adaption right. Low rank

01:02:29.080 --> 01:02:32.620
adaption. So here this is the example I was talking about

01:02:32.620 --> 01:02:35.920
that there is a model a big one right and parallel to that

01:02:35.920 --> 01:02:39.240
so I will try to add a fresh neural network. I will try to

01:02:39.240 --> 01:02:42.600
train this entire entity but not the big model I will try to

01:02:42.600 --> 01:02:45.540
train. I will try to train only this one and when it will

01:02:45.540 --> 01:02:47.960
try to give an output so it will try to give an output by

01:02:47.960 --> 01:02:50.940
using both of this entity. So this entity which understands

01:02:50.940 --> 01:02:53.320
the universal data and this entity which understands my

01:02:53.320 --> 01:02:57.920
data. So in this way. I am like. Trying to avoid a billions

01:02:57.920 --> 01:03:01.700
of parameter training. So maybe I am trying to add or I am

01:03:01.700 --> 01:03:05.180
just trying to train a fraction of the parameter right. So

01:03:05.180 --> 01:03:08.420
in this manner my training will be you know pretty much

01:03:08.420 --> 01:03:12.480
efficient. I can like train it in a low hardware right and I

01:03:12.480 --> 01:03:15.520
will be able to quickly train it and quickly I will be able

01:03:15.520 --> 01:03:18.820
to use it because I am not supposed to like I am not

01:03:18.820 --> 01:03:22.080
changing the whole weight of the model. So this is where

01:03:22.080 --> 01:03:26.440
called as low rank adaption. Let me write it down. So this

01:03:26.440 --> 01:03:33.720
LoRa is nothing but it is called as low rank adaption.

01:03:35.680 --> 01:03:39.060
In some of the classes I have even like explained its

01:03:39.060 --> 01:03:42.420
mathematics behind it. So there is like a small calculation,

01:03:42.700 --> 01:03:45.980
rank calculation which goes behind. Maybe I will try to

01:03:45.980 --> 01:03:48.640
discuss even in this class once again but yeah in some of

01:03:48.640 --> 01:03:50.720
the classes I think in a previous generative AI classes I

01:03:50.720 --> 01:03:53.000
have already discussed about like how mathematics wise this

01:03:53.000 --> 01:03:58.100
ranking works right. Hmm. Then there is something called as

01:03:58.100 --> 01:04:01.980
Q LoRa right. Again extension of the same thing you will be

01:04:01.980 --> 01:04:09.260
able to find out. So there is something called as Q LoRa. So

01:04:09.260 --> 01:04:12.420
now what is this by the way. So and how it is different from

01:04:12.420 --> 01:04:15.340
the above one. So it is nothing but it is a quantized one.

01:04:15.640 --> 01:04:19.600
So whenever you will be able to you know let me write it

01:04:19.600 --> 01:04:26.040
down, Q U A N T I Z E D quantized one. So Q LoRa. So

01:04:26.040 --> 01:04:31.700
quantized LoRa simple quantized low rank adaption yeah.

01:04:34.640 --> 01:04:38.180
So whenever we say quantized, so quantized simply means that

01:04:38.180 --> 01:04:43.060
that we are trying to change the scale right. Scale of what?

01:04:43.180 --> 01:04:46.880
Scale of the weight by the way. So in general let's suppose

01:04:46.880 --> 01:04:51.520
I am trying to represent an integer by using a 32 bit yeah

01:04:51.520 --> 01:04:54.860
by using a 32 bit means 32 bit of a space is required to

01:04:54.860 --> 01:04:58.420
represent one single integer. And again. So if I will talk

01:04:58.420 --> 01:05:03.060
about your CPU or GPU a silicon chip where like actually

01:05:03.060 --> 01:05:06.940
computation happens it understands a bits right. It

01:05:06.940 --> 01:05:10.920
understands bits 0 1 0 1 0 1 0 1. So for to represent one

01:05:10.920 --> 01:05:13.920
single integer let's suppose if I am taking 32 bit of a

01:05:13.920 --> 01:05:17.520
space yeah 32 bit of a space and now when I am trying to

01:05:17.520 --> 01:05:20.760
like you know do a computation. So obviously 32 bit is

01:05:20.760 --> 01:05:23.800
trying to do a computation with a 32 bit that is space that

01:05:23.800 --> 01:05:27.560
length of the bits. It will like get into the computation.

01:05:27.980 --> 01:05:31.600
And obviously if I am talking about a billions of parameter.

01:05:31.900 --> 01:05:34.940
So as my parameter will increase so my compute will be

01:05:34.940 --> 01:05:37.680
heavy. My computer will become heavier and heavier and

01:05:37.680 --> 01:05:42.900
heavier. So what people said that okay let's do one thing.

01:05:43.120 --> 01:05:47.260
So maybe try to represent that 32 bit into maybe like a

01:05:47.260 --> 01:05:52.440
lower bit 4 bit 8 bit 16 bit. How we can do that. So just we

01:05:52.440 --> 01:05:56.580
are trying to optimize the space required. Okay. But maybe

01:05:56.580 --> 01:05:59.580
we are trying to do the bits. So if we are reducing our

01:05:59.580 --> 01:06:03.880
bits. So yeah we are losing some meaning of the data some

01:06:03.880 --> 01:06:07.540
fraction of the data we are losing over there. But overall

01:06:07.540 --> 01:06:12.140
let's suppose I am trying to write 2.10 right. Let's

01:06:12.140 --> 01:06:14.440
understand in this way. So let's suppose there is a number 2

01:06:14.440 --> 01:06:19.480
.10. I will try to chop off 1 0 right. Still I will be

01:06:19.480 --> 01:06:23.240
having 2 a base value 2. So I will be able to like think

01:06:23.240 --> 01:06:26.200
that that okay. Think in this way that. Okay I am able to

01:06:26.200 --> 01:06:29.220
chop off this value but yeah so if by chopping off this

01:06:29.220 --> 01:06:33.540
values if I am able to retain majority of the information

01:06:33.540 --> 01:06:37.520
means that 2 which is a base which is like a major one if I

01:06:37.520 --> 01:06:40.700
am able to retain it then obviously I am not losing much of

01:06:40.700 --> 01:06:44.120
information but I am trying to make my calculation pretty

01:06:44.120 --> 01:06:46.980
much faster and that was the approach you will be able to

01:06:46.980 --> 01:06:49.300
find out in terms of quantization. So instead of

01:06:49.300 --> 01:06:53.220
representing any numbers on a higher bit higher scale reduce

01:06:53.220 --> 01:06:57.280
it maybe. From 32 bring it to 4 bit bring it to 8 bit bring

01:06:57.280 --> 01:07:01.060
it to 16 bit. So your computation will be reduced and we are

01:07:01.060 --> 01:07:04.240
talking about a billions of parameter and technically when

01:07:04.240 --> 01:07:07.580
we say my model size is 500 GB because that kind of model

01:07:07.580 --> 01:07:11.180
you will be able to find out or maybe a 50 GB all those

01:07:11.180 --> 01:07:14.740
sizes are coming from your weight size as your weight number

01:07:14.740 --> 01:07:18.400
of weights will increase and like this bits will be

01:07:18.400 --> 01:07:21.740
increased obviously bits will eventually converts into your

01:07:21.740 --> 01:07:25.460
sizes. MB, KB, GB whatever you can say right because

01:07:25.460 --> 01:07:28.700
eventually that's a space it is going to take. So that was

01:07:28.700 --> 01:07:30.800
the whole idea that was the whole approach in terms of doing

01:07:30.800 --> 01:07:34.320
a quantization that try to represent a number into a lower

01:07:34.320 --> 01:07:37.640
bits and then do a computation so computation will be

01:07:37.640 --> 01:07:41.760
lighter and the size will be like again reduced in that

01:07:41.760 --> 01:07:46.980
proportions and I will be able to host that model on any

01:07:46.980 --> 01:07:51.480
hardware right even on a mobile devices I will be able to

01:07:51.480 --> 01:07:56.520
hold. Like a model or any other devices right. So even on

01:07:56.520 --> 01:08:01.020
mobile or TPUs tensor processing unit which is again you can

01:08:01.020 --> 01:08:04.940
say brother sister of like a GPU right but for a lightweight

01:08:04.940 --> 01:08:09.020
small devices basically a tensor processing unit so there is

01:08:09.020 --> 01:08:12.360
something called a CPU, GPU and then TPUs. So it will be

01:08:12.360 --> 01:08:15.420
able to even run on a very very light weighted devices and

01:08:15.420 --> 01:08:19.500
yeah I will be able to make use of this LLMs on remote or

01:08:19.500 --> 01:08:22.220
mobile devices or edge devices as well technically. It is

01:08:22.220 --> 01:08:25.920
called as edge devices. So this is the approach which has

01:08:25.920 --> 01:08:29.460
been adopted it is not a new approach I would say it is a

01:08:29.460 --> 01:08:32.760
very very old approach even in computer vision which does

01:08:32.760 --> 01:08:36.520
this kind of a things a lot and I think in my experience I

01:08:36.520 --> 01:08:39.900
think I am doing it like since like 6-7 years right. So we

01:08:39.900 --> 01:08:42.560
are trying to you know create a quantization model in terms

01:08:42.560 --> 01:08:45.560
of computer vision and same thing they have adopted even in

01:08:45.560 --> 01:08:49.560
case of a NLP because we all know that size of LLMs is

01:08:49.560 --> 01:08:52.800
increasing day by day. Day by day. Day by day. So yeah we

01:08:52.800 --> 01:08:55.540
are trying to do a little bit of compromise with respect to

01:08:55.540 --> 01:09:01.300
the output but in terms of speed it is like a 1000x of speed

01:09:01.300 --> 01:09:05.680
and in terms of storing those things inside our memory so we

01:09:05.680 --> 01:09:08.160
are we are like trying we are able to make a lot of

01:09:08.160 --> 01:09:14.400
improvement. So this is again so this QLORA is nothing but

01:09:14.400 --> 01:09:19.240
just an extension of your pre-fit and here for this model

01:09:19.240 --> 01:09:22.180
the big model that we have right. The big model. Big model

01:09:22.180 --> 01:09:25.780
will be having most of the weights. So for a big model we

01:09:25.780 --> 01:09:29.780
are trying to basically represent all the weights into its

01:09:29.780 --> 01:09:33.160
lower bit. So maybe previously it was in the 32 bit now I

01:09:33.160 --> 01:09:36.240
will try to represent it into a 4 bit or maybe into a 8 bit.

01:09:36.580 --> 01:09:41.460
That is something happens with respect to QLORA. Then after

01:09:41.460 --> 01:09:47.220
QLORA right so you will be able to find out in general a

01:09:47.220 --> 01:09:50.740
kind of you know reinforcement learning based learning.

01:09:50.740 --> 01:09:55.180
Based approach where you like go and try to like train the

01:09:55.180 --> 01:09:59.900
model with the help of basically a human input right. So

01:09:59.900 --> 01:10:03.940
with the help of human input. So again RLHF I can say

01:10:03.940 --> 01:10:06.440
reinforcement learning based approach so where you know you

01:10:06.440 --> 01:10:09.040
train the model you give a feedback then again it will try

01:10:09.040 --> 01:10:12.020
to consider the feedback now based on the consideration of

01:10:12.020 --> 01:10:16.380
the feedback. So it is going to again train or maybe detrain

01:10:16.380 --> 01:10:22.260
yeah. Retrain the entire model. Okay. So again inside that

01:10:22.260 --> 01:10:26.860
you will be able to see a PPOs or DPOs direct preference

01:10:26.860 --> 01:10:30.120
optimization kind of a technique comes into a picture in

01:10:30.120 --> 01:10:33.940
general I would say right in general. Again there are

01:10:33.940 --> 01:10:37.000
multiple ways by which I will be able to categorize but yeah

01:10:37.000 --> 01:10:40.620
so we are going to learn about a full fine tuning. We will

01:10:40.620 --> 01:10:43.580
be learning about a LORA basically. We will be learning

01:10:43.580 --> 01:10:47.700
about a QLORA and we will be learning about practically

01:10:47.700 --> 01:10:54.760
right we will be learning about even a DPO. Which is not

01:10:54.760 --> 01:10:58.720
exactly the RLHF but kind of a extension of a RLHF itself.

01:10:59.200 --> 01:11:02.260
So let me write it down 3

01:11:04.790 --> 01:11:06.070
why

01:11:08.630 --> 01:11:10.790
it is changing DPO

01:11:13.350 --> 01:11:17.410
direct preference optimization yeah. Now so when we talk

01:11:17.410 --> 01:11:21.670
about these like approaches by the way so obviously based on

01:11:21.670 --> 01:11:26.010
this approach we have to prepare our data set right. Domain

01:11:26.010 --> 01:11:29.690
is not necessary over here. I can train this thing. It is

01:11:29.690 --> 01:11:31.970
with respect to any kind of a domain with respect to any

01:11:31.970 --> 01:11:38.070
kind of a data right. So here I can even train for the

01:11:38.070 --> 01:11:40.750
coding I can train for the mathematics I can train for maybe

01:11:40.750 --> 01:11:43.590
a generic text whatever I want I can train it everything

01:11:43.590 --> 01:11:47.990
will be under my control. Now when we talk about a full fine

01:11:47.990 --> 01:11:52.450
tuning right when we talk about a full fine tuning so

01:11:52.450 --> 01:11:57.010
basically it is a supervised approach of doing a training

01:11:57.010 --> 01:11:59.930
right full fine tuning means it is a supervised approach. So

01:11:59.930 --> 01:12:05.790
here what we try to do so whenever we try to prepare a data

01:12:05.790 --> 01:12:08.750
right whenever we try to prepare data for a full fine tuning

01:12:08.750 --> 01:12:13.210
so my data should be available into a input and output pair

01:12:13.210 --> 01:12:18.050
by the way yeah input and output pair. So for example if I

01:12:18.050 --> 01:12:21.870
am trying to train my GPT model OSS 20 billion parameter OSS

01:12:21.870 --> 01:12:25.430
maybe 120 billion parameter or maybe any Lama series any

01:12:25.430 --> 01:12:28.410
Mistral series any deep six series if I am trying to train

01:12:28.410 --> 01:12:32.510
right. Right. So obviously I should prepare a data in a

01:12:32.510 --> 01:12:37.110
input output pair right that okay fine so this is the prompt

01:12:37.110 --> 01:12:40.150
and then this will be the output or this is going to be the

01:12:40.150 --> 01:12:44.090
completion. Eventually this is what we have done over here.

01:12:44.210 --> 01:12:47.990
So if you will look into this health care data set right so

01:12:47.990 --> 01:12:51.530
health care data set so we have prepared this data what are

01:12:51.530 --> 01:12:56.110
the symptoms for of a dengue fever common in India during a

01:12:56.110 --> 01:13:00.390
monsoon right. So like we have. Like this kind of

01:13:00.390 --> 01:13:03.950
instruction then we have input as a blank and then we have a

01:13:03.950 --> 01:13:07.630
output pair right. So output is a very very long output that

01:13:07.630 --> 01:13:11.230
we have prepared over here. So this this format is required

01:13:11.230 --> 01:13:14.230
so you must be having some sort of instruction and then you

01:13:14.230 --> 01:13:17.410
must be having some sort of output. Again if you will check

01:13:17.410 --> 01:13:20.390
my HR data set so instruction input outputs in a similar

01:13:20.390 --> 01:13:23.950
format we have prepared all of these data set right. All of

01:13:23.950 --> 01:13:26.990
these data set so whenever we are talking about a full fine

01:13:26.990 --> 01:13:30.790
tuning you should always prepare a data. In this particular

01:13:30.790 --> 01:13:34.890
format this key can be like different you can give a

01:13:34.890 --> 01:13:36.630
different name because at the end of the day we are just

01:13:36.630 --> 01:13:39.710
going to do a mapping right. So this name can be different

01:13:39.710 --> 01:13:42.130
instruction input output like for example if I have given

01:13:42.130 --> 01:13:44.550
you can you can give some different name that's okay because

01:13:44.550 --> 01:13:47.630
it's just a key mapping by which we try to say that okay

01:13:47.630 --> 01:13:50.990
fine this is the input and this is the output for you. As

01:13:50.990 --> 01:13:54.490
simple as that yeah as simple as that. So in this format

01:13:54.490 --> 01:13:57.790
everywhere every time everywhere you have to prepare the

01:13:57.790 --> 01:14:01.890
data making sense. In case of like a full fine tuning guys

01:14:01.890 --> 01:14:05.210
yeah yep.

01:14:16.420 --> 01:14:18.140
So does

01:14:20.220 --> 01:14:23.180
full fine tuning means as a training the whole original

01:14:23.180 --> 01:14:26.680
model again we lose the original model parameter value yeah

01:14:26.680 --> 01:14:29.260
this is the meaning of that that we are changing the entire

01:14:29.260 --> 01:14:32.420
weight. No we will not lose the entire meaning of the

01:14:32.420 --> 01:14:36.100
original model because see it is going to adjust the weights

01:14:36.100 --> 01:14:40.180
like we have certain numbers numbers means weights and it is

01:14:40.180 --> 01:14:42.940
going to adjust the weights. Based on what based on the

01:14:42.940 --> 01:14:45.380
losses right if you understand and if you remember the

01:14:45.380 --> 01:14:50.260
training concept yeah. So basically you have given some like

01:14:50.260 --> 01:14:54.640
you know combinations of a text of embeddings and obviously

01:14:54.640 --> 01:14:57.340
my model is good enough to understand those things. So

01:14:57.340 --> 01:15:00.260
basically it will not try to adjust much it will try to just

01:15:00.260 --> 01:15:03.840
adjust with respect to my given data itself. It is not going

01:15:03.840 --> 01:15:10.320
to like adjust like to some like a big you can say a

01:15:10.320 --> 01:15:10.600
numbers.

01:15:24.760 --> 01:15:28.440
Okay now here so we have an instruction we have an input and

01:15:28.440 --> 01:15:31.140
we have an output. What is the meaning of this three things

01:15:31.140 --> 01:15:34.440
by the way right. So when I say this instruction right so it

01:15:34.440 --> 01:15:39.400
simply means that that what I want my model to do this is

01:15:39.400 --> 01:15:42.420
what I am trying to say over here. This is the meaning of an

01:15:42.420 --> 01:15:46.700
instruction in terms of preparing a data. When I say input

01:15:46.700 --> 01:15:50.480
and mostly my inputs are blank so it's nothing it's again

01:15:50.480 --> 01:15:54.920
optional always optional. So like instruction. I can. If I

01:15:54.920 --> 01:15:58.300
can like avoid it that's completely okay. If I'm giving it

01:15:58.300 --> 01:16:00.700
again well and good it will be having more capabilities but

01:16:00.700 --> 01:16:03.060
yeah I can keep it blank and in my cases I have kept it

01:16:03.060 --> 01:16:05.900
blank as of now. So instruction means what I want my model

01:16:05.900 --> 01:16:11.260
to do. Input means so basically a external context. If I

01:16:11.260 --> 01:16:15.420
wanted to give to the model to complete a particular task,

01:16:15.480 --> 01:16:19.380
task means the instruction yeah. So how does a paternity

01:16:19.380 --> 01:16:23.280
leave and childcare policy works. So simple instruction.

01:16:23.280 --> 01:16:25.600
Instruction. And then I have given the output. I have not

01:16:25.600 --> 01:16:29.900
given any kind of internal or external context. So maybe I

01:16:29.900 --> 01:16:31.940
can fit some data from the internet, some different

01:16:31.940 --> 01:16:34.540
companies, HR policies I can try to fetch and maybe I can

01:16:34.540 --> 01:16:38.320
try to give as a reference as a context. But again it's an

01:16:38.320 --> 01:16:41.960
optional one. Yeah it's an optional one. Maybe I can I can

01:16:41.960 --> 01:16:44.460
try to attach a policies. Maybe I can try to fetch some data

01:16:44.460 --> 01:16:48.200
from some table and then try to attach it. But like I said

01:16:48.200 --> 01:16:50.860
so hope all of you are able to understand this three

01:16:50.860 --> 01:16:54.100
parameter instruction. Instruction means the input, the

01:16:54.100 --> 01:16:57.480
command that I'm giving to the model input. It's a context.

01:16:58.140 --> 01:17:01.380
If I wanted to give a context, I will give. If I don't want

01:17:01.380 --> 01:17:04.540
to give a context, I will not give. For example, you must

01:17:04.540 --> 01:17:06.880
have seen that you try to give a user input, right? So you

01:17:06.880 --> 01:17:10.880
try to give a context that you are a professor, you are a

01:17:10.880 --> 01:17:14.460
coder, you are a senior architect kind of instruction,

01:17:14.840 --> 01:17:17.240
right? Or maybe some sort of a context we try to give that,

01:17:17.280 --> 01:17:20.760
okay, behave like this so that it will be able to, you know,

01:17:20.800 --> 01:17:24.960
change. It's behavior. So this kind of a data you have to

01:17:24.960 --> 01:17:29.760
prepare for your, any kind of a fine tuning you are trying

01:17:29.760 --> 01:17:32.220
to do. So technically a full fine tuning I'm talking about.

01:17:32.300 --> 01:17:35.920
So where I will change the weight, entire weight, I'll try

01:17:35.920 --> 01:17:38.460
to like, you know, train the entire weights. But again, so

01:17:38.460 --> 01:17:42.720
it will, it will not like, you know, uh, change the weights

01:17:42.720 --> 01:17:46.020
drastically. The reason is very simple. My model is already

01:17:46.020 --> 01:17:49.520
trained, so losses will not be much. It already understands.

01:17:49.520 --> 01:17:52.820
Sure. It's a very good English, right? Combination of your,

01:17:52.880 --> 01:17:57.000
all of these words, it's the best one. So is it like a

01:17:57.000 --> 01:18:00.860
memory? I'm not like a memory memory. We talk about it in a

01:18:00.860 --> 01:18:04.840
different context. It's like more like a giving some sort of

01:18:04.840 --> 01:18:09.280
additional information context, right? So basically like

01:18:09.280 --> 01:18:12.580
something like that. Yeah. So for example, if like you are

01:18:12.580 --> 01:18:15.160
going to ask a question that who is your answer Kumar, and

01:18:15.160 --> 01:18:18.460
then you have written something, but you have also given my

01:18:18.460 --> 01:18:22.100
childhood context to this one. Just like that. Yeah. Think

01:18:22.100 --> 01:18:25.440
in that way. So input instruction is basically like what you

01:18:25.440 --> 01:18:28.940
want your model to do. Input means just additional context,

01:18:29.060 --> 01:18:32.660
which is optional, not mandatory. So you can give it, you

01:18:32.660 --> 01:18:35.980
can leave it up to you. Output and instruction is important.

01:18:36.260 --> 01:18:39.280
So this is the input. Technically you can say that this is

01:18:39.280 --> 01:18:41.060
the instruction I'm giving to the model, and this is

01:18:41.060 --> 01:18:44.680
something that it is supposed to reply to me, right? So as

01:18:44.680 --> 01:18:47.640
you can see, how does paternity leave and childcare policy

01:18:47.640 --> 01:18:50.260
work? So male employee gets seven days paid paternity leave.

01:18:50.280 --> 01:18:53.620
Within six months of childbirth, as per my company policy,

01:18:53.800 --> 01:18:56.620
right? As per my company policy, additional five days can be

01:18:56.620 --> 01:19:00.320
taken using a CL and EL, like a for adoptive father, five

01:19:00.320 --> 01:19:04.200
days leave granted new parents, both can avail of flexible

01:19:04.200 --> 01:19:07.800
working hour for one year, post childbirth daycare allow for

01:19:07.800 --> 01:19:10.800
a rupees 5,000 per month provided for our children below

01:19:10.800 --> 01:19:14.040
three year, a crutch facilities available at the corporate

01:19:14.040 --> 01:19:18.940
office for the parents convenience. Right? Now just see the

01:19:18.940 --> 01:19:22.500
detail. The detail answer. This is where you need a human,

01:19:22.680 --> 01:19:27.360
right? Human. If you are not going to prepare a data

01:19:27.360 --> 01:19:33.890
properly, entire training will go for a toss as simple as

01:19:33.890 --> 01:19:36.730
that, right? So it takes a lot of time, lot of observation,

01:19:37.130 --> 01:19:40.130
lot of like a back and forth checks is required. Then only

01:19:40.130 --> 01:19:43.910
you will be able to prepare the data at the end of the day,

01:19:43.990 --> 01:19:48.070
right? So data preparation is a tough task, obviously,

01:19:48.170 --> 01:19:51.510
right? It is a tough task. So. So you should be very, very

01:19:51.510 --> 01:19:53.670
careful and we have spent a lot of time, a lot of like a

01:19:53.670 --> 01:19:56.650
verification. We try to do in a multiple manner. Most of

01:19:56.650 --> 01:20:00.550
those like things are a manual by the way. Yeah. And uh,

01:20:00.650 --> 01:20:03.030
there must be some observer. There must be some subject

01:20:03.030 --> 01:20:05.990
matter expert or functional people. So who will be doing all

01:20:05.990 --> 01:20:09.450
of these things plus some HR, obviously if, if I'm like

01:20:09.450 --> 01:20:11.810
talking about HR data, so obviously HR understand these

01:20:11.810 --> 01:20:14.390
policies, right? So obviously they have to verify, they have

01:20:14.390 --> 01:20:16.590
to approve. If I'm talking about the finance, so some

01:20:16.590 --> 01:20:18.370
finance guy must be involved. Healthcare means some

01:20:18.370 --> 01:20:20.150
healthcare guy must be involved. All who understands this

01:20:20.150 --> 01:20:24.410
data, marketing sales, it goes for the same. Okay. So when I

01:20:24.410 --> 01:20:27.330
talk about a fine tuning, right, full fine tuning simply

01:20:27.330 --> 01:20:29.430
means that I'm changing the entire weight of the model, but

01:20:29.430 --> 01:20:32.030
yeah, the weight will be changed versus the loss and system

01:20:32.030 --> 01:20:35.230
already understand the combinations, right? Uh, text

01:20:35.230 --> 01:20:38.430
combinations and grammar and everything. So it will not

01:20:38.430 --> 01:20:41.330
adopt, like it will not like, uh, you know, change the

01:20:41.330 --> 01:20:45.330
weights drastically. It will just do the minor changes now.

01:20:45.710 --> 01:20:48.610
So if I'll talk about a data set for this parameter,

01:20:48.870 --> 01:20:51.330
efficient. Okay. This is a fine tuning, right? So again,

01:20:51.490 --> 01:20:56.110
it's going to be a similar kind of a data, yeah, similar

01:20:56.110 --> 01:20:58.790
kind of a data. It's not going to be different kind of a

01:20:58.790 --> 01:21:03.030
data that we prepare for a pre-fit, uh, here. So what we are

01:21:03.030 --> 01:21:05.390
changing, so we are not talking about the data. Data can be

01:21:05.390 --> 01:21:07.350
anything, right? So here we are talking about the

01:21:07.350 --> 01:21:10.630
architecture of the model. So in case of Laura, so we are

01:21:10.630 --> 01:21:13.310
trying to add maybe this parallel layer of a neural network

01:21:13.310 --> 01:21:15.770
and this network we are trying to train with the original

01:21:15.770 --> 01:21:18.210
data and this network is going to be as it is, right? This

01:21:18.210 --> 01:21:21.470
is what we do with respect to Laura, Laura. So we are trying

01:21:21.470 --> 01:21:25.110
to, you know, uh, change the bit representation of this big

01:21:25.110 --> 01:21:27.930
model itself so that my model will be very, very small. And

01:21:27.930 --> 01:21:30.770
then we are like, you know, uh, training the model

01:21:30.770 --> 01:21:33.430
parallely. So basically it's a quantized Laura, right? So

01:21:33.430 --> 01:21:37.430
the extension of the Laura. So here in this approach, again,

01:21:37.550 --> 01:21:41.630
your data set is going to be same. You are not supposed to

01:21:41.630 --> 01:21:45.470
change the data. So here you will be able to find out that,

01:21:45.490 --> 01:21:49.090
uh, this is what I have been doing. Okay. So when I was like

01:21:49.090 --> 01:21:51.510
trying to prepare the data, you will be able to see the same

01:21:51.510 --> 01:21:54.170
thing instruction input and like, you know, the output part,

01:21:54.370 --> 01:21:59.100
yeah, instruction input output part. So it's the same data,

01:21:59.200 --> 01:22:01.440
similar kind of a data format instruction means command to

01:22:01.440 --> 01:22:04.960
the system and then input context. I have not given that.

01:22:05.320 --> 01:22:07.900
I've just kept it as a blank and then output means what will

01:22:07.900 --> 01:22:10.100
be the output with respect to that. So we have a marketing

01:22:10.100 --> 01:22:13.100
data and if you'll read out this data, it's a real, you will

01:22:13.100 --> 01:22:15.780
feel like it's a, it's a real one. It's all the data set is

01:22:15.780 --> 01:22:18.540
making sense. This is how I have prepared my data set by the

01:22:18.540 --> 01:22:21.300
way. Same goes with our sales data set. Same goes with the

01:22:21.300 --> 01:22:24.240
HR data set. Same goes with the healthcare data set

01:22:24.240 --> 01:22:27.220
instruction input output, right? Because I'm going to use

01:22:27.220 --> 01:22:30.120
all of these data in either LoRa, either Quora, either full

01:22:30.120 --> 01:22:33.480
fine tuning or maybe simple prefet, right? Just to call a

01:22:33.480 --> 01:22:38.480
prefet. So these data set now here in case of DPO, you will

01:22:38.480 --> 01:22:42.560
be able to see a little bit of differences, right? It's,

01:22:42.560 --> 01:22:46.020
it's not same by the way. So here you will be able to see

01:22:46.020 --> 01:22:49.260
something called as prompt input. Choose. You can reject it.

01:22:49.340 --> 01:22:52.240
So all of these like a different, a little bit of

01:22:52.240 --> 01:22:55.400
differences, right? Not much of differences, but yeah, a

01:22:55.400 --> 01:22:58.260
little bit of differences, uh, basically you will be able

01:22:58.260 --> 01:22:59.740
to, uh, find out.

01:23:09.440 --> 01:23:13.100
So here, what is a DPO by the way? So full form wise DPO is

01:23:13.100 --> 01:23:16.520
nothing but it's a direct preference optimization, fine

01:23:16.520 --> 01:23:22.320
direct preference optimization. Now so here basically we try

01:23:22.320 --> 01:23:26.980
to give here a pair of a preferred versus a rejected one.

01:23:26.980 --> 01:23:30.020
It's kind of a reinforcement learning, right? So we are

01:23:30.020 --> 01:23:32.900
trying, reinforcement learning means give a feedback and

01:23:32.900 --> 01:23:36.060
from the feedback it will learn. Now in a DPO, direct

01:23:36.060 --> 01:23:38.940
preference optimization, what we try to do, so we try to

01:23:38.940 --> 01:23:44.280
give a preferred one and versus a rejected one and based on

01:23:44.280 --> 01:23:46.680
that, so it will be able to, you know, understand that,

01:23:46.720 --> 01:23:49.500
okay, fine. So what I'm supposed to understand, like what,

01:23:49.540 --> 01:23:52.960
what I'm supposed to basically, uh, like, uh, give as an

01:23:52.960 --> 01:23:56.920
answer against this one. Okay. So here, as you can see, this

01:23:56.920 --> 01:23:59.740
is a prompt, prompt means instruction, right? That okay,

01:23:59.800 --> 01:24:02.140
fine. Do this, uh, everywhere you will be able to find out

01:24:02.140 --> 01:24:05.260
the prompt. So prompt means basically, for example, how I

01:24:05.260 --> 01:24:10.280
can, uh, save income tax legally in India. Fine. Now this is

01:24:10.280 --> 01:24:12.900
the instruction and for this instruction model is supposed

01:24:12.900 --> 01:24:16.300
to learn fine. So I'm talking about the finance document,

01:24:16.440 --> 01:24:19.700
let's suppose finance policy. Now input means again, same

01:24:19.700 --> 01:24:21.900
thing, context we are talking about. So we have already

01:24:21.900 --> 01:24:24.260
discussed. So if I would like to give an additional

01:24:24.260 --> 01:24:27.560
references from internet. Or maybe from my databases, I can

01:24:27.560 --> 01:24:32.320
do that and I can leave it optional. Then for this input,

01:24:32.560 --> 01:24:36.380
this is the chosen answer means this is the correct answer.

01:24:36.600 --> 01:24:40.520
So legal tax saving option includes a section 86 rupees, 1.5

01:24:40.520 --> 01:24:44.560
lakh PPF, ELSS, insurance tuition fees section and all these

01:24:44.560 --> 01:24:46.880
things. This is the option which is given to you, which is

01:24:46.880 --> 01:24:50.400
technically a correct answer, chosen one, right? Against

01:24:50.400 --> 01:24:53.920
that, against this answer. So just invest in a mutual fund

01:24:53.920 --> 01:24:56.160
and you can save all your taxes. You don't need to worry

01:24:56.160 --> 01:24:59.020
about any document. Now this is something which I'm writing

01:24:59.020 --> 01:25:02.920
against it means a rejected one that, okay, you should not

01:25:02.920 --> 01:25:07.900
learn this one. So even by not learning something, you are

01:25:07.900 --> 01:25:13.280
learning something, right? Yeah. So let's suppose if I'm

01:25:13.280 --> 01:25:17.820
like a teaching my child that, uh, do not learn the abusive

01:25:17.820 --> 01:25:23.180
word, right? So basically even by asking him or her not to

01:25:23.180 --> 01:25:28.140
learn the abusive word. I'm trying to teach and basically my

01:25:28.140 --> 01:25:32.620
child is learning, yeah. So not learning something is also a

01:25:32.620 --> 01:25:35.980
learning process basically, right? It's it's a learning

01:25:35.980 --> 01:25:39.440
process. So this is what we do and basically you can create,

01:25:39.460 --> 01:25:43.360
treat it as a feedback loop. Yeah. Feedback loop. So

01:25:43.360 --> 01:25:46.940
basically this is my instruction and uh, this is my context.

01:25:47.020 --> 01:25:49.380
So context is blank, let's suppose, and this should be the

01:25:49.380 --> 01:25:53.240
ideal answer and this is something which I just want my

01:25:53.240 --> 01:25:58.040
model. To unlearn or you can like say that that, okay, fine.

01:25:58.180 --> 01:26:03.280
So whenever, like not give this kind of answer for this kind

01:26:03.280 --> 01:26:05.800
of a question, not to give this kind of answer. This is what

01:26:05.800 --> 01:26:08.300
is called as a rejected. So chosen one and the rejected one.

01:26:08.360 --> 01:26:11.500
So this is kind of a feedback loop. The way we try to like

01:26:11.500 --> 01:26:14.500
behave in a RLHF reinforcement, like a learning with the

01:26:14.500 --> 01:26:18.200
human inferences or human interference. So similar kind of a

01:26:18.200 --> 01:26:20.900
data we are trying to prepare over there so that you know,

01:26:20.940 --> 01:26:24.520
it will learn from the preferences. Yeah. And again from the

01:26:24.520 --> 01:26:28.680
rejected as well, both. So this is a data. So you will be

01:26:28.680 --> 01:26:32.080
able to find out like for a RLHF for, for a DPOs, we are

01:26:32.080 --> 01:26:35.400
having a different kind of a data, but for like full fine

01:26:35.400 --> 01:26:39.300
tuning and uh, like a LoRa, Quora, all those things, we have

01:26:39.300 --> 01:26:42.680
a similar kind of a data. So I believe we all understands a

01:26:42.680 --> 01:26:45.500
data preparation strategy, right guys. And you can read out

01:26:45.500 --> 01:26:48.020
all this data, every data, the data that I have prepared,

01:26:48.140 --> 01:26:51.180
it's not a vague one. It's, it will, every line will make

01:26:51.180 --> 01:26:54.540
you like give you a sense. And I'll show you my output also,

01:26:54.720 --> 01:26:57.280
yesterday it took almost like one and half hour of time for

01:26:57.280 --> 01:27:03.220
me to train this five model, right? So train this five, one,

01:27:03.320 --> 01:27:06.840
two, three, four, yeah, five or six model, I can say. And

01:27:06.840 --> 01:27:10.700
I'll, I'll show you the final output. It's amazing with

01:27:10.700 --> 01:27:14.220
respect to these data set. It's literally amazing, right?

01:27:14.580 --> 01:27:17.440
Means you can directly send those model to a production. So

01:27:17.440 --> 01:27:21.220
basically I have not trained for a lot of epochs, just for

01:27:21.220 --> 01:27:23.580
two, three epochs, I have trained my model, right? And that

01:27:23.580 --> 01:27:26.320
too in my local system, it's giving me pretty much good

01:27:26.320 --> 01:27:30.820
result. Yeah. We'll, we'll learn those things, but yeah, I

01:27:30.820 --> 01:27:33.600
hope a data preparation strategy is clear to all of us.

01:27:38.140 --> 01:27:41.920
Yes. Okay. So now we all understand that. Okay. So if I have

01:27:41.920 --> 01:27:44.160
to go ahead with the full fine tuning LoRa, Quora, so what

01:27:44.160 --> 01:27:46.060
kind of a data I have to prepare if I have to go with the

01:27:46.060 --> 01:27:48.500
DPO, so what kind of a data I have to prepare and we

01:27:48.500 --> 01:27:51.160
understands a meaning of these like a, you know, things as

01:27:51.160 --> 01:27:54.340
well. So everywhere, wherever you will go in this world, you

01:27:54.340 --> 01:27:57.600
will find the exact same thing. Right. It's a universal one

01:27:57.600 --> 01:28:00.700
by the way, but there are like a millions of model out there

01:28:00.700 --> 01:28:05.140
on hugging phase. Even you can log into your, you know, this

01:28:05.140 --> 01:28:10.420
open AI interface and even inside that you will be able to

01:28:10.420 --> 01:28:14.660
find out like a models and inside that you will be able to

01:28:14.660 --> 01:28:17.860
find out a fine tuning panel where you can go, you can try

01:28:17.860 --> 01:28:20.320
to put your data and then you will be able to do a fine

01:28:20.320 --> 01:28:24.820
tuning. This is how you should prepare that. This is how you

01:28:24.820 --> 01:28:27.980
will end up preparing the data. So basically it's a kind of

01:28:27.980 --> 01:28:32.020
approach which is applied to all millions of model out there

01:28:32.020 --> 01:28:36.920
in real time. Doesn't matter you are doing it in a class or

01:28:36.920 --> 01:28:40.020
tomorrow you will do it in your company. Nothing is going to

01:28:40.020 --> 01:28:41.960
change. Yeah. Not even a bit of it.

01:28:45.640 --> 01:28:48.320
Also just wanted a glimpse how you have prepared. See it's,

01:28:48.320 --> 01:28:50.620
it's a kind of a manual approach, right? It's a kind of a

01:28:50.620 --> 01:28:53.300
manual approach. You need like some document you have to

01:28:53.300 --> 01:28:55.600
pass through some document and then you have to, like, you

01:28:55.600 --> 01:28:57.300
know, create a question, answer, question, answer, question,

01:28:57.340 --> 01:29:01.120
answer. Like I said, it's, it's, it's a hectic one, right?

01:29:02.260 --> 01:29:05.100
It's not like simple. You will write a code and then it will

01:29:05.100 --> 01:29:08.280
prepare. No, you have to go, you have, you must be having a

01:29:08.280 --> 01:29:11.200
subject understanding. You have to involve people right for

01:29:11.200 --> 01:29:15.620
a cross check because this is how, how your code will

01:29:15.620 --> 01:29:17.340
understand that what will be the question, what will be the

01:29:17.340 --> 01:29:20.320
answer. Yeah. Now you will say that I will go and generate

01:29:20.320 --> 01:29:23.040
an answer from a GPT. I mean like then you will lose the

01:29:23.040 --> 01:29:26.880
context of your own data. Yeah. GPT will give you a generic

01:29:26.880 --> 01:29:29.920
answer. Your data is having some like a specific to your

01:29:29.920 --> 01:29:32.720
company, right? Policies will be specific to your company.

01:29:32.820 --> 01:29:37.180
My HR policies is not going to be the, you know, GPT HR like

01:29:37.180 --> 01:29:39.880
a policy that GPT is going to give it to me, right? My

01:29:39.880 --> 01:29:43.160
financial policy, my HR policies or my sales pitch because

01:29:43.160 --> 01:29:47.400
it's my product, right? My marketing strategy, all, all

01:29:47.400 --> 01:29:50.080
those things, right? All those things are like not going to

01:29:50.080 --> 01:29:52.580
be a generic one. That's an, it is not a generic one. That's

01:29:52.580 --> 01:29:55.080
the reason we are doing fine tuning, right? Otherwise, what

01:29:55.080 --> 01:30:01.860
is the need of fine tuning? Yeah. The only reason we are

01:30:01.860 --> 01:30:04.800
going ahead with the fine tuning is very simple. The

01:30:04.800 --> 01:30:08.740
existing LLM is not able to give an answer with respect to

01:30:08.740 --> 01:30:11.900
my custom data. That was the whole reason. So in that

01:30:11.900 --> 01:30:14.780
situation, this is, this is kind of a hectic task. Actually,

01:30:14.780 --> 01:30:18.560
this is not like a easy task and obviously team will be

01:30:18.560 --> 01:30:20.920
involved. Functional people will be involved. Domain expert

01:30:20.920 --> 01:30:24.200
will be involved over here. It takes time. It takes time

01:30:24.200 --> 01:30:28.340
always because you have to do a vetting of every data set,

01:30:28.500 --> 01:30:32.700
right? Because if this question and if this answer is going

01:30:32.700 --> 01:30:35.980
to be wrong, then obviously you can't expect a correct

01:30:35.980 --> 01:30:41.850
answer from your model. As simple as that means always we

01:30:41.850 --> 01:30:44.110
need a already existing model with the fine tuning, then

01:30:44.110 --> 01:30:47.430
only model work according to our organization. So always

01:30:47.430 --> 01:30:51.230
need a existing model with a fine tuning. Yeah. The good

01:30:51.230 --> 01:30:54.290
one, the best one, right? This is called as fine tuning,

01:30:54.390 --> 01:30:56.750
right? Otherwise you can do a training from the scratch.

01:30:56.990 --> 01:31:01.150
That is, that also I have taught in so many classes. So you

01:31:01.150 --> 01:31:04.790
can try to train the entire transformer on your own and like

01:31:04.790 --> 01:31:10.830
starting from like a scratch basically. Consult with HR

01:31:10.830 --> 01:31:13.610
team, sales team, then yeah, everyone, everyone, whoever is

01:31:13.610 --> 01:31:16.110
a part of like, you know, the process and for whomever you

01:31:16.110 --> 01:31:18.470
are creating a model because I'll create one model for my

01:31:18.470 --> 01:31:21.390
finance team, HR team, I'll create one model like for every

01:31:21.390 --> 01:31:24.050
department, even in one single department. Maybe multiple

01:31:24.050 --> 01:31:27.430
model. This is how we are shipping a model nowadays, right?

01:31:27.470 --> 01:31:28.350
This is how we are doing it.

01:31:32.900 --> 01:31:35.420
So redacted. So introduce a bias towards the correct result

01:31:35.420 --> 01:31:38.120
instead of hallucination. Yeah, basically. So we are trying

01:31:38.120 --> 01:31:40.320
to, you know, control the hallucination over here. That

01:31:40.320 --> 01:31:42.760
means there is something called as like we are saying that,

01:31:42.820 --> 01:31:46.400
okay, learn this and unlearn this. Unlearning is also a

01:31:46.400 --> 01:31:50.980
learning process. This is what I'm trying to say. Data

01:31:50.980 --> 01:31:53.740
preparation will save our job. It will be a huge task.

01:31:53.920 --> 01:31:58.060
Generally Junius does that. Every company, right? Even GPT.

01:31:58.060 --> 01:32:01.360
OpenA kind of a company. They have a big, big like a team

01:32:01.360 --> 01:32:05.760
and mostly they used to even outsource those jobs, right? So

01:32:05.760 --> 01:32:09.000
where like a labor cost, labor cost means engineers cost.

01:32:09.100 --> 01:32:12.640
That's a labor market, right, for IT industry. So where

01:32:12.640 --> 01:32:15.180
labor cost will be less. So they try to just outsource those

01:32:15.180 --> 01:32:19.020
work to like, you know, those countries or maybe you can say

01:32:19.020 --> 01:32:25.340
those teams, they just try to like observe it so that they

01:32:25.340 --> 01:32:28.180
prepare the data. Yeah. It's a big industry itself. Data

01:32:28.180 --> 01:32:31.380
labeling is one of the like a very big industry.

01:32:37.360 --> 01:32:38.780
It's a data rotation. Yes.

01:32:42.470 --> 01:32:45.270
Interns from low price country college. Yeah. And then it's

01:32:45.270 --> 01:32:49.150
like people used to hire massively. If you look back, maybe

01:32:49.150 --> 01:32:54.490
three or four years back, right. Maybe you guys were not a

01:32:54.490 --> 01:32:56.650
part of data science industry or something, but yeah, if you

01:32:56.650 --> 01:32:58.630
can go and ask someone who were already a part of data

01:32:58.630 --> 01:33:00.830
science industry, you will be able to like, you know, see

01:33:00.830 --> 01:33:04.130
that they will tell you that. Okay. So it's a very, very big

01:33:04.130 --> 01:33:07.350
industry. And you know, it's providing a job to not just

01:33:07.350 --> 01:33:10.430
thousand people. So like 10,000, 20,000 people are working

01:33:10.430 --> 01:33:13.170
in like one single team and they are doing day and night one

01:33:13.170 --> 01:33:16.550
thing like data annotating, data labeling, because to train

01:33:16.550 --> 01:33:19.550
even like, you know, self-driving car, I need like all the

01:33:19.550 --> 01:33:21.750
object labeling, teeny tiny object labeling, right. Then I

01:33:21.750 --> 01:33:26.010
can build a best of best vision model. Same goes for NLP. So

01:33:26.010 --> 01:33:29.670
just like, just imagine to train like a GPT kind of a model,

01:33:29.750 --> 01:33:33.770
how much data preparation they have done. So obviously in

01:33:33.770 --> 01:33:37.110
that. Yeah. Because it's like, it's aware about the world's

01:33:37.110 --> 01:33:41.350
data, right. So like just imagine how many people were

01:33:41.350 --> 01:33:45.610
required and what kind of checks, scrutiny, all those things

01:33:45.610 --> 01:33:48.590
are required. So a huge management, a huge data labeling,

01:33:48.750 --> 01:33:51.570
annotation team, everything is required for that kind of a

01:33:51.570 --> 01:33:54.510
model, which they have to like train it from the scratch.

01:33:57.300 --> 01:34:00.320
Nowadays almost all the data set we are able to label. So

01:34:00.320 --> 01:34:04.340
yeah, specific to a particular, like in a particular project

01:34:04.340 --> 01:34:07.820
itself, you will get that job, but yeah, like as a data

01:34:07.820 --> 01:34:12.620
labeler. So even that job is somewhere like nowadays

01:34:12.620 --> 01:34:17.120
reducing because we are able to label most of the data.

01:34:17.420 --> 01:34:20.200
That's the reason we are able to create best LLM model. But

01:34:20.200 --> 01:34:23.880
yeah, it will, it will be in picture all the time. It will

01:34:23.880 --> 01:34:27.000
be required. Maybe not with the same kind of intensity that

01:34:27.000 --> 01:34:31.540
was there two or three years back, but yeah, it will be

01:34:31.540 --> 01:34:37.000
required. It's a raw data used in pre-training, right. Yeah.

01:34:37.020 --> 01:34:40.320
It depends what kind of a training I'm trying to do, right.

01:34:40.520 --> 01:34:43.120
Depends. So what kind of a training, what kind of a model

01:34:43.120 --> 01:34:45.520
I'm trying to build. So I'm trying to build maybe a question

01:34:45.520 --> 01:34:49.000
answer generation model, or I'm trying to maybe build like a

01:34:49.000 --> 01:34:53.760
language translation models, right. It always depends nature

01:34:53.760 --> 01:34:58.100
of the training that we are supposed to like, or we are

01:34:58.100 --> 01:34:58.520
doing it.

01:35:05.280 --> 01:35:10.520
Okay. So now let's go ahead. So this is basically a data. I

01:35:10.520 --> 01:35:12.860
believe our understanding with respect to our data is pretty

01:35:12.860 --> 01:35:20.200
much. Okay. Right. Then we have to choose a model, right? So

01:35:20.200 --> 01:35:26.640
once my data labeling is done, so type of fine tuning. So

01:35:26.640 --> 01:35:28.960
let's suppose I have decided that I'll go ahead with the

01:35:28.960 --> 01:35:31.560
full fine tuning, right. Or maybe I'll go ahead with a coral

01:35:31.560 --> 01:35:34.520
or, or maybe a DPO, then I'll do a data preparation

01:35:34.900 --> 01:35:37.960
accordingly. Then obviously I'll choose the hardware side of

01:35:37.960 --> 01:35:40.460
it. So as of now, I'm going to do a training in my local,

01:35:40.500 --> 01:35:43.760
like I said, yesterday it took around, like a one and a half

01:35:43.760 --> 01:35:47.560
hour of time for me in terms of training. Then I'll try to

01:35:47.560 --> 01:35:52.340
prepare a code and infra. So here, when I say code before

01:35:52.340 --> 01:35:56.800
that, so we have to even prepare a base model. So which

01:35:56.800 --> 01:36:02.480
model I'm going to choose. So base model, right? So which

01:36:02.480 --> 01:36:05.860
base model I'm going to consider and which base model I will

01:36:05.860 --> 01:36:09.620
be like, you know, fine tuning. Okay. So here you will be

01:36:09.620 --> 01:36:13.980
able to find out in my code base. So I have just separated

01:36:13.980 --> 01:36:17.240
all the file in a very, very clean manner. So full fine

01:36:17.240 --> 01:36:21.500
tuning, Laura, Cora, Prefet, just go to any of these code

01:36:21.500 --> 01:36:25.180
bases. I'm using a very, very light weighted model called as

01:36:25.180 --> 01:36:29.320
tiny Lama, 1.1 billion chat V one zero model. So this is

01:36:29.320 --> 01:36:32.360
coming from a hugging phase, right? It's an open source

01:36:32.360 --> 01:36:36.320
model. I'm just trying to basically use this particular

01:36:36.320 --> 01:36:41.740
model everywhere. Okay. You can try to use GPT OSS 20 B one

01:36:41.740 --> 01:36:46.240
20 B any other model, any other LLM models. You can try to

01:36:46.240 --> 01:36:49.540
use it instead of using this particular model. So this is

01:36:49.540 --> 01:36:52.400
just a base one of the base model I'm using. You can use

01:36:52.400 --> 01:36:56.480
like a, all the black models out there and it just depends

01:36:56.480 --> 01:37:00.760
upon you. If I'll talk about this entire training part, it's

01:37:00.760 --> 01:37:04.300
very, very easy. Believe me, right? It's very, very easy to

01:37:04.300 --> 01:37:07.920
understand. Let me give you the explanation. And it's not at

01:37:07.920 --> 01:37:11.660
all tough to understand. So code wise, it's nothing. Believe

01:37:11.660 --> 01:37:15.440
me, it's just a configuration means prepare the data, select

01:37:15.440 --> 01:37:18.720
the model, set a parameter training parameter for the model

01:37:18.720 --> 01:37:23.620
done. So code wise, it's not at all difficult to believe me.

01:37:23.700 --> 01:37:26.300
So preparation before like whatever preparation that we do

01:37:26.300 --> 01:37:29.480
before that, that's a major part, but yeah, putting

01:37:29.480 --> 01:37:32.920
something for a training on my local hardware or on

01:37:32.920 --> 01:37:36.040
basically like a GPUs. It's again, not a big deal. Anyone

01:37:36.040 --> 01:37:39.740
can do it in the easiest possible manner. So let's try to

01:37:39.740 --> 01:37:42.080
take a understanding. So let's suppose I'm going out of the

01:37:42.080 --> 01:37:48.460
DPO right. Like that preference optimization now here. So I

01:37:48.460 --> 01:37:52.220
have prepared basically our finance data for a DPO. So if

01:37:52.220 --> 01:37:55.080
I'm doing a DPO fine tuning, DPO based fine tuning. So I'll

01:37:55.080 --> 01:37:57.560
be using a finance data right. I have already named it in a

01:37:57.560 --> 01:38:00.160
very, very clear manner that for finance I believe using

01:38:00.160 --> 01:38:04.540
DPO. So let's suppose this is a DPO code. Uh, for doing a

01:38:04.540 --> 01:38:08.040
fine tuning. tuning so data is already been prepared right

01:38:08.040 --> 01:38:11.800
data is already been prepared so here I have written a

01:38:11.800 --> 01:38:15.860
simple function to load a finance DPO data set so I am

01:38:15.860 --> 01:38:19.000
trying to open up a file as you can see so with open file in

01:38:19.000 --> 01:38:23.220
a read mode right and load the JSON data so this will lead

01:38:23.220 --> 01:38:28.100
the entire JSON data now inside my DPO data set I have what

01:38:28.100 --> 01:38:31.840
I have prompt chosen and rejected these three things I have

01:38:31.840 --> 01:38:34.420
I have four things actually input I have but yeah input is a

01:38:34.420 --> 01:38:37.760
context and I have kept input as a blank everywhere so I am

01:38:37.760 --> 01:38:41.020
not going to consider it like I said so I can do a key value

01:38:41.020 --> 01:38:43.860
mapping so again these names doesn't matter so I can I can

01:38:43.860 --> 01:38:47.560
like give some different name that's okay because anyhow I

01:38:47.560 --> 01:38:51.440
am doing a mapping over here right but context intent should

01:38:51.440 --> 01:38:54.220
not change intent should not in form prunes instruction

01:38:54.220 --> 01:38:56.780
chosen means the correct answer rejected means the counter

01:38:56.780 --> 01:39:01.340
one right so intent should not change name you can like give

01:39:01.340 --> 01:39:03.820
any kind of a name any variable name doesn't matter at all.

01:39:03.820 --> 01:39:07.100
Even in your JSON file you just have to do a mapping so that

01:39:07.100 --> 01:39:10.680
system can understand so here I am trying to create a three

01:39:10.680 --> 01:39:13.820
like a empty list as you can see and then I am running

01:39:13.820 --> 01:39:17.420
through a data right so whatever JSON that I have loaded

01:39:17.420 --> 01:39:22.320
technically this JSON which I am going to load where I will

01:39:22.320 --> 01:39:25.900
be having prompt chosen and rejected one so I am just like

01:39:25.900 --> 01:39:30.680
trying to like you know go through this JSON one by one data

01:39:30.680 --> 01:39:34.880
one by one and then in our prompt list I am adding prompt in

01:39:34.880 --> 01:39:37.740
a chosen list I am adding chosen in a rejected list I am

01:39:37.740 --> 01:39:41.780
adding a rejected and then it is going to return me a data

01:39:41.780 --> 01:39:44.980
into a dictionary format right dictionary format so this is

01:39:44.980 --> 01:39:47.680
what this function is doing I believe this function is

01:39:47.680 --> 01:39:51.160
pretty much clear I believe one of the easiest Pythonic

01:39:51.160 --> 01:39:55.300
function you must have seen in recent days yeah one of the

01:39:55.300 --> 01:39:59.640
easiest one right just like a story I think anyone can

01:39:59.640 --> 01:40:02.480
understand and you can write it down yeah okay. So, this.

01:40:02.940 --> 01:40:05.320
Function will take your file path only, so wherever your

01:40:05.320 --> 01:40:08.000
data set is may be on some server, may be on some drive, may

01:40:08.000 --> 01:40:12.060
be on S3 or whatever, read the data and then like finally

01:40:12.060 --> 01:40:15.940
give me the dictionary of it, dictionary out of it. So may

01:40:15.940 --> 01:40:19.580
be my data could be available in a JSON format let's

01:40:19.580 --> 01:40:22.860
suppose, may be my data is available into a text file let's

01:40:22.860 --> 01:40:26.820
suppose, my data set is available into a CSV file in a excel

01:40:26.820 --> 01:40:33.920
sheet, what I want, I want this kind of a data, dictionary

01:40:33.920 --> 01:40:38.240
format of the data set I am looking for. Is it making sense

01:40:38.240 --> 01:40:46.290
to all of us guys? So in this format basically. Now again

01:40:46.290 --> 01:40:49.470
people will ask me a question that why, I mean like the

01:40:49.470 --> 01:40:54.030
simple answer is why your name is XYG because someone has

01:40:54.030 --> 01:40:57.550
already defined. So those who have created this like you

01:40:57.550 --> 01:41:00.230
know this like a training format. Trainer functions, trainer

01:41:00.230 --> 01:41:03.450
function basically, they have defined that whenever you are

01:41:03.450 --> 01:41:06.350
giving an input to me you should always follow this rule

01:41:06.350 --> 01:41:08.570
that you should always convert your data in this way and

01:41:08.570 --> 01:41:11.810
then I will, it is not like you will just like you know read

01:41:11.810 --> 01:41:15.070
some scrap of the data in any format and then dump it and

01:41:15.070 --> 01:41:17.150
then system will be able to understand automatically right.

01:41:17.230 --> 01:41:19.870
System will never be able to understand. System is not

01:41:19.870 --> 01:41:22.770
having that kind of a capabilities. It will only understand

01:41:22.770 --> 01:41:25.650
the instruction that you are going to give which is already

01:41:25.650 --> 01:41:30.030
predefined. So this kind of a data set. What data? I will

01:41:30.030 --> 01:41:33.270
try to give. So it doesn't matter in which format I have my

01:41:33.270 --> 01:41:36.090
base data. So I could have kept this data into a JSON. I

01:41:36.090 --> 01:41:38.650
could have kept this data into a TXT. I could have kept this

01:41:38.650 --> 01:41:41.390
data into a CSV, Excel, maybe into some other databases.

01:41:41.570 --> 01:41:44.530
Maybe into Mongo, Postgres, Cassandra, whatever right.

01:41:45.070 --> 01:41:49.150
Doesn't matter at all right. Ultimately I have to read those

01:41:49.150 --> 01:41:52.550
data and I have to finally prepare my data in this format.

01:41:52.750 --> 01:41:56.210
Is it making sense guys? So someone has asked me a question

01:41:56.210 --> 01:41:59.490
that do I need to prepare always a JSON data set. Do I need

01:41:59.490 --> 01:42:02.230
to have a JSON data set? Yes or no?

01:42:06.370 --> 01:42:10.750
No. I need this format of data. So finally code it, do it.

01:42:11.370 --> 01:42:16.370
Yeah. So I think that part is clear now right. That JSON

01:42:16.370 --> 01:42:18.330
data is not required. It doesn't matter like in whatever

01:42:18.330 --> 01:42:21.410
format you have keeping a data, keep it right. I just need

01:42:21.410 --> 01:42:24.590
three things. Prompt, chosen, rejected. If I am doing a DPO

01:42:24.590 --> 01:42:27.570
right. So these three things are three entities are

01:42:27.570 --> 01:42:30.850
required. I will just like and then finally read it from

01:42:30.850 --> 01:42:33.970
some like any other places. Ok. and then finally prepare the

01:42:33.970 --> 01:42:36.930
data set into a dictionary format by using maybe this data

01:42:36.930 --> 01:42:41.730
set library okay now moving to the next part right a

01:42:41.730 --> 01:42:45.690
training part now to do a training right so this is a

01:42:45.690 --> 01:42:50.530
function right this is a function so here to do a training

01:42:50.530 --> 01:42:55.050
basically i have to give a data set part number one to do

01:42:55.050 --> 01:42:59.470
any kind of a training i have to give a model a base model

01:42:59.470 --> 01:43:04.330
and then after a training model will save somewhere yeah

01:43:04.330 --> 01:43:08.090
model will be saved in some directory all the files model

01:43:08.090 --> 01:43:12.030
files then epoch how many times we are going to pass the

01:43:12.030 --> 01:43:15.250
entire data right then a batch size basically so how many

01:43:15.250 --> 01:43:18.650
data will go in one single like a you know run then a

01:43:18.650 --> 01:43:22.010
learning rate i believe we all understand this like a

01:43:22.010 --> 01:43:24.910
learning rate parameter and then the beta so again coming

01:43:24.910 --> 01:43:29.930
from your like optimization optimizer itself a beta so here

01:43:29.930 --> 01:43:33.910
these are the input which is required so this is a function

01:43:33.910 --> 01:43:37.110
we are trying to create over here and one by one one by one

01:43:37.110 --> 01:43:42.810
so we are trying to give this as a input right so those

01:43:42.810 --> 01:43:45.070
again who is having a question with respect to this data set

01:43:45.070 --> 01:43:48.770
library so basically this data set is a library so which

01:43:48.770 --> 01:43:53.750
will try to convert a data into a hugging face compatible

01:43:53.750 --> 01:43:56.830
data set object this is what this data set library is trying

01:43:56.830 --> 01:43:59.010
to do. So those who is having like a question on that part

01:43:59.010 --> 01:44:04.730
yeah simple okay so here what we are trying to do so

01:44:04.730 --> 01:44:09.170
basically there is this function this is just you know like

01:44:09.170 --> 01:44:14.210
a basically like all this base model name what is the

01:44:14.210 --> 01:44:17.290
meaning of output directory epoch batch size all these

01:44:17.290 --> 01:44:21.250
things just as a like you know write up is mentioned so just

01:44:21.250 --> 01:44:25.110
doc string you can say right so this is our function name.

01:44:25.230 --> 01:44:29.170
Now what this function is. This is trying to do so basically

01:44:29.170 --> 01:44:34.850
this function is trying to call auto tokenizer yeah so this

01:44:34.850 --> 01:44:37.650
function is trying to call auto tokenizer from pre-trained

01:44:37.650 --> 01:44:42.010
and then a model name so whatever model name you have given

01:44:42.010 --> 01:44:45.490
this let's suppose I have given as a model name what it will

01:44:45.490 --> 01:44:50.370
do technically so it will try to download that model yeah so

01:44:50.370 --> 01:44:55.010
it will try to download that particular model. So that you

01:44:55.010 --> 01:44:58.070
know I will be able to do a function. Fine tuning of that

01:44:58.070 --> 01:45:02.010
model and then we are trying to do end of the sentence

01:45:02.010 --> 01:45:05.150
tokenization so that we are trying to make sure that there

01:45:05.150 --> 01:45:08.810
should not be any kind of a missing padding available inside

01:45:08.810 --> 01:45:11.910
the model means the length of the model should be like or

01:45:11.910 --> 01:45:16.070
length of the entire embedding should be like same by the

01:45:16.070 --> 01:45:21.490
way. Then auto model from a casual lm from a pre-trained so

01:45:21.490 --> 01:45:24.830
we are giving a model name we are giving a device mapping

01:45:24.830 --> 01:45:29.170
over here. And then we are trying to give basically a low

01:45:29.170 --> 01:45:33.510
CPU memory use is equals to true. Now we are trying to give

01:45:33.510 --> 01:45:36.870
a device mapping auto means if CUDA is available CUDA means

01:45:37.230 --> 01:45:42.390
if my GPU is available right. So just try to use it if GPU

01:45:42.390 --> 01:45:46.530
is not available then try to use a CPU. So I have given both

01:45:46.530 --> 01:45:48.730
the instruction I was trying to train it. If you are

01:45:48.730 --> 01:45:52.110
training it in a GPU then you can you can remove the auto

01:45:52.110 --> 01:45:56.410
part just give a CUDA part. Right. So it will be having a

01:45:56.410 --> 01:46:00.030
GPU in my system I have a CPU I have a GPU both so I am just

01:46:00.030 --> 01:46:02.190
giving an option that okay fine so choose whatever you want

01:46:02.190 --> 01:46:04.950
whichever is available right whichever is best available at

01:46:04.950 --> 01:46:08.290
that point of a time. So just try to choose it again you

01:46:08.290 --> 01:46:11.090
will be able to control the uses of your resources your

01:46:11.090 --> 01:46:14.150
hardware. This is like something which I am trying to do

01:46:14.150 --> 01:46:18.430
with the help of this one and hope this is making sense to

01:46:18.430 --> 01:46:19.470
all of us. Yeah.

01:46:22.750 --> 01:46:30.670
So multi GPUs is available. Okay now so this is just a

01:46:30.670 --> 01:46:35.150
hardware then coming to the like this one so auto model from

01:46:35.150 --> 01:46:38.150
the casual LM from the pre-trained same thing model name

01:46:38.150 --> 01:46:43.230
this this this it seems I have repeated this things two

01:46:43.230 --> 01:46:48.170
times yeah it's I'll just remove one maybe while doing a

01:46:48.170 --> 01:46:51.750
copy paste I have copy pasted twice. Yeah. Okay. So again

01:46:51.750 --> 01:46:54.470
torch CUDA is available. If GPU is available this is what it

01:46:54.470 --> 01:46:57.670
means. So model dot half so if CUDA is available save my

01:46:57.670 --> 01:47:01.930
RAM. So this is what like half means over here so save my

01:47:01.930 --> 01:47:05.970
virtual RAM memory. So in this way I am just trying to set

01:47:05.970 --> 01:47:09.050
my system preferences that okay whenever you are trying to

01:47:09.050 --> 01:47:12.910
train my model maybe use a GPU use a CPU and then take a

01:47:12.910 --> 01:47:16.950
decision automatically. Then the main part is training

01:47:16.950 --> 01:47:19.610
argument. So what are the training argument that we are

01:47:19.610 --> 01:47:23.090
trying to give over here. So output directory. Already

01:47:23.090 --> 01:47:26.730
coming as a parameter right that okay where you have to save

01:47:26.730 --> 01:47:30.330
the model. So I can give any path any directory wherever I

01:47:30.330 --> 01:47:33.710
would like to save this model for this one. So this output

01:47:33.710 --> 01:47:37.870
directory I am trying to give number of training epoch. So

01:47:37.870 --> 01:47:40.090
how many number of times I would like to pass the whole data

01:47:40.090 --> 01:47:45.070
batch size again as a parameter I am trying to give gradient

01:47:45.070 --> 01:47:47.790
accumulation step. So again this is one of the parameter

01:47:47.790 --> 01:47:51.130
that we are trying to give over here then like a learning

01:47:51.130 --> 01:47:56.310
rate. LR. CUDA. I am trying to say that okay if like CUDA is

01:47:56.310 --> 01:48:00.130
available just use it. Save strategy epoch. So basically

01:48:00.130 --> 01:48:03.050
save strategy is nothing but a kind of a checkpointing. So

01:48:03.050 --> 01:48:06.190
basically for every epoch I can try to save the model for

01:48:06.190 --> 01:48:10.590
the best of the you know the output or best of the like a

01:48:10.590 --> 01:48:13.130
loss I can try to save the model. So here epoch wise I am

01:48:13.130 --> 01:48:16.430
trying to save the model. Logging steps after every 10 steps

01:48:16.430 --> 01:48:19.810
just try to log in. Warm up steps after every 50 steps just

01:48:19.810 --> 01:48:22.470
try to this one. Optimizer. So I am trying to use a Adam

01:48:22.470 --> 01:48:25.710
optimizer over here as you can see. Optimizer is required to

01:48:25.710 --> 01:48:28.470
calculate the loss and like you know accordingly a

01:48:28.470 --> 01:48:32.750
gradients. Save total limit 2. So total like a 2 max to max

01:48:32.750 --> 01:48:36.250
model you can try to save. Report to none. No need to do

01:48:36.250 --> 01:48:40.310
that. Remove unused column false. So this is a training

01:48:40.310 --> 01:48:43.450
parameter and accordingly you can try to adjust your

01:48:43.450 --> 01:48:47.270
parameter. If your epoch will be more if your batch size

01:48:47.270 --> 01:48:49.910
will be more so obviously it is going to affect your memory

01:48:49.910 --> 01:48:52.770
and the training time. And accordingly you need a hardware

01:48:52.770 --> 01:48:56.730
scale right and I think we all understand that right in

01:48:56.730 --> 01:48:59.870
every deep learning concept so we keep on like talking about

01:48:59.870 --> 01:49:03.370
this Adam optimizers by the way our loss functions our

01:49:03.370 --> 01:49:06.350
learning rate each and everything. So these are just a

01:49:06.350 --> 01:49:09.370
training parameter right training parameter we are trying to

01:49:09.370 --> 01:49:13.050
set over here. Then these are the generic training

01:49:13.050 --> 01:49:16.850
parameter. Then coming to the next part as we are doing a

01:49:16.850 --> 01:49:20.630
DPO right. So system is supposed to understand. Understand

01:49:20.630 --> 01:49:24.490
that we are doing a DPO. Now for DPO we have a library by

01:49:24.490 --> 01:49:27.670
the way right. We have a library over here called as DPO

01:49:27.670 --> 01:49:31.370
trainer and with the help of this library only you will be

01:49:31.370 --> 01:49:36.530
able to say that okay I am like you know like basically

01:49:36.530 --> 01:49:39.730
doing a DPO kind of a training a direct preference

01:49:39.730 --> 01:49:42.350
optimization kind of a training which is nothing but a

01:49:42.350 --> 01:49:46.490
transformer right transformer for doing a reinforcement

01:49:46.490 --> 01:49:50.730
learning. So with the help of this library. You will be able

01:49:50.730 --> 01:49:54.450
to like say so for DPO you have to set certain parameter

01:49:54.450 --> 01:49:57.250
because these parameters are just a generic one right. It

01:49:57.250 --> 01:50:01.510
goes with everyone. So if I am doing a DPO so I have to call

01:50:01.510 --> 01:50:04.230
a DPO trainer model whatever model you are going to give

01:50:04.230 --> 01:50:07.130
reference model. So you have to give argument. So all the

01:50:07.130 --> 01:50:10.590
training argument means this entire things will go inside

01:50:10.590 --> 01:50:14.350
this argument part right. Training data set. So data set

01:50:14.350 --> 01:50:17.390
directory. So whatever data set directory that you have like

01:50:17.390 --> 01:50:21.170
a given. So you have to like load. Use this load function it

01:50:21.170 --> 01:50:24.990
will return the data set in which format in this format.

01:50:25.190 --> 01:50:27.270
Then only DPO will understand that okay fine this is the

01:50:27.270 --> 01:50:29.650
data this is the format. So here we are trying to give a

01:50:29.650 --> 01:50:33.790
input to a DPO that okay load it and then give the data set

01:50:33.790 --> 01:50:37.230
tokenizer. So again we are trying to like call our tokenizer

01:50:37.230 --> 01:50:41.570
over here use tokenizer so that it will my entire data set

01:50:41.570 --> 01:50:45.090
will be converted into a tokens numeric value because

01:50:45.090 --> 01:50:48.370
without system will not be I am giving input in a English

01:50:48.370 --> 01:50:51.390
language right. But system will understand what system will

01:50:51.390 --> 01:50:54.970
understand technically a numeric value. So this is what we

01:50:54.970 --> 01:51:00.010
are trying to set their tokenizer beta beta is just a KL

01:51:00.010 --> 01:51:02.930
divergence value we are trying to give maximum prompt length

01:51:02.930 --> 01:51:07.930
is 26 maximum length is 512 means maximum input length is

01:51:07.930 --> 01:51:10.570
this maximum length as an output will be this something like

01:51:10.570 --> 01:51:15.570
that we are trying to set it over here as my DPO parameter.

01:51:16.290 --> 01:51:23.670
Yeah. So. So like this is and if my prompt and if my like

01:51:23.670 --> 01:51:27.510
output is greater than this it will try to truncate it yeah

01:51:27.510 --> 01:51:30.490
and both is mentioned both is mentioned inside my data set

01:51:30.490 --> 01:51:33.110
itself that this is the input this is the output right and

01:51:33.110 --> 01:51:36.410
then the counter one. So if something will be more than that

01:51:36.410 --> 01:51:39.930
chop off yeah chop off simply. So this is basically like a

01:51:39.930 --> 01:51:42.650
total length I am trying to set that okay fine so you will

01:51:42.650 --> 01:51:45.410
be able to take input as this much and output as this much

01:51:45.410 --> 01:51:48.910
you will be able to take. Okay. Again that depends upon the

01:51:48.910 --> 01:51:52.930
model so if model like can understand the longer context you

01:51:52.930 --> 01:51:55.750
can try to give a longer one that is okay with all of us.

01:51:56.510 --> 01:52:00.730
Now this is the main part where it is digesting everything

01:52:00.730 --> 01:52:05.510
my model my like all the parameters my data set my tokenizer

01:52:05.510 --> 01:52:08.810
my maximum like output length input length with the help of

01:52:08.810 --> 01:52:13.470
this DPO trainer after that nothing to do just call DPO dot

01:52:13.470 --> 01:52:16.550
trainer simple I am just trying to print all of these things

01:52:16.550 --> 01:52:19.130
all the parameter. Right but yeah nothing to do you just

01:52:19.130 --> 01:52:23.090
have to call a DPO dot trainer it will start a training once

01:52:23.090 --> 01:52:26.910
training will be done and even during a training right. So

01:52:26.910 --> 01:52:29.830
here you can try to define your output directory so where it

01:52:29.830 --> 01:52:33.630
is saving the model as simple as that and return the output

01:52:33.630 --> 01:52:37.910
directory. Is it making sense to all of us guys. So this is

01:52:37.910 --> 01:52:39.390
what our function is trying to do.

01:52:45.770 --> 01:52:49.230
Yes reference model is nothing but a frozen model the model

01:52:49.230 --> 01:52:52.190
which we are not like a changing. This is what it means

01:52:52.190 --> 01:52:56.870
means the original download of the model that is called as a

01:52:56.870 --> 01:53:01.750
reference model yeah fine. So I think code wise it is not a

01:53:01.750 --> 01:53:05.570
big deal right code wise I do not think that it is a big

01:53:05.570 --> 01:53:08.390
deal for anyone of us to understand yeah we are just setting

01:53:08.390 --> 01:53:10.830
up the parameter loading the same data and then converting

01:53:10.830 --> 01:53:14.150
the data into the format which is required by the model and

01:53:14.150 --> 01:53:18.330
then like you know we are trying to set the parameter right

01:53:18.330 --> 01:53:21.370
as per the training and we understand all of these parameter

01:53:21.370 --> 01:53:24.050
one by one one by one one by one I can change all of these

01:53:24.050 --> 01:53:27.230
parameter as per my need as well right and then we are just

01:53:27.230 --> 01:53:30.530
trying to like a call the training part that is it. Now let

01:53:30.530 --> 01:53:33.470
us go ahead with something different so let us suppose I am

01:53:33.470 --> 01:53:35.950
doing a full fine tuning right let us see what kind of a

01:53:35.950 --> 01:53:39.510
changes we are going to observe I am just trying to call all

01:53:39.510 --> 01:53:42.470
of these things yeah so auto tokenizer auto model for the

01:53:42.470 --> 01:53:45.150
casual LLM training argument trainer data collection all

01:53:45.150 --> 01:53:48.430
those things I am trying to import. Now data loading wise.

01:53:48.430 --> 01:53:52.170
So load a HR data set for example I am using this HR data

01:53:52.170 --> 01:53:54.590
set for this full fine tuning so where we have instruction

01:53:54.590 --> 01:53:57.170
and we have a output right instruction and output in this

01:53:57.170 --> 01:54:00.490
format my data set is available. Let us go ahead with full

01:54:00.490 --> 01:54:04.390
fine tuning right so here we are trying to access the file

01:54:04.390 --> 01:54:07.910
as you can see and then in a dictionary format same as my

01:54:07.910 --> 01:54:11.950
DPO right same as my DPO so in a dictionary format I am

01:54:11.950 --> 01:54:16.390
trying to return the data yeah so my data set can be

01:54:16.390 --> 01:54:19.670
available in any format. Not just in JSON maybe in any other

01:54:19.670 --> 01:54:22.890
formats I have to read it I have to convert it in this

01:54:22.890 --> 01:54:27.090
format return the data so I have just optimized this load HR

01:54:27.090 --> 01:54:30.830
data set function even like a little bit over here for the

01:54:30.830 --> 01:54:33.750
understanding purpose and then tokenization functions

01:54:33.750 --> 01:54:36.890
tokenization means basically like convert my data set into

01:54:36.890 --> 01:54:41.730
numeric right so return tokenizer example text truncation

01:54:41.730 --> 01:54:45.190
true maximum length is equals to 512 so if my sentence is

01:54:45.190 --> 01:54:48.470
more than that chop it off. Right padding is equal to

01:54:48.470 --> 01:54:50.890
maximum length so if my sentence is lesser than this then

01:54:50.890 --> 01:54:54.310
add 0 0 0 0 0 some padding just try to add it this is the

01:54:54.310 --> 01:54:58.670
meaning of it so tokenization function then I am trying to

01:54:58.670 --> 01:55:01.470
set the parameter so data set so HR data set you are

01:55:01.470 --> 01:55:03.830
supposed to use so wherever my data set is available model

01:55:03.830 --> 01:55:06.830
same model I am using tiny llama 1.1 billion parameter model

01:55:06.830 --> 01:55:10.010
output directory so where you have to save the model epoch

01:55:10.010 --> 01:55:13.010
batch size learning rate same thing I am trying to give in

01:55:13.010 --> 01:55:16.390
this function now let us go ahead right and try to

01:55:16.390 --> 01:55:18.830
understand so most of the parameter you will be able to find

01:55:18.830 --> 01:55:21.890
out is the same it's it's not like different over here right

01:55:21.890 --> 01:55:25.530
even model name like where I am trying to load the model

01:55:25.530 --> 01:55:28.770
right it's same kuda and all those things are again same so

01:55:28.770 --> 01:55:33.570
I have not like a changed at all you can say so tokenization

01:55:33.570 --> 01:55:36.990
and everything we are trying to do now here even trainable

01:55:36.990 --> 01:55:41.030
parameter wise nothing has changed if I wanted to change it

01:55:41.030 --> 01:55:43.610
I can change it but yeah nothing has changed over here right

01:55:43.610 --> 01:55:49.510
now. Hmm. Data collector right so we are just trying to like

01:55:49.510 --> 01:55:52.410
you know data collector for our language modeling so we are

01:55:52.410 --> 01:55:55.370
trying to call our tokenizer itself so this will collect the

01:55:55.370 --> 01:55:59.930
data and then we are trying to call a trainer inside that

01:55:59.930 --> 01:56:03.290
model training argument so whatever argument that we have

01:56:03.290 --> 01:56:07.110
set over here and then tokenized data set numeric data set

01:56:07.110 --> 01:56:09.310
and data collector so everything we are trying to pass and

01:56:09.310 --> 01:56:13.370
then trainer dot train simple this is basically a full fine

01:56:13.370 --> 01:56:16.570
tuning. Yeah. This is basically a full fine tuning. So full

01:56:16.570 --> 01:56:19.330
fine tuning means change all the weights so technically you

01:56:19.330 --> 01:56:22.070
don't have to define anything additional over here in terms

01:56:22.070 --> 01:56:25.330
of full fine tuning. Now let's try to understand this LoRa

01:56:25.330 --> 01:56:29.470
fine tuning by the way because LoRa is nothing but adding a

01:56:29.470 --> 01:56:32.170
parallel layer right and then we are trying to do some sort

01:56:32.170 --> 01:56:35.110
of a training over here so here LoRa fine tuning I will be

01:56:35.110 --> 01:56:38.410
doing with respect to a healthcare data set data format is

01:56:38.410 --> 01:56:42.350
same data set dot dictionary right so data format is like

01:56:42.350 --> 01:56:46.150
going to be same. Here you will be able to see that I am

01:56:46.150 --> 01:56:49.950
loading one library a pfet library right parameter efficient

01:56:49.950 --> 01:56:53.590
fine tuning because LoRa Cora will be a part of pfet itself

01:56:53.590 --> 01:56:58.570
right. So get pfet model LoRa configuration task type this

01:56:58.570 --> 01:57:01.770
is going to help me out in terms of taking a decision that

01:57:01.770 --> 01:57:05.670
okay go ahead with the pfet go ahead with inside a pfet go

01:57:05.670 --> 01:57:08.070
ahead with the LoRa go ahead with the Cora full fine tuning

01:57:08.070 --> 01:57:12.250
means not required right follow the regular approach. DPO

01:57:12.250 --> 01:57:15.450
means DPO trainer. I have to use right so that library is

01:57:15.450 --> 01:57:19.090
also already available. Now here you will be able to find

01:57:19.090 --> 01:57:23.370
out that all those things are same tokenizer is same load

01:57:23.370 --> 01:57:28.050
help load data set is same this function right. So here

01:57:28.050 --> 01:57:31.470
loading a data set same model model I'm not I have not

01:57:31.470 --> 01:57:34.230
changed I'm defining a directory so where I have to like you

01:57:34.230 --> 01:57:39.350
know store this one epoch I can make it up and down so LoRa

01:57:39.350 --> 01:57:43.910
R configuration and LoRa alpha. So these are two parameter

01:57:43.910 --> 01:57:48.810
which is required actually for doing any kind of a LoRa

01:57:48.810 --> 01:57:54.130
training. So if these parameters are not available you will

01:57:54.130 --> 01:57:57.090
not be able to do a LoRa just for the LoRa. So basically

01:57:57.090 --> 01:58:00.750
LoRa rank so LoRa is nothing but LoRa rank and then there is

01:58:00.750 --> 01:58:03.550
something called as LoRa alpha parameter. What basically

01:58:03.550 --> 01:58:06.530
this one in a layman way if I have to explain you so this

01:58:06.530 --> 01:58:13.350
helps us out in terms of basically I told you right. So. So

01:58:13.350 --> 01:58:17.610
what by what means n cross m right up it is going to be a

01:58:17.610 --> 01:58:21.390
matrix right when I say wait it should be a matrix is so by

01:58:21.390 --> 01:58:24.890
what by what matrix is what will be the matrix dimension I

01:58:24.890 --> 01:58:28.150
am supposed to pick and choose over here. That is something

01:58:28.150 --> 01:58:31.670
that we try to adjust as a parameter. So I'm saying that 16

01:58:31.670 --> 01:58:36.270
cross 32 something like that I'm trying to define I can play

01:58:36.270 --> 01:58:39.570
with this parameter. It's completely under my control. So

01:58:39.570 --> 01:58:42.550
basically this is a decision making parameter for you. How

01:58:42.550 --> 01:58:44.130
is a parallel network the parallel network that you are

01:58:44.130 --> 01:58:46.530
trying to add so you can try to add a big one you can try to

01:58:46.530 --> 01:58:51.230
add a small one because as per that this and this is where I

01:58:51.230 --> 01:58:53.370
told you that sometime I'll try to explain you the

01:58:53.370 --> 01:58:55.710
mathematics behind it so that you will be able to understand

01:58:55.710 --> 01:58:59.830
this actual matrix like a size calculation. It's a small

01:58:59.830 --> 01:59:02.870
mathematics maybe next class I'll try to or maybe you can

01:59:02.870 --> 01:59:05.150
watch my previous lecture from my previous generative y

01:59:05.150 --> 01:59:08.370
series I have already explained that part as well. So

01:59:08.370 --> 01:59:13.290
training a parameter. Now here. So here tokenization is

01:59:13.290 --> 01:59:16.370
same, not changing anything, model is same, not changing

01:59:16.370 --> 01:59:20.490
anything this one. Now here, so basically we are talking

01:59:20.490 --> 01:59:27.030
about a LoRa configuration. So here we are talking about the

01:59:27.030 --> 01:59:31.390
LoRa configuration, so task type casual LLM, R basically

01:59:31.390 --> 01:59:35.110
rank is nothing but a LoRa, then we are trying to like set a

01:59:35.110 --> 01:59:38.390
LoRa alpha, LoRa dropout ratio, so when it will try to do a

01:59:38.390 --> 01:59:40.710
backup propagation means the small network what it will

01:59:40.710 --> 01:59:45.230
train, so we always try to adopt a dropouts, so that you

01:59:45.230 --> 01:59:49.610
know just try to make zero or make it silent some of the

01:59:49.610 --> 01:59:52.730
weights, so that it will be able to learn in a better way.

01:59:53.310 --> 01:59:57.990
Target module is basically a Q LoRa and then like a V LoRa

01:59:57.990 --> 02:00:04.530
and then like a P LoRa. So basically here target module name

02:00:04.530 --> 02:00:07.970
that we are trying to give over here. So basically it should

02:00:07.970 --> 02:00:12.250
match with my base model, right. So if I am using a LLM

02:00:12.250 --> 02:00:16.170
model, if I am using a TLM model basically, so it depends

02:00:16.170 --> 02:00:19.430
upon what kind of architecture, the base architecture we are

02:00:19.430 --> 02:00:23.870
using. So if you go and check, it is basically my LLM

02:00:23.870 --> 02:00:27.210
series, so tiny LLM is something that we are trying to use

02:00:27.210 --> 02:00:31.530
over here. So these are the target modules which is like

02:00:31.530 --> 02:00:35.990
aligned with my base models and again you can try to like do

02:00:35.990 --> 02:00:38.610
a search. That okay, if this is my target model, then what

02:00:38.610 --> 02:00:43.130
should be my target modules for this model in terms of a

02:00:43.130 --> 02:00:50.690
LoRa. Bias is none. Now if your architecture is going to

02:00:50.690 --> 02:00:53.410
change, then this name is going to differ by the way. So

02:00:53.410 --> 02:00:57.130
there is something called as WPAC, a query key value, this

02:00:57.130 --> 02:00:59.630
is something that we try to put as a target module, but as

02:00:59.630 --> 02:01:03.330
of now, so Q project, B project, K project and O project is

02:01:03.330 --> 02:01:05.690
something that we try to give. So query key and values

02:01:05.690 --> 02:01:07.710
basically, right. And then after that, we are going to

02:01:07.710 --> 02:01:10.770
change it. This is my target model, means target computation

02:01:10.770 --> 02:01:15.730
basically. Now so here we are trying to call a function get

02:01:15.730 --> 02:01:18.250
prefet module and we are trying to pass our original model

02:01:18.250 --> 02:01:21.530
and then we are trying to pass the configuration, right, a

02:01:21.530 --> 02:01:24.070
LoRa configuration, the configuration that we have done just

02:01:24.070 --> 02:01:28.750
specific to the LoRa and then we are trying to basically

02:01:29.310 --> 02:01:32.550
give a trainable parameter, this is just a calculation we

02:01:32.550 --> 02:01:36.270
are doing so that I can show you that. Okay. So how many

02:01:36.270 --> 02:01:39.410
parameters? We are actually training. So for example, I can

02:01:39.410 --> 02:01:41.550
easily find out what is the total number of parameter in

02:01:41.550 --> 02:01:45.010
this one and which I have trained already in full fine

02:01:45.010 --> 02:01:49.850
tuning, right? So here, just to show you in my like a run.

02:01:49.990 --> 02:01:53.010
So whenever, whenever, when I'm going to run it, right. So

02:01:53.010 --> 02:01:55.350
just to show you, this is not required for the training by

02:01:55.350 --> 02:01:57.990
the way. So, but just to show you that, okay, how many

02:01:57.990 --> 02:02:01.350
parameters we are actually training versus the original

02:02:01.350 --> 02:02:04.950
number of parameter means how much like we are able to save,

02:02:05.110 --> 02:02:08.890
right? A fraction. And you will be able to find out like a

02:02:08.890 --> 02:02:14.310
99% we are able to save basically. So just to like do the

02:02:14.310 --> 02:02:17.490
print, we have done this one. After that, nothing much

02:02:17.490 --> 02:02:21.470
simple, call the data set, call a same trainable parameter,

02:02:21.850 --> 02:02:25.670
which we have done, call a data collector and then call the

02:02:25.670 --> 02:02:28.510
trainer. Trainer means just try to pass model, training

02:02:28.510 --> 02:02:31.470
architecture, tokenize, data collector, and then it will try

02:02:31.470 --> 02:02:34.550
to call trainer.train as simple as that, right? Everything

02:02:34.550 --> 02:02:37.850
is connected. And then save the model. Now, this is what

02:02:37.850 --> 02:02:41.910
happens in case of a LoRa, just like DPO in case of LoRa. So

02:02:41.910 --> 02:02:46.670
I will be having one more additional configuration, right?

02:02:46.750 --> 02:02:49.510
So which will help me out in terms of adding a parallel

02:02:49.510 --> 02:02:54.390
layer to my model. Again if I'll talk about QLoRa, quantized

02:02:54.390 --> 02:02:58.070
LoRa, right? So here I'm trying to, you know, calling a PFET

02:02:58.070 --> 02:03:01.090
again from a PFET, you will be able to find out, prepare a

02:03:01.090 --> 02:03:04.290
model for k bit, any number of bit I told you, right?

02:03:04.350 --> 02:03:07.770
Quantization means what? Reducing the number of bits. So

02:03:07.770 --> 02:03:11.490
here I will be having a control that, okay, I can reduce it

02:03:11.490 --> 02:03:15.530
to a specific bit, maybe 32 bit to a 4 bit or maybe 8 bit or

02:03:15.530 --> 02:03:19.010
maybe to a 16 bit. And you will be able to find out again

02:03:19.010 --> 02:03:23.570
one additional parameter to maintain this one. So here load

02:03:23.570 --> 02:03:28.570
in 4 bit. I'm trying to call this like a bits and bytes

02:03:28.570 --> 02:03:32.050
configuration, right? And I'm saying that, that I am trying

02:03:32.050 --> 02:03:35.530
to create a model and that should be available in a, in a 4

02:03:35.530 --> 02:03:39.050
bit. So in a 4 quantization, I'm trying to use, I can go

02:03:39.050 --> 02:03:41.390
ahead with 8 bit as well. I can go ahead with 16 bit as

02:03:41.390 --> 02:03:43.810
well. I can go ahead with any other bits. That's like a

02:03:43.810 --> 02:03:48.690
completely okay with me, but yeah, so it's just a bit

02:03:48.690 --> 02:03:51.630
control that we have to do. So this is what we are like

02:03:51.630 --> 02:03:55.650
trying to do over here in terms of configuration. And on top

02:03:55.650 --> 02:03:59.390
of that, we are trying to call a LoRa because when I taught

02:03:59.390 --> 02:04:03.650
you, uh, like a Quora. So what I have written? It's a

02:04:03.650 --> 02:04:07.930
quantized LoRa. So LoRa configuration will be there and plus

02:04:07.930 --> 02:04:10.130
quantization configuration will be there. So quantization

02:04:10.130 --> 02:04:14.710
configuration for a bit basically. So convert 32 or any bit

02:04:14.710 --> 02:04:18.710
into 4 bits and then for a big model and then there will be

02:04:18.710 --> 02:04:22.990
a parallel layer. Parallel layer means to understand my data

02:04:22.990 --> 02:04:26.330
set. So this model will be reduced in the size and then

02:04:26.330 --> 02:04:29.170
there will be a parallel architecture which I'm going to

02:04:29.170 --> 02:04:32.290
train with my own, my own data set so that it will be able

02:04:32.290 --> 02:04:34.970
to balance the generalized and the specific data set. All

02:04:34.970 --> 02:04:40.670
together. Uh, this is what, uh, we are like, uh, trying to

02:04:40.670 --> 02:04:44.870
do over here, right? This is what it is trying to do over

02:04:44.870 --> 02:04:48.770
here. Uh, nothing much in terms of, you know, like output

02:04:48.770 --> 02:04:55.790
I'm trying to change, uh, by the way. Uh, so yeah, so this

02:04:55.790 --> 02:04:59.410
is like, so code wise, all this four or five code, which I

02:04:59.410 --> 02:05:02.590
have written. So it's actually same as per the

02:05:02.590 --> 02:05:05.910
specification. We are just trying to. To add a layer, that's

02:05:05.910 --> 02:05:09.490
it. A modular layer I have added and I have also kept it in

02:05:09.490 --> 02:05:12.330
such a way that you all will be able to understand any time,

02:05:12.390 --> 02:05:14.410
maybe even after two year, three year, you will be able to

02:05:14.410 --> 02:05:17.190
understand it. So no class and object kind of approach I

02:05:17.190 --> 02:05:19.570
have used over here because that makes a code unnecessarily

02:05:19.570 --> 02:05:22.750
complex. I have just used a variable declaration and you

02:05:22.750 --> 02:05:25.590
know, a functional approach so that, you know, things will

02:05:25.590 --> 02:05:29.310
be pretty much modelize, uh, separate and you can call

02:05:29.310 --> 02:05:33.290
anything into anything. Uh, more. I will be talking about it

02:05:33.290 --> 02:05:36.010
in depth and detail. In my next class, which is going to be

02:05:36.010 --> 02:05:40.130
on a Saturday, but, uh, just now quickly, I will run it

02:05:40.130 --> 02:05:43.450
right quickly. I will run it because I have already trained

02:05:43.450 --> 02:05:45.990
the, my model study itself. So my model is available

02:05:45.990 --> 02:05:48.470
everywhere. You will see, I have a checkpointing, right? I

02:05:48.470 --> 02:05:51.610
have a checkpoints, which is available, uh, if you are going

02:05:51.610 --> 02:05:53.830
to train the model. So again, it will take a time for you.

02:05:53.910 --> 02:05:56.790
Uh, I'll, I'll share the code base, just delete the entire

02:05:56.790 --> 02:05:59.810
model, uh, available file, and then you can try to train it.

02:06:00.110 --> 02:06:02.350
I'll just show you the testing part by the way, because that

02:06:02.350 --> 02:06:05.090
is going to be interesting. Yeah. That is going to be the

02:06:05.090 --> 02:06:12.030
interesting one. So here for a testing, I have a module I

02:06:12.030 --> 02:06:15.230
have created where I'm passing all different, different kind

02:06:15.230 --> 02:06:18.750
of, uh, queries, HR queries, finance queries, okay, sales

02:06:18.750 --> 02:06:25.250
queries, fine. So here what I will do, so I'll try to write,

02:06:25.290 --> 02:06:31.190
uh, Python, it's not API. I don't know how to, I don't want

02:06:31.190 --> 02:06:35.050
to do API testing for now. I've even converted that as an

02:06:35.050 --> 02:06:39.910
API. So I just wanted to do a testing today. Just try to

02:06:39.910 --> 02:06:43.890
learn and observe, don't do anything. So test model, test,

02:06:43.970 --> 02:06:46.790
test, not API, test

02:06:49.740 --> 02:06:56.540
model dot PI. Yeah. So let's do a testing of this, like a

02:06:56.540 --> 02:06:58.080
model basically.

02:07:01.360 --> 02:07:05.780
So here, see, I am as a query. So testing means what I'm

02:07:05.780 --> 02:07:07.960
trying to do up a testing of different, different models. So

02:07:07.960 --> 02:07:10.320
full fine tuning model, it is able to select, right. It is

02:07:10.320 --> 02:07:13.840
loading a model from my HR, uh, like a model directory. And

02:07:13.840 --> 02:07:17.320
then it is asking a query. How do I apply for a casual

02:07:17.320 --> 02:07:21.120
leave? That that was my question, right. And somewhere I

02:07:21.120 --> 02:07:24.740
have already trained on this particular question. So there

02:07:24.740 --> 02:07:29.180
must be some answer and answer should come from my data and

02:07:29.180 --> 02:07:31.920
that too in a proper formatted way, which anyone can

02:07:31.920 --> 02:07:36.060
understand, right? So let's see. It is taking time because

02:07:36.060 --> 02:07:38.360
I'm doing a inferencing in my data. This is my local system.

02:07:38.560 --> 02:07:43.980
And if you will see my, uh, let me show you my, yeah,

02:07:46.210 --> 02:07:50.530
uh, so here, how do I apply for a casual leave responses to

02:07:50.530 --> 02:07:53.450
avail a casual leave? You need to present, uh, your leave

02:07:53.450 --> 02:07:57.650
application from form 19. Now form number 19, it's not a

02:07:57.650 --> 02:08:02.070
generic data. It's coming from where my data, right? Because

02:08:02.070 --> 02:08:04.430
if you'll go and ask your chat GPT, they will not give you a

02:08:04.430 --> 02:08:07.270
form number 19. What is for number 19? Right? Basically it's

02:08:07.270 --> 02:08:09.670
all my company's policy. So formula. Form number 19 is my

02:08:09.670 --> 02:08:13.090
company's data. At time of reporting to the work, you will

02:08:13.090 --> 02:08:16.110
guarantee up to six days of leave per month. Leave must be

02:08:16.110 --> 02:08:20.010
taken on a pre-booked basis and not on a casual basis. Leave

02:08:20.010 --> 02:08:22.970
will be paid at the rate of 50% of your regular pay. All

02:08:22.970 --> 02:08:27.150
this like, you know, and this output looks great to me. It

02:08:27.150 --> 02:08:29.210
literally looks amazing to me. Yes, everyone.

02:08:33.140 --> 02:08:38.320
Yeah. It actually looks great, right? I have taken like a

02:08:38.320 --> 02:08:41.620
small data, not very small. I have a sizeable data. I can

02:08:41.620 --> 02:08:45.060
say. Sizeable number of record. I have just trained it for

02:08:45.060 --> 02:08:47.440
two, three epochs, not more than that, because if you'll see

02:08:47.440 --> 02:08:49.580
my parameter, trainable parameter, which I have shown you

02:08:49.580 --> 02:08:51.700
somewhere, I'm keeping five epochs, somewhere I'm keeping

02:08:51.700 --> 02:08:55.120
three epochs, somewhere I'm keeping four epochs, right? As

02:08:55.120 --> 02:08:57.740
per the, you know, training and accuracy that it has given

02:08:57.740 --> 02:08:59.780
to me. So I have like, you know, modified that part

02:08:59.780 --> 02:09:02.940
basically. And yeah, it's, it's just in two, three epochs.

02:09:03.060 --> 02:09:05.220
If I'm going to train it for a hundred epochs, maybe on more

02:09:05.220 --> 02:09:08.500
data set, maybe it will be like, it will work better than

02:09:08.500 --> 02:09:11.440
this. But yeah, even with this epoch, it's, it's behaving

02:09:11.440 --> 02:09:11.920
like a, you know, it's behaving like, it's behaving like a

02:09:11.920 --> 02:09:14.500
good, and yeah, it is, it is able to give me like a very

02:09:14.500 --> 02:09:18.300
good response. Inferencing is slow because it is going to my

02:09:18.300 --> 02:09:20.760
model and then, you know, it is, it is trying to do the

02:09:20.760 --> 02:09:23.620
inferencing here. I'm trying to like test some preferred

02:09:23.620 --> 02:09:25.360
model. Yeah.

02:09:31.740 --> 02:09:35.440
So if you'll go and check my task manager as of now, so my

02:09:35.440 --> 02:09:37.340
CPU, my

02:09:39.420 --> 02:09:43.080
entire compute is going very, very high as you can see. So

02:09:43.080 --> 02:09:47.500
my CPU is like 57%, my memory is 43%, I'm doing an

02:09:47.500 --> 02:09:52.740
inferencing, right? So just see how my CPU is behaving. It's

02:09:52.740 --> 02:09:57.600
like fully occupied. Yeah. It's, it's fully occupied. My

02:09:57.600 --> 02:10:01.680
CUDA number one. So almost like 14%, 15% it's running on

02:10:01.680 --> 02:10:04.900
that GPU number one, GPU number zero. So yeah, it is able to

02:10:04.900 --> 02:10:07.880
use something, but if I'll talk about my memory, so my

02:10:07.880 --> 02:10:12.500
memory is high. My CPUs are like super high, right? All my

02:10:12.500 --> 02:10:16.140
like a core is like a, you know, and processors, logical

02:10:16.140 --> 02:10:19.300
processes are super, super high as of now because

02:10:19.300 --> 02:10:24.320
inferencing is a tough task is still doing inferencing. I

02:10:24.320 --> 02:10:26.540
have written so many queries. If you look into my test model

02:10:26.540 --> 02:10:29.320
queries, right, I have given all the queries with respect to

02:10:29.320 --> 02:10:32.960
all the model and with every model, you will be able to find

02:10:32.960 --> 02:10:35.480
out that it's, it's behaving in a beautiful manner, right?

02:10:35.680 --> 02:10:39.000
How to handle a delivery delay complaints, right? So thank

02:10:39.000 --> 02:10:41.440
you for your feedback. Uh, we understand the inconvenience

02:10:41.440 --> 02:10:44.400
you are facing and apology for a delay. We are working on

02:10:44.400 --> 02:10:46.620
resolving the issues, providing a solution. Please provide

02:10:46.620 --> 02:10:48.880
your audience. What a detail. So whenever someone is like

02:10:48.880 --> 02:10:53.060
saying that, that, so as per like, you know, my, uh, you

02:10:53.060 --> 02:10:57.820
know, uh, data, it is behaving very good. It was good,

02:10:57.920 --> 02:11:00.640
right? It is, it is able to give me an answer and yeah, all

02:11:00.640 --> 02:11:03.520
this answers are actually with respect to my data because if

02:11:03.520 --> 02:11:05.900
you'll read out this answer, it's not a generic one. It's

02:11:05.900 --> 02:11:09.080
not a chat GPT's answer or put it in LLM answer. You will be

02:11:09.080 --> 02:11:11.120
able to find out, you will be able to find out same answer

02:11:11.120 --> 02:11:16.780
in your data set. Yeah. So Laura model, Cora model. What is

02:11:16.780 --> 02:11:19.140
this? So Laura model. So basically Laura model is trained on

02:11:19.140 --> 02:11:22.040
healthcare data. So what is the symptom for the dengue

02:11:22.040 --> 02:11:25.560
fever? So can vary, but uh, include fevers, severe headache,

02:11:25.780 --> 02:11:31.700
muscle pain, joint pain, vomiting and rashes. Yup. So

02:11:31.700 --> 02:11:36.480
performance of my model is actually like a great, yeah. And

02:11:36.480 --> 02:11:40.580
uh, explain the EMI option for a laptop purchase. Now this,

02:11:40.580 --> 02:11:45.800
this data is actually coming from where my data set 2.99% of

02:11:45.800 --> 02:11:47.020
like a, you know, EMI.

02:11:51.440 --> 02:11:57.020
So I'm able to train, uh, in my local system, like, uh, a

02:11:57.020 --> 02:12:01.740
good model, by the way, which, which I can actually use, uh,

02:12:01.800 --> 02:12:06.360
for my, like, you know, real time purposes. Right. Everyone.

02:12:07.340 --> 02:12:11.360
Yeah. I'm just trying to show you the output, the

02:12:11.360 --> 02:12:17.860
authenticity of the output. Yes. And then what I have to do,

02:12:17.920 --> 02:12:20.880
I have to, you know, test this model here in local or maybe

02:12:20.880 --> 02:12:23.160
wherever I'm training it. And then I have to migrate this

02:12:23.160 --> 02:12:27.600
model on a final server because here, uh, I have a limited

02:12:27.600 --> 02:12:31.180
compute. So inferencing is taking a lot of time. Uh, maybe I

02:12:31.180 --> 02:12:35.100
can try to, you know, Cora output will be quick. So Qlaura

02:12:35.100 --> 02:12:38.440
output will be quick, uh, this time. And again, so you will

02:12:38.440 --> 02:12:41.760
see that my compute will be decreasing when it will call the

02:12:41.760 --> 02:12:47.680
Cora, Qlaura, quantized Laura. Right. So, uh, maybe I can

02:12:47.680 --> 02:12:49.980
try to like, uh, you know, host it on some like a higher

02:12:49.980 --> 02:12:54.660
instances, uh, GPUs. Right. And, uh, I can just like, uh,

02:12:54.720 --> 02:12:59.220
attach with any system out there. Maybe some, uh, chat

02:12:59.220 --> 02:13:02.100
system, maybe some document summarizer system, anything,

02:13:02.340 --> 02:13:04.940
anything, WhatsApp, telegram, whatever I want, I can try to

02:13:04.940 --> 02:13:08.680
integrate those output. Person will ask, person will get the

02:13:08.680 --> 02:13:11.620
answer. So my HR department, my sales department, marketing

02:13:11.620 --> 02:13:15.920
department, my finance department, all will be live and

02:13:15.920 --> 02:13:22.200
ready to give any kind of answer. Yeah. That we will do next

02:13:22.200 --> 02:13:27.180
week. We will bring all the model online. Online means

02:13:27.180 --> 02:13:31.040
anyone can use it in this entire world from their telegram,

02:13:31.180 --> 02:13:34.000
from their WhatsApp, maybe. Yeah. From their chat interface.

02:13:34.160 --> 02:13:36.920
And you can even use this model for any other purposes,

02:13:37.020 --> 02:13:41.020
maybe for like agentic purpose for RIG purposes. We have a

02:13:41.020 --> 02:13:43.580
LLM, right? So I can just try to. I can try to like, uh, use

02:13:43.580 --> 02:13:46.700
LLM in hundreds of other ways, not just in a chatting ways,

02:13:46.820 --> 02:13:50.040
but yeah. So we'll try to bring our entire, uh, you know,

02:13:50.060 --> 02:13:51.920
department live, all the department.

02:13:58.520 --> 02:14:01.500
If query is not in our data set, then what output will you

02:14:01.500 --> 02:14:05.280
get? Uh, it will give you some vague output, right? As per

02:14:05.280 --> 02:14:07.620
its own understanding, because anyhow it's a generation

02:14:07.620 --> 02:14:09.980
model, right? Generative model. It will generate some

02:14:09.980 --> 02:14:14.360
output. It will generate some English text. Kind of update,

02:14:14.460 --> 02:14:19.300
less learn. Kind of update, less learn more. I'm not able to

02:14:19.300 --> 02:14:24.200
get your, uh, comment to Yogi G. What if I want to answer

02:14:24.200 --> 02:14:27.240
from only the trained information, not from the default LLM

02:14:27.240 --> 02:14:33.800
trained data? Uh, then you are going to make a blunder. I'll

02:14:33.800 --> 02:14:36.360
tell you the reason why you're using a pre-trained model.

02:14:36.800 --> 02:14:40.900
See your pre-trained model is not a specific to a particular

02:14:40.900 --> 02:14:43.600
domain. It understands the meaning of a grammar. It

02:14:43.600 --> 02:14:46.640
understands the sentences. Anyhow. Anyhow you are trying to

02:14:46.640 --> 02:14:50.600
give a data in English or maybe in some languages, right? So

02:14:50.600 --> 02:14:53.780
you need a base weight, which will, which must be able to

02:14:53.780 --> 02:14:57.060
understand the grammar. So if you are not taking an output,

02:14:57.200 --> 02:15:00.580
if you're not considering your base LLMs in that case, I

02:15:00.580 --> 02:15:03.120
have already taught about like a training of vanilla model

02:15:03.120 --> 02:15:06.120
or training a model from the scratch. Just go there and the

02:15:06.120 --> 02:15:08.740
kind of a result it will give you, you will not be able to

02:15:08.740 --> 02:15:11.220
understand. It will give you a result. I'm not saying that

02:15:11.220 --> 02:15:12.800
it will not give you a result. It will give you a result in

02:15:12.800 --> 02:15:16.640
English itself. But. Grammar and all those things will be

02:15:16.640 --> 02:15:20.560
like missing grammar relation context. Everything will be

02:15:20.560 --> 02:15:22.880
missing. Right? So we need a LLM model. We need a base

02:15:22.880 --> 02:15:23.060
model.

02:15:26.300 --> 02:15:31.560
Yeah. Testing completed. And yes, this is a amazing answer

02:15:31.560 --> 02:15:35.000
everywhere I'm able to get from all of my models, right? So

02:15:35.000 --> 02:15:38.580
this, this entire file will be available. I'll just walk you

02:15:38.580 --> 02:15:41.140
through this entire file once again. But if you look into

02:15:41.140 --> 02:15:44.860
these files, it's not at all difficult to understand. I

02:15:44.860 --> 02:15:48.280
believe we understand the core concept. Right? And going

02:15:48.280 --> 02:15:50.840
forward, even in your company, if you are going to do a

02:15:50.840 --> 02:15:54.920
training, use it directly. No need to change anything.

02:15:56.640 --> 02:15:58.900
Right? Prepare the data. So everything is going to be

02:15:58.900 --> 02:16:02.280
actually same. Right? At least for these many kinds of fine

02:16:02.280 --> 02:16:06.520
tuning, which I am teaching you. So nothing is not even

02:16:06.520 --> 02:16:08.420
maybe single line you will change, you will change some

02:16:08.420 --> 02:16:11.980
parameters. That's it. Right? And if you're doing a training

02:16:11.980 --> 02:16:15.260
in local, local on cloud, on cloud, everything is fine.

02:16:16.440 --> 02:16:19.420
Yeah. What is a frozen model? Frozen model is the original

02:16:19.420 --> 02:16:21.440
model, the model that we are downloading from Hugging Face

02:16:21.440 --> 02:16:24.660
library. Right? We have given a model name. Right? That's

02:16:24.660 --> 02:16:29.280
my, that's my frozen model. This one. Yeah.

02:16:34.900 --> 02:16:37.120
What needs to be done if you want to get an answer on a

02:16:37.120 --> 02:16:39.920
different language? So basically you have to pick and choose

02:16:39.920 --> 02:16:42.900
that kind of a model, which has been trained on that many

02:16:42.900 --> 02:16:47.080
languages. Yeah. And then even you have to give your data

02:16:47.080 --> 02:16:49.420
set in that many languages.

02:16:52.300 --> 02:16:56.160
How can we use two or more model as a base model for a fine

02:16:56.160 --> 02:16:58.660
tuning or only one? As of now, only one.

02:17:02.580 --> 02:17:09.440
Yeah. Okay. So this is it from my side. Just try to digest,

02:17:09.620 --> 02:17:12.520
just try to, you know, go through this one. Believe me, you

02:17:12.520 --> 02:17:16.620
will enjoy, you will enjoy this entire like a code base as

02:17:16.620 --> 02:17:19.000
well as like this entire application that we are trying to

02:17:19.000 --> 02:17:21.920
create. Don't try to understand any other files. I'll give

02:17:21.920 --> 02:17:24.120
you the explanation. Yeah. I'll give you the explanation.

02:17:24.260 --> 02:17:26.060
Most of the file I created it for the testing purposes

02:17:26.060 --> 02:17:28.780
because I was getting like a lot of issues. I have fixed all

02:17:28.780 --> 02:17:32.480
of those issues. Plus I have even like a created an API.

02:17:33.260 --> 02:17:36.200
Plus I have even created like a something where I can host

02:17:36.200 --> 02:17:40.060
the entire things on H100 and then do inferencing. That I'll

02:17:40.060 --> 02:17:42.640
show you in a practical manner, everything, even training,

02:17:42.760 --> 02:17:45.640
I'll show you in a practical manner. I'll just copy the

02:17:45.640 --> 02:17:47.980
entire instance in some other directory and then I'll show

02:17:47.980 --> 02:17:49.700
you the training because training itself will take you like

02:17:49.700 --> 02:17:53.680
a one, one and a half hour. Yeah. So it will, because we are

02:17:53.680 --> 02:17:56.200
training five to six models over here, not just like one

02:17:56.200 --> 02:18:00.620
single model we are trying to train. Even we are training

02:18:00.620 --> 02:18:04.900
for two, three epoch. Any security breach in a company, if

02:18:04.900 --> 02:18:07.980
we use this code base model, what will be the security? I

02:18:07.980 --> 02:18:10.980
mean like look into the code, why are you even asking this

02:18:10.980 --> 02:18:15.720
question? Whenever I discuss something, right? So people

02:18:15.720 --> 02:18:19.400
nowadays, I can see like people ask a couple of questions.

02:18:19.400 --> 02:18:23.020
Very quickly, like security, how safe it is. And then like a

02:18:23.020 --> 02:18:25.720
scale. I mean like look into the code, what is the security

02:18:25.720 --> 02:18:28.320
breach? Everything is happening in your local system, like

02:18:28.320 --> 02:18:30.620
you're just downloading the model. Data is yours. Instance

02:18:30.620 --> 02:18:33.840
is yours. Now what will be the security breach? These

02:18:33.840 --> 02:18:36.520
questions are just a dummy, dumb question I would say.

02:18:40.660 --> 02:18:42.940
So please share the code base URL if any of you have already

02:18:42.940 --> 02:18:45.920
shared. No, I have not shared this one. I'll just upload it

02:18:45.920 --> 02:18:48.060
inside your dashboard. So once I'll upload the recording and

02:18:48.060 --> 02:18:51.300
then you guys can go through it. Take your time. Take your

02:18:51.300 --> 02:18:54.640
time. Digest it. But yeah, don't try to understand all the

02:18:54.640 --> 02:18:56.980
other files. Other files, I'll try to explain it to you.

02:18:57.120 --> 02:18:59.760
Yeah. A lot of file are testing file. I'll just delete these

02:18:59.760 --> 02:19:02.260
files. Testing files are not required. Not all the testing

02:19:02.260 --> 02:19:06.440
files are required. Just a couple of them. And then like

02:19:06.440 --> 02:19:09.860
even I was trying to deploy these things in two to three

02:19:09.860 --> 02:19:12.200
ways. One is a Docker approach. One is a Kubernetes

02:19:12.200 --> 02:19:15.500
approach. I'll try to show you Docker approach by the way.

02:19:15.560 --> 02:19:18.240
Even I can show you Kubernetes approach, just a command in

02:19:18.240 --> 02:19:20.940
terms of like, you know, doing a deployment on single

02:19:20.940 --> 02:19:24.380
instances. Or in a multiple instances and exposing your

02:19:24.380 --> 02:19:25.900
model to the entire world.

02:19:29.840 --> 02:19:32.560
How we can integrate model in our chart UI that we will see

02:19:32.560 --> 02:19:36.080
next class. Not now. Yeah. That I'll teach you in upcoming

02:19:36.080 --> 02:19:41.620
classes. Once we'll deploy this model on some cloud platform

02:19:41.620 --> 02:19:47.260
and make our model live. As of now, it's only working in my

02:19:47.260 --> 02:19:51.320
machine. So we can't make it live. Yeah. ng-roc is one of

02:19:51.320 --> 02:19:56.040
the option which we have, but that is not a final option. So

02:19:56.040 --> 02:19:59.120
we'll deploy our model. With the help of Docker or

02:19:59.120 --> 02:20:04.560
Kubernetes and then like expose it via APIs. And if

02:20:04.560 --> 02:20:08.860
something is available as an API, I can try to just call the

02:20:08.860 --> 02:20:12.480
API in WhatsApp, in Telegram, in my URI kind of a chat

02:20:12.480 --> 02:20:18.500
system and bingo. So next class, what we will see that we

02:20:18.500 --> 02:20:24.240
are trying to make all our departments live. Simple. All the

02:20:24.240 --> 02:20:28.080
department will be live to the world. So. So this is it guys

02:20:28.080 --> 02:20:30.620
from my side. If you have any kind of a question, raise your

02:20:30.620 --> 02:20:33.740
hand, I'll try to unmute you. And then you can like, you

02:20:33.740 --> 02:20:35.920
know, go ahead with your question. Just just raise your

02:20:35.920 --> 02:20:39.280
hand. Yeah. And hope all of you have enjoyed today's class.

02:20:39.460 --> 02:20:42.200
Yeah. You all are able to understand a little bit at least

02:20:42.200 --> 02:20:48.500
with respect to like, you know, fine tuning today's class

02:20:48.500 --> 02:20:52.040
was complex. Is it? I mean, like in last half an hour, I

02:20:52.040 --> 02:20:54.460
have talked about a code before that I was just talking

02:20:54.460 --> 02:21:00.880
about a theory. Like. Yeah. I know Okay. The.

02:21:20.740 --> 02:21:24.980
Only thing is in terms of giving our data set. So in case of

02:21:24.980 --> 02:21:27.400
full fine tuning, so what we say, we say that it's as a .

02:21:27.400 --> 02:21:30.860
and this is the output. In terms of DPO, so we are trying to

02:21:30.860 --> 02:21:34.460
just change a learning approach a little bit, learning

02:21:34.460 --> 02:21:37.180
approach. So where we say that, that, okay, this is that

02:21:37.180 --> 02:21:40.220
data, this is the input instruction prompt. You can say,

02:21:40.280 --> 02:21:43.880
right, this is the output. But when you are trying to

02:21:43.880 --> 02:21:47.600
generate this output, also try not to generate the other

02:21:47.600 --> 02:21:52.320
one. Yeah. So rejected one basically. So try to always

02:21:52.320 --> 02:21:55.200
select the chosen one. So basically it's a reinforcement. So

02:21:55.200 --> 02:21:59.080
it's just a way of like a approach of changing the training

02:21:59.080 --> 02:22:03.900
process. That's it. Nothing much. Oh, I think, sir, uh, just

02:22:03.900 --> 02:22:07.100
tried, uh, I've gone through all these things. So all the

02:22:07.100 --> 02:22:11.400
things is depends on totally on the data preparation, right?

02:22:11.920 --> 02:22:15.640
And like a data preparation, then a model selection, you

02:22:15.640 --> 02:22:18.220
have to like, it depends then kind of a training that you

02:22:18.220 --> 02:22:21.640
are doing it. Because again, when I say data preparation, so

02:22:21.640 --> 02:22:24.240
my data preparation will be different for DPO. My data

02:22:24.240 --> 02:22:26.560
preparation will be different for like a full fine tuning,

02:22:26.680 --> 02:22:31.400
right? So data preparation is one thing. And then my like a

02:22:31.400 --> 02:22:34.180
model selection, then obviously my hardware selection type

02:22:34.180 --> 02:22:36.520
of the training that is a reason. So I have mentioned

02:22:36.520 --> 02:22:42.070
clearly over here, this flow, but what does it mean by model

02:22:42.070 --> 02:22:45.970
selection? It means, I mean, uh, if we have a, uh, what is

02:22:45.970 --> 02:22:49.510
your, what is your base model? Yes. But all the base model

02:22:49.510 --> 02:22:53.250
is, I think, uh, uh, you told earlier as well that, uh, all

02:22:53.250 --> 02:22:58.370
the models. Uh, respond the correct one. If you are trained

02:22:58.370 --> 02:23:02.030
correctly, right? No, no base model means what is a pre

02:23:02.030 --> 02:23:04.150
-trained weight you are trying to take. So whether you are

02:23:04.150 --> 02:23:07.350
trying to take a chat GPT based 120 billion parameter model

02:23:07.350 --> 02:23:10.150
or 20 billion parameter model, Lama model, Mr. Model, deep

02:23:10.150 --> 02:23:13.710
seek model, which model basically that is something which

02:23:13.710 --> 02:23:16.110
has been labeled as a base model, right? So if you will look

02:23:16.110 --> 02:23:18.530
into my code base, which I have explained to you, so if you

02:23:18.530 --> 02:23:20.890
will go and check, what is the base model, which I'm using

02:23:20.890 --> 02:23:25.310
over here? So I'm technically using. Uh, Lama tiny Lama

02:23:25.310 --> 02:23:29.890
cities, this base model, right? So this is already a pre

02:23:29.890 --> 02:23:32.350
-trained model. I'm downloading it from a hugging phase, and

02:23:32.350 --> 02:23:34.650
then I'm trying to use it in my, like a fine tuning

02:23:34.650 --> 02:23:38.810
approach. So this base model also matters a lot. If your

02:23:38.810 --> 02:23:41.490
base model is maybe GPT OSS 120 billion parameter model,

02:23:41.710 --> 02:23:45.470
it's a big one. My entire system will crash. I'll not be

02:23:45.470 --> 02:23:48.430
able to train 120 billion parameter model, uh, in my local

02:23:48.430 --> 02:23:51.710
system at least not even with the H one single H one. I need

02:23:51.710 --> 02:23:54.950
like three to four. H one. So it depends upon my base model

02:23:54.950 --> 02:24:00.310
as well. So how, how we can, how we can, uh, I mean, uh,

02:24:00.470 --> 02:24:03.490
give the instruction to our organization that we need, uh,

02:24:03.490 --> 02:24:06.810
this type of, uh, this type of, uh, system, uh,

02:24:06.930 --> 02:24:11.550
configuration for, uh, doing our, the model. Yeah. So

02:24:11.550 --> 02:24:13.910
basically if you, if you have selected a big base model,

02:24:14.070 --> 02:24:16.870
right. If, if you have selected a base model, so obviously

02:24:16.870 --> 02:24:19.610
you must be aware about the parameter. For example, when I

02:24:19.610 --> 02:24:23.610
say GPT OSS 120 B simply means that I need a. There is a 120

02:24:23.610 --> 02:24:27.550
billion parameter model, right? And then when I say 20 B, 20

02:24:27.550 --> 02:24:29.890
billion parameter model now to train 20 billion parameter

02:24:29.890 --> 02:24:32.350
model. So I can check the specification. So maybe a

02:24:32.350 --> 02:24:35.610
specification has given that, that I need a two H 100 at

02:24:35.610 --> 02:24:39.150
least, or maybe a 100, right? So that is the specification

02:24:39.150 --> 02:24:41.890
that will be give to our client or maybe to our like a, you

02:24:41.890 --> 02:24:44.790
know, organization that, okay, just give me this like access

02:24:44.790 --> 02:24:49.130
so that I will be able to train. Hmm. I mean, uh, we need

02:24:49.130 --> 02:24:52.590
to, we need to learn those things as well. So that. There is

02:24:52.590 --> 02:24:54.770
nothing on a learning in that one. So you should always

02:24:54.770 --> 02:24:57.450
aware about it because there are like a millions of models.

02:24:57.630 --> 02:25:00.550
And then when you will like, you know, go and check over the

02:25:00.550 --> 02:25:02.930
internet instruction for every model will be given to you.

02:25:03.870 --> 02:25:07.750
Okay. But, uh, uh, if, uh, uh, we are talking about the

02:25:07.750 --> 02:25:10.790
models, then we can, we can consider suppose on the

02:25:10.790 --> 02:25:15.890
internet, but if we are training, uh, to our model, our

02:25:15.890 --> 02:25:20.390
data. So in that case, how we can calculate, suppose, uh,

02:25:20.450 --> 02:25:24.530
uh, a thousand. So first of all, base model, right? Base

02:25:24.530 --> 02:25:27.190
model, you are trying to train. So base model is not your

02:25:27.190 --> 02:25:29.770
model. Base model is some of the public open source model.

02:25:30.510 --> 02:25:33.470
This is not your model, right? This is a model which has

02:25:33.470 --> 02:25:36.090
been already trained on a huge amount of data set. So

02:25:36.090 --> 02:25:39.070
basically this is our base model. Now you are trying to give

02:25:39.070 --> 02:25:42.450
your data set. So first criteria should be that, okay, at

02:25:42.450 --> 02:25:44.810
least the base model should run in my system. If my baseball

02:25:44.810 --> 02:25:47.210
itself, let's suppose I'm doing an inferencing or I'm trying

02:25:47.210 --> 02:25:50.430
to train, do a training with 120 billion parameter model, or

02:25:50.430 --> 02:25:52.990
maybe 700 billion parameter model. Now, if that model

02:25:52.990 --> 02:25:56.130
itself, I will not be able to run, right. How I will be able

02:25:56.130 --> 02:25:59.270
to train it with my data set. Yeah. So my system

02:25:59.270 --> 02:26:01.890
configuration, first of all, accommodate this base model.

02:26:02.070 --> 02:26:04.430
Now once this accommodation will be done, then obviously I

02:26:04.430 --> 02:26:07.070
have to choose a Delta that what is the data which I'm

02:26:07.070 --> 02:26:09.570
trying to process. Once this will be done, then obviously my

02:26:09.570 --> 02:26:12.250
training parameter will come into a picture, my epoch and my

02:26:12.250 --> 02:26:14.510
batch size, because batch size, if batch size is more,

02:26:14.610 --> 02:26:17.150
basically, so it simply means that, that I'm trying to take

02:26:17.150 --> 02:26:22.330
more off my Ram or VRAM because batch didn't work. So that

02:26:22.330 --> 02:26:25.570
is the number of data set. It is time to set it one go in

02:26:25.570 --> 02:26:28.610
one, one go basically right in one, like a basically like a

02:26:28.610 --> 02:26:31.770
beta adjustment or in one forward propagation in a model.

02:26:31.990 --> 02:26:36.050
Yes. So that, so again, accordingly, so I have to basically

02:26:36.050 --> 02:26:40.170
like a increase my Ram or my main memory over there, epoch

02:26:40.170 --> 02:26:43.010
again, uh, if I'm trying to train it, train my model. So

02:26:43.010 --> 02:26:45.810
accordingly, I have to adjust my entire hardware structure.

02:26:46.210 --> 02:26:50.370
So my entire hardware structure depends first on my base

02:26:50.370 --> 02:26:53.070
model. Second. And the number of kind of a data set third,

02:26:53.250 --> 02:26:59.190
the parameter. Okay. So I just wanted to ask that if

02:26:59.190 --> 02:27:02.170
suppose, uh, the base model I have handled with the

02:27:02.170 --> 02:27:05.210
information that already we have taken from the internet.

02:27:05.370 --> 02:27:08.850
And then after that, how we can calculate actually any, any

02:27:08.850 --> 02:27:13.410
formula or something like that, that, uh, if I have input my

02:27:13.410 --> 02:27:17.630
data, the formula is, I think I have already talked about

02:27:17.630 --> 02:27:20.370
that formula as well, that how many CPU hours or GPU hours,

02:27:20.410 --> 02:27:22.870
it will be able to take. So technically it's a number of

02:27:22.870 --> 02:27:25.510
parameter calculation. So first we try to take a number of

02:27:25.510 --> 02:27:28.530
parameter in a consideration. Then we take a batch size.

02:27:28.670 --> 02:27:31.890
Then we take a epoch into a number of like a consideration

02:27:31.890 --> 02:27:34.890
and then like a total amount of the data or tokens

02:27:34.890 --> 02:27:39.530
basically. So once you will consider this, then there is a

02:27:39.530 --> 02:27:42.950
formula by which you will be able to calculate a GPU or CPU

02:27:42.950 --> 02:27:47.110
hours plus GPU CPU hours. So GPU frequency and CPU frequency

02:27:47.110 --> 02:27:50.090
also our clock also matters because every GPU will not same.

02:27:51.090 --> 02:27:53.050
So each one on it and anyone, it is not going to be the

02:27:53.050 --> 02:27:56.610
same. So lump sum, you will be able to do a math over there

02:27:56.610 --> 02:27:58.710
that, okay, fine. So this is the GPU hours, which is

02:27:58.710 --> 02:28:01.870
required. Uh, then you can try to like, you know, arrange

02:28:01.870 --> 02:28:05.650
your GPU plates accordingly. So also in the next class, can

02:28:05.650 --> 02:28:08.970
you, can you, uh, I'll talk about that lump sum formula. I

02:28:08.970 --> 02:28:11.030
think I have already discussed somewhere in my preparation

02:28:11.030 --> 02:28:15.690
series somewhere. It's a important, uh, because, uh, always

02:28:15.690 --> 02:28:20.310
we need to get the, uh, uh, system configuration to the. Has

02:28:20.310 --> 02:28:23.430
already been, yeah, it was, it was already actually, I

02:28:23.430 --> 02:28:26.070
remember I have already discussed that. See, as he said,

02:28:26.130 --> 02:28:28.490
already ping, right. It was discussing an interview batch

02:28:28.490 --> 02:28:30.610
because I remember I have discussed about that formula.

02:28:32.670 --> 02:28:35.290
Okay, fine. Just give me a reminder in next class. I'll talk

02:28:35.290 --> 02:28:38.230
about that formula once again. Uh, but yeah, in your recent

02:28:38.230 --> 02:28:41.510
generative a batch, uh, interview batches, that's the reason

02:28:41.510 --> 02:28:43.890
I keep on saying just join all the batches. It will give you

02:28:43.890 --> 02:28:47.190
a lot of learning. Um, but yeah, fine. We'll discuss that

02:28:47.190 --> 02:28:52.110
next class. Okay. Okay. Dhruv, go ahead with the question

02:28:52.110 --> 02:28:58.310
Naresh after that. Yeah. Yeah. Hi sir. Yeah. Good. Yeah. So,

02:28:58.410 --> 02:29:03.510
uh, my question was, so there is two project, the first one

02:29:03.510 --> 02:29:06.070
is myself of course, because I consider myself a biggest

02:29:06.070 --> 02:29:10.630
project. So I have to train data about myself because right

02:29:10.630 --> 02:29:14.670
now what I'm doing, I'm using deep seek chat GPT. I just

02:29:14.670 --> 02:29:18.150
keep updating data based on chat. Okay. But then. That is

02:29:18.150 --> 02:29:22.950
very basic and I can not train on a like very large label.

02:29:23.270 --> 02:29:26.990
Right. And the second, the second project, you can say my

02:29:26.990 --> 02:29:29.910
company that you already have to train like the finance data

02:29:29.910 --> 02:29:33.670
marketing and sales, this is a very, very real use case that

02:29:33.670 --> 02:29:36.370
every company needed, but they, but they do not start

02:29:36.370 --> 02:29:40.470
because either they do not have, uh, engineering bandwidth

02:29:40.470 --> 02:29:43.390
or either they don't know how to do that. The majority of

02:29:43.390 --> 02:29:45.570
companies are doing it nowadays. So whatever model companies

02:29:45.570 --> 02:29:47.870
are developing internally, right? Proprietary model. Uh,

02:29:48.270 --> 02:29:50.290
every, every company is doing the same thing. Every

02:29:50.290 --> 02:29:54.770
nowadays, many companies are doing it basically. In this

02:29:54.770 --> 02:29:57.710
software, like we are selling software. So we are, I'm into

02:29:57.710 --> 02:30:00.810
the software company, even they haven't yet started. I, I

02:30:00.810 --> 02:30:05.710
know this part, like, okay. Okay. Okay. Okay. Our use case

02:30:05.710 --> 02:30:09.230
is very, very used in terms of customer support, in terms of

02:30:09.230 --> 02:30:12.910
training that team in terms of HR and all these cases is

02:30:12.910 --> 02:30:15.930
like way more important. Even, even what do we do? So for

02:30:15.930 --> 02:30:17.910
our different, different customers, right? See. See how

02:30:17.910 --> 02:30:20.710
companies are generating a revenue out of generative AI or

02:30:20.710 --> 02:30:24.870
like this, uh, new AI, uh, you know, uh, wave, uh, they are

02:30:24.870 --> 02:30:26.850
actually like creating a lot of models for a client and

02:30:26.850 --> 02:30:29.690
they're charging them huge. Believe me. And technically when

02:30:29.690 --> 02:30:33.070
I say they are creating a models, this is what they do.

02:30:33.630 --> 02:30:36.990
Okay. Okay. Exactly. The same thing that you are able to see

02:30:36.990 --> 02:30:40.970
on your screen. So they're charging like a million dollars

02:30:40.970 --> 02:30:43.610
for like, you know, giving them. And they say that, okay,

02:30:43.650 --> 02:30:46.810
this is your model on your dataset. This is your proprietary

02:30:46.810 --> 02:30:50.770
model. Just charge them a million dollars for that. Okay.

02:30:50.830 --> 02:30:53.670
And that was the second thing that I just wanted to, uh,

02:30:53.770 --> 02:30:56.370
like not ask, but just wanted to add. This is a real

02:30:56.370 --> 02:30:59.070
business use case. Also, if companies are doing that, fine.

02:30:59.450 --> 02:31:02.350
If they are not doing, then we can tell them we can do in a

02:31:02.350 --> 02:31:05.330
behalf of their department. This is the proposal you should

02:31:05.330 --> 02:31:08.290
give to your client that, okay, I'll, I'll prepare a pump

02:31:08.290 --> 02:31:11.390
complete proprietary model for you, a best of best model for

02:31:11.390 --> 02:31:13.510
you because they don't know, right. What goes in the

02:31:13.510 --> 02:31:21.630
backend. Yeah. Yeah. Yeah. Okay. Got it. So like, uh, okay.

02:31:21.750 --> 02:31:25.750
I think this is a better place to like, firstly to

02:31:25.750 --> 02:31:30.350
understand with this code, just my machine and just try to

02:31:30.350 --> 02:31:33.930
understand in this code. It's very simple. I'll try to run.

02:31:34.030 --> 02:31:35.910
I'll try to explain to you once again, but yeah, nothing

02:31:35.910 --> 02:31:38.590
much to understand code wise. It's one of the simplest code

02:31:38.590 --> 02:31:41.170
you will see in a entire, you know, deep learning computers

02:31:41.170 --> 02:31:45.010
and NLP, by the way, we are doing nothing except setting a

02:31:45.010 --> 02:31:48.790
parameter. That's it. Right. So the main part will come then

02:31:48.790 --> 02:31:52.050
in, in the case, the data part only, right. If we have the

02:31:52.050 --> 02:31:54.810
data preparation part, hardware preparation part, hardware

02:31:54.810 --> 02:31:57.650
means you are not doing anything even in hardware. So it's

02:31:57.650 --> 02:31:59.850
like you should have the access of the hardware. That's it.

02:32:00.390 --> 02:32:04.230
Right. Access of the hardware. Again, model wise, like a,

02:32:04.310 --> 02:32:05.830
you know, base model wise, you're not doing anything,

02:32:05.890 --> 02:32:08.910
whatever is as available as an open source, you will be

02:32:08.910 --> 02:32:12.230
picking up that big one, a small one that depends, right.

02:32:12.330 --> 02:32:14.310
That depends upon my selection. But yeah, that is the model

02:32:14.310 --> 02:32:16.830
that you are going to choose. And then, you know, you will

02:32:16.830 --> 02:32:22.170
retrain the, fine tune the model. Okay. Yeah. And how you

02:32:22.170 --> 02:32:24.870
suggest, so you have, of course, there will be a lot more

02:32:24.870 --> 02:32:28.050
company use cases that we will be training, we will be doing

02:32:28.050 --> 02:32:31.390
all those things and what you suggest for personal case,

02:32:31.490 --> 02:32:34.590
because what I believe after five years and 10 years, there

02:32:34.590 --> 02:32:38.950
will be more advancement in AI, right. I do not want to go

02:32:38.950 --> 02:32:42.330
from scratch and tell them, okay, Hey, my name is Dhruv. I

02:32:42.330 --> 02:32:46.250
think like this. I do that. I just want, I have one data set

02:32:46.250 --> 02:32:50.950
on kind of the in backend, the kind of API. If I get that

02:32:50.950 --> 02:32:54.990
thing to that AI, it knows everything about me, how I, how I

02:32:54.990 --> 02:32:58.910
think, how I thought, how was my mindset in 2025 now, how

02:32:58.910 --> 02:33:04.250
I'm thinking, like 2040 to that level of scale in coming

02:33:04.250 --> 02:33:10.110
time. So like a platform or like local, how, how to start

02:33:10.110 --> 02:33:12.670
with that, because this is not a one day part. This is a

02:33:12.670 --> 02:33:17.710
lifelong part, if I'm alive in like, see if you, your data

02:33:17.710 --> 02:33:20.950
is changing frequently means about yourself, let's suppose

02:33:20.950 --> 02:33:24.610
about things are changing frequently, then it's better to go

02:33:24.610 --> 02:33:30.150
with the RAG approach till today, based on till today's

02:33:30.150 --> 02:33:32.550
data. So maybe you can try to train the model and then

02:33:32.550 --> 02:33:35.210
whatever, like update, which will come, maybe just start

02:33:35.210 --> 02:33:39.170
putting up in a RAG manner and then model will be capable

02:33:39.170 --> 02:33:41.370
enough to, you know, understand your past as well as

02:33:41.370 --> 02:33:43.710
understand your current data. And based on that, it will be

02:33:43.710 --> 02:33:45.510
able to give you the answer. That's the approach. Number one

02:33:45.510 --> 02:33:48.430
approach, number two, memory based approach, which your chat

02:33:48.430 --> 02:33:52.390
GPT is using by the way, your chat GPT is already using a

02:33:52.390 --> 02:33:55.390
memory approach, right? Or even URI when you use a URI, so

02:33:55.390 --> 02:33:57.590
URI can understand you, it can remember you because what we

02:33:57.590 --> 02:34:00.970
have done. So we have basically attached a memory. So

02:34:00.970 --> 02:34:03.210
whatever conversation that you are trying to do, so we are

02:34:03.210 --> 02:34:06.850
trying to like, you know, store some sort of a summary of

02:34:06.850 --> 02:34:09.330
your conversation. So it understands basically who is who.

02:34:10.630 --> 02:34:13.210
Yeah. So right now. Basically, because I'm working with

02:34:13.210 --> 02:34:16.870
anything. So RAG seems more comfortable and more doable for

02:34:16.870 --> 02:34:19.610
me. And the reason, because I think there are, I can add

02:34:19.610 --> 02:34:23.330
more type of data as well, images and all. Yeah. Yeah. Yeah.

02:34:23.330 --> 02:34:26.270
So RAG is one. And then like, see this, this model will be

02:34:26.270 --> 02:34:28.630
available somewhere on a plate, somewhere on some like a

02:34:28.630 --> 02:34:31.990
instance, right? So in the next class, I'm going to show you

02:34:31.990 --> 02:34:34.530
that, how we can expose this model to the outer world,

02:34:34.630 --> 02:34:38.250
basically as an API. So if my model will be available as an

02:34:38.250 --> 02:34:41.890
API. Okay. Okay. So you are going to be able to call a

02:34:41.890 --> 02:34:45.290
request, right? A fancy STTPS request. Okay. Okay. Yeah.

02:34:45.370 --> 02:34:49.930
Yeah. Right. So from a N8N, you will be able to call your

02:34:49.930 --> 02:34:53.810
model, your fine tuned model, right? The way you are calling

02:34:53.810 --> 02:34:57.490
GPT models. Or the way you are calling URI model. How you're

02:34:57.490 --> 02:35:00.310
calling URI? URI models, basically. STTPS request, right?

02:35:00.650 --> 02:35:03.350
Yeah. STTPS request. Yes. Same you will be able to do in the

02:35:03.350 --> 02:35:05.450
next class itself. Next class means like next Saturday.

02:35:06.730 --> 02:35:08.990
Exactly same thing. You will be able to do it with all these

02:35:08.990 --> 02:35:11.790
five, six models. Your finance, your HR, health, everything.

02:35:11.790 --> 02:35:16.030
With all the models. Got it. And when you say memory, the

02:35:16.030 --> 02:35:20.090
second method, the memory method, does it wrong to say it is

02:35:20.090 --> 02:35:23.670
just take input in text format or we can give it in like

02:35:23.670 --> 02:35:26.910
video image and all the other format also or only text

02:35:26.910 --> 02:35:31.970
format? Generally, like we can, we give a memory into a text

02:35:31.970 --> 02:35:36.150
format, I will say, yeah, in a token format. In a token

02:35:36.150 --> 02:35:39.310
format. Yes. Yeah. And token could be going forward your

02:35:39.310 --> 02:35:43.110
image pixels, bytes. Yeah. Yeah. Or it could be anything.

02:35:43.170 --> 02:35:46.030
But yeah, as of now, when we are talking about this textual

02:35:46.030 --> 02:35:48.410
conversation. So in general, we are considering a token of

02:35:48.410 --> 02:35:51.310
the textual conversation. Okay. And I think this is where

02:35:51.310 --> 02:35:54.450
the good part with vector database and RAG is that already

02:35:54.450 --> 02:35:57.910
it converts all the PDF images and all it tokenize at the

02:35:57.910 --> 02:36:03.230
end that also tokenize. Not tokenize. Vectorize. Okay. Yeah.

02:36:03.230 --> 02:36:07.410
Tokenization is a part of vectorization. Okay. Okay. Yeah.

02:36:08.430 --> 02:36:12.330
Fine. Yeah. Yeah. I think. Okay. Yeah. Okay. Okay. Yeah.

02:36:12.390 --> 02:36:16.690
Another is quite pleased with the question. Yeah. So my

02:36:16.690 --> 02:36:19.850
first question would be like, on what basis we have to

02:36:19.850 --> 02:36:22.950
decide whether we should go for a full parameter training

02:36:22.950 --> 02:36:27.610
or, you know, a best kind of training. Hmm. And what

02:36:27.610 --> 02:36:31.490
advantages it you are? What are the disadvantages it gives?

02:36:31.630 --> 02:36:35.810
Like, basically, what is the deciding factor? Okay. So see,

02:36:35.850 --> 02:36:38.910
full fine tuning is something like as its approach itself

02:36:38.910 --> 02:36:41.110
says. Yeah. So that you are changing the entire way. It's

02:36:41.110 --> 02:36:44.630
right. You're not changing like, you know, some couple of

02:36:44.630 --> 02:36:49.090
it. So when you have a massive data with, um, means kind of

02:36:49.090 --> 02:36:54.490
a data you have basically, so which is nowhere close to our

02:36:54.490 --> 02:36:59.310
base model learning. Let's suppose I have a base model and I

02:36:59.310 --> 02:37:03.650
have some sort of a data, but my data and a base model, so

02:37:03.650 --> 02:37:05.350
yeah, baseball understands grammar based on model,

02:37:05.410 --> 02:37:07.270
understand the relationship between the words and tokens.

02:37:07.390 --> 02:37:12.070
That's okay. But, uh, base model is nowhere aware about my

02:37:12.070 --> 02:37:14.790
domain or my division of the data. In that case, obviously

02:37:14.790 --> 02:37:18.490
what I will do just to get a best of best result means less

02:37:18.490 --> 02:37:21.430
hallucination. I'll go out with a full fine tuning, but

02:37:21.430 --> 02:37:24.990
again, the cons will be, uh, it will be a heavy approach. So

02:37:24.990 --> 02:37:28.750
it reads a more computation, uh, for me, inferencing will be

02:37:28.750 --> 02:37:30.750
same because size is not going to change even in full fine

02:37:30.750 --> 02:37:33.390
tuning and then in a Laura in Cora, obviously it's going to

02:37:33.390 --> 02:37:36.390
change. Uh, so in that approach, I'll go ahead with a full

02:37:36.390 --> 02:37:41.550
fine tuning. If I have a base model, which is closer to my

02:37:41.550 --> 02:37:44.270
domain understanding night, which understands my domain, but

02:37:44.270 --> 02:37:48.830
I just have to, you know, uh, give just a policy or I can

02:37:48.830 --> 02:37:51.450
say, you know, I just have to add a little bit of

02:37:51.450 --> 02:37:54.650
information about my specific domain. In that case, I can go

02:37:54.650 --> 02:37:57.310
out with the, uh, like a preferred approach. So parameter

02:37:57.310 --> 02:38:01.530
efficient, fine tuning approach inside that Laura Cora. So

02:38:01.530 --> 02:38:04.450
whenever I have a requirement of hosting a model on an edge

02:38:04.450 --> 02:38:07.770
devices, right, I want to run my model on maybe a Raspberry

02:38:07.770 --> 02:38:11.330
Pi, maybe in my Android, maybe in my iOS system, like iOS

02:38:11.330 --> 02:38:14.610
mobile devices with a limited compute and a limited, you

02:38:14.610 --> 02:38:16.810
know, memory. So in that case, I will go ahead with a

02:38:16.810 --> 02:38:20.770
quantize Cora one DPO. So DPO, again, it's a full fine

02:38:20.770 --> 02:38:22.630
tuning approach by the way, means we are training the entire

02:38:22.630 --> 02:38:25.250
weights, but yeah, so the approach itself is different over

02:38:25.250 --> 02:38:28.470
here. We are trying to create a feedback loop and feedback.

02:38:28.550 --> 02:38:30.950
Also we have mentioned that learn this and don't learn this

02:38:30.950 --> 02:38:34.530
one. I believe I'm able to give you an answer. Yeah. Yeah.

02:38:34.530 --> 02:38:37.870
Yeah. Thank you. Yeah. Yeah. Thank you. Okay. Uh, what is

02:38:37.870 --> 02:38:44.350
your question? Yes. So training arguments, uh, these, these

02:38:44.350 --> 02:38:47.630
are the parameters are fixed or it's our own defined

02:38:47.630 --> 02:38:50.530
functions. No, it's not our own defined function. It's

02:38:50.530 --> 02:38:54.190
actually fixed. It's coming from here. Okay. Yeah. It's,

02:38:54.190 --> 02:38:56.750
it's already fixed. You are not doing anything. I think you

02:38:56.750 --> 02:38:59.850
have not attended, uh, I believe, uh, never attended a deep

02:38:59.850 --> 02:39:01.770
learning or some other classes, because if you have attended

02:39:01.770 --> 02:39:04.790
some deep learning classes, uh, in that case, you would not

02:39:04.790 --> 02:39:07.390
have asked me this question. Because all of this parameter,

02:39:07.670 --> 02:39:10.830
I mean, like it's not new, it's actually like a deep

02:39:10.830 --> 02:39:13.230
learning parameter, which we use for any neural network, by

02:39:13.230 --> 02:39:19.330
the way, I think you should, you should visit some of the,

02:39:19.330 --> 02:39:22.530
uh, deep learning lecture. Maybe some of my lectures that

02:39:22.530 --> 02:39:24.430
will make you comfortable with respect to neural network.

02:39:24.850 --> 02:39:28.250
Yeah. Sure. Other things that are related to the different

02:39:28.250 --> 02:39:33.170
languages, so different files that we need to create data

02:39:33.170 --> 02:39:37.250
data files. Are there any possibilities? I 18 in kind of

02:39:37.250 --> 02:39:40.130
things we need to implement the same answer in the English

02:39:40.130 --> 02:39:45.350
we can get at the end of the day, I need only this much,

02:39:45.430 --> 02:39:49.690
right? Maybe I have a different file. Maybe I have a

02:39:49.690 --> 02:39:51.990
different data set. You are able to see my highlighted one,

02:39:52.050 --> 02:39:56.630
right? I just need this one simple. I need in this format

02:39:56.630 --> 02:40:00.770
where I need your like a input. I need a output. That's it.

02:40:00.850 --> 02:40:03.230
Yeah. It means your question, your instruction, and then

02:40:03.230 --> 02:40:07.910
it's answer. Uh, I don't, my model don't need any, or my

02:40:07.910 --> 02:40:11.530
model don't even understand anything except this one as

02:40:11.530 --> 02:40:16.590
simple as that. Yeah. So doesn't matter in which language we

02:40:16.590 --> 02:40:20.170
are trying to like a train the model. Ultimately I have to

02:40:20.170 --> 02:40:24.850
prepare my data in this format. Data is coming from maybe a

02:40:24.850 --> 02:40:28.050
text file, CSV file, two files, or maybe it's just from one

02:40:28.050 --> 02:40:33.980
single file. Uh, basically my model don't care about it. So

02:40:33.980 --> 02:40:38.040
in Java, like we, uh. We do the I 18 in that library we use

02:40:38.040 --> 02:40:42.060
and convert, uh, in any of the languages to kind of things

02:40:42.060 --> 02:40:45.340
are there in the pipeline. No, no, that is, uh, like

02:40:45.340 --> 02:40:48.220
adjusted. That is just a notation. I believe I 18 a, that

02:40:48.220 --> 02:40:51.320
you are talking about, right? Uh, it's never do a language

02:40:51.320 --> 02:40:53.540
conversion. Language conversion is something like very

02:40:53.540 --> 02:40:55.980
different. For example, if I'm saying something in English

02:40:55.980 --> 02:40:59.060
and then you have to like translate something in Hindi. So

02:40:59.060 --> 02:41:01.460
obviously like, uh, uh, it's, it's a complete, like a

02:41:01.460 --> 02:41:04.020
translation, right. From one language to other languages. So

02:41:04.020 --> 02:41:08.000
you have to give. Data in that manner, basically. And if

02:41:08.000 --> 02:41:10.340
your data is bad, right, your data is bad, then it will not

02:41:10.340 --> 02:41:15.700
be able to understand. Yeah. Yeah. In terms of language, uh,

02:41:16.200 --> 02:41:22.210
different, like a language based training. Okay. So hope all

02:41:22.210 --> 02:41:25.230
of you are enjoying it. Uh, I'll just upload this code file.

02:41:25.390 --> 02:41:28.850
Uh, don't do much this week. I'll say, uh, maybe try to

02:41:28.850 --> 02:41:30.990
complete a previous assignment, which I have given to you,

02:41:31.030 --> 02:41:33.630
which was, uh, based on in it and 10 assignments I've

02:41:33.630 --> 02:41:36.570
already given to you 10 problem statements. Okay. So just

02:41:36.570 --> 02:41:41.110
try to maybe look into all of these, prepare your question

02:41:41.110 --> 02:41:43.510
for me so that you know, you can come to next class and then

02:41:43.510 --> 02:41:46.310
you can ask me questions. I'll show you end to end

02:41:46.310 --> 02:41:49.070
everything. Till production means till production. We'll

02:41:49.070 --> 02:41:51.570
make it live. We'll try to integrate with a multiple system.

02:41:51.710 --> 02:41:54.210
Like I said, telegram, maybe WhatsApp, maybe, maybe with the

02:41:54.210 --> 02:41:59.630
Uri chat kind of a system. So fully productionized my own

02:41:59.630 --> 02:42:03.310
custom departments as simple as that, that will be my

02:42:03.310 --> 02:42:08.170
objective for a next week. And, uh, believe me, you all will

02:42:08.170 --> 02:42:11.610
enjoy, and you all are going to write this kind of a project

02:42:11.610 --> 02:42:14.010
directly into your resume. You say that, okay, I have worked

02:42:14.010 --> 02:42:16.010
for this department, that department, and I have like, you

02:42:16.010 --> 02:42:19.690
know, uh, build this model, that model, uh, this much time,

02:42:19.770 --> 02:42:22.670
this much of data, this much of team size, everything,

02:42:22.830 --> 02:42:25.690
everything. And this was a GPU, everything you will be able

02:42:25.690 --> 02:42:28.570
to talk about. And then I have like, uh, done this kind of

02:42:28.570 --> 02:42:31.410
inferencing. And this is how like accuracy was each and

02:42:31.410 --> 02:42:33.610
everything you will be able to talk about in your interview.

02:42:33.730 --> 02:42:37.130
So this is like. Okay. So this is really a real world, which

02:42:37.130 --> 02:42:40.250
every company does by the way. Yeah. Not just one company.

02:42:40.310 --> 02:42:43.010
Every company does that. And they like, uh, you know, charge

02:42:43.010 --> 02:42:47.110
their client a million dollars for that one. So fine. Okay.

02:42:47.170 --> 02:42:48.770
Sumit, you have a question. Naresh, you have a question

02:42:48.770 --> 02:42:54.050
again. Okay. Go ahead then. Uh, just in last, uh, batch

02:42:54.050 --> 02:42:58.070
during when you explain the mathematics, you mentioned in

02:42:58.070 --> 02:43:02.430
the Q LoRa, when we reduce the metric size, the metric size

02:43:02.430 --> 02:43:07.370
would not be a subset of the original. No, basically it's

02:43:07.370 --> 02:43:11.010
not a subset of the original. It's like a ranking. Just take

02:43:11.010 --> 02:43:13.470
one reference that, okay, when I'm trying to create a

02:43:13.470 --> 02:43:17.270
parallel matrixes, then what should be the size? So it just

02:43:17.270 --> 02:43:20.930
tried to take a rank reference for that one rank means like

02:43:20.930 --> 02:43:23.290
number of rows or columns. You can say number of rows,

02:43:23.430 --> 02:43:26.650
right? In, in general, uh, as of now, uh, if you understand

02:43:26.650 --> 02:43:29.450
the metrics multiplication and then metrics, uh, mathematics

02:43:29.450 --> 02:43:33.290
basically, so just, it takes inspiration and then based on

02:43:33.290 --> 02:43:36.090
that, it like create a parallel one. But it's not a subset

02:43:36.090 --> 02:43:41.290
of it. Never. It takes inspiration. It's trying to add a

02:43:41.290 --> 02:43:44.030
Delta. So basically there is something called Delta W that

02:43:44.030 --> 02:43:48.210
it tries to add over there. Understood. And so just like in

02:43:48.210 --> 02:43:52.090
a case of fine, like full fine tuning, if we are aware that

02:43:52.090 --> 02:43:54.690
our base model is not very much close to the, what we are

02:43:54.690 --> 02:43:59.510
expecting. So in that case, uh, why are we even using the

02:43:59.510 --> 02:44:03.390
base? Even we can only train a new model. Yeah. Because.

02:44:04.830 --> 02:44:07.350
Because I need some model who understand at least a grammar

02:44:07.350 --> 02:44:11.910
language, maybe my Tamil, Telugu, Hindi, English, Spanish

02:44:11.910 --> 02:44:14.630
languages, because that is also important, right?

02:44:17.710 --> 02:44:20.930
So if you, if you will try to train the data with respect

02:44:20.930 --> 02:44:23.930
to, uh, languages, you need literally a very, very huge

02:44:23.930 --> 02:44:26.750
volume of data. Language understanding is not that easy. You

02:44:26.750 --> 02:44:32.150
need a world's conversational data for that. Getting my

02:44:32.150 --> 02:44:35.290
point. That means we are using the functionality of

02:44:35.290 --> 02:44:38.350
understanding the language. Not the actual data. Not the

02:44:38.350 --> 02:44:41.230
actual one. Yeah. Not the output that you are looking for

02:44:41.230 --> 02:44:44.910
with respect to your own domain. We are just looking for

02:44:44.910 --> 02:44:47.830
some model. So see, uh, for example, I'll, I'll just give

02:44:47.830 --> 02:44:51.790
you one example, right? So I hear, uh, there are many non

02:44:51.790 --> 02:44:54.190
tech people in this batch. Let's suppose, let's suppose you

02:44:54.190 --> 02:44:58.430
are a non tech guy. Yeah. And you don't understand like a

02:44:58.430 --> 02:45:01.390
programming. You don't understand model anything, but you

02:45:01.390 --> 02:45:05.990
are able to understand whatever I'm able to teach you in a

02:45:05.990 --> 02:45:08.430
class. Because you understand at least language, English

02:45:08.430 --> 02:45:12.290
language. Yes. What if, if you are not able to understand

02:45:12.290 --> 02:45:14.070
English language, will you be able to understand the deep

02:45:14.070 --> 02:45:16.610
learning and this, uh, uh, training concept, which I'm

02:45:16.610 --> 02:45:20.770
teaching you? No, there will be no communication because I

02:45:20.770 --> 02:45:23.810
don't know what you are saying. Exactly. Same goes over

02:45:23.810 --> 02:45:27.730
here. I think you are able to get your answer, right? Hmm.

02:45:28.310 --> 02:45:31.670
So basically you are the, before joining before, like, you

02:45:31.670 --> 02:45:34.410
know, enrolling into this batch, you are basically a base

02:45:34.410 --> 02:45:40.910
model. A person who understands just, uh, English or like

02:45:40.910 --> 02:45:43.710
all those conversations person can understand, right? But

02:45:43.710 --> 02:45:47.070
you were not aware about a generative AI before joining this

02:45:47.070 --> 02:45:50.390
batch. Now, once you have joined this batch, now you are

02:45:50.390 --> 02:45:55.010
learning right on your, on top of your base model. So Sumit

02:45:55.010 --> 02:45:57.910
Kumar was technically a base model till the date we have

02:45:57.910 --> 02:46:00.030
launched this batch. And then Sumit Kumar has started

02:46:00.030 --> 02:46:04.070
learning basically, and still like he's like a learning, but

02:46:04.070 --> 02:46:08.430
base model was required. If someone has joined my class who

02:46:08.430 --> 02:46:10.510
don't understand my language, who don't understand my

02:46:10.510 --> 02:46:12.510
English, who don't understand my punctuation and

02:46:12.510 --> 02:46:16.390
pronunciation, right? Then obviously, uh, Sumit Kumar or no

02:46:16.390 --> 02:46:19.230
one will be able to understand generative AI, right? That's

02:46:19.230 --> 02:46:20.870
the only difference. And I think that's the best example.

02:46:20.990 --> 02:46:23.250
And I believe this is an example which everyone and anyone

02:46:23.250 --> 02:46:24.390
can understand now.

02:46:27.390 --> 02:46:33.250
Yeah, exactly. So why do we need a good base model even? And

02:46:33.250 --> 02:46:37.030
why we should not. So if I will. Now Sumit told me that,

02:46:37.110 --> 02:46:39.510
okay, what if we can try to train the model from the

02:46:39.510 --> 02:46:41.750
scratch? Yeah, you can do it because transform architecture

02:46:41.750 --> 02:46:44.430
is nothing. Just create layer by layer. And I have even done

02:46:44.430 --> 02:46:47.370
that in my classes. Right? Yes. It will go and check my code

02:46:47.370 --> 02:46:49.990
base. I have already discussed about that, that how to train

02:46:49.990 --> 02:46:53.130
a transformer from the various scratch, right? But the

02:46:53.130 --> 02:46:55.530
problem is that, that let's suppose if I'll start teaching

02:46:55.530 --> 02:46:58.770
Sumit, first of all English. So maybe I'll take a years of

02:46:58.770 --> 02:47:01.650
time to teach Sumit just the English language and just like,

02:47:01.670 --> 02:47:04.670
you know, the way we try to communicate. And then only I

02:47:04.670 --> 02:47:06.790
will be able to teach the generatively specific things.

02:47:07.530 --> 02:47:12.890
Yeah. That will take a lot of time. Time is what? Data. So

02:47:12.890 --> 02:47:15.210
let's suppose I'm taking three years of time to teach Sumit

02:47:15.210 --> 02:47:17.690
just the English. It simply means that I'm talking to Sumit,

02:47:17.730 --> 02:47:19.410
right? I'm trying to transfer the data to Sumit.

02:47:19.650 --> 02:47:22.710
Technically, I am like trying to send a lot of data to Sumit

02:47:22.710 --> 02:47:25.610
because Sumit will not be able to like, you know, learn

02:47:25.610 --> 02:47:28.350
English and all those like, you know, punctuation, grammar

02:47:28.350 --> 02:47:30.870
and everything. And Sumit will not be able to communicate

02:47:30.870 --> 02:47:33.590
with me efficiently. I'll listen until he's not having a

02:47:33.590 --> 02:47:41.390
problem. And then only

02:47:41.390 --> 02:47:43.850
I will be able to like, you know, train on my generative AI.

02:47:43.990 --> 02:47:47.490
So that approach is going to be the costliest approach. That

02:47:47.490 --> 02:47:49.210
is the reason. So we take a base model.

02:47:52.820 --> 02:47:55.500
That would be very nice explanation, sir. Very good example.

02:47:56.060 --> 02:47:59.360
Yeah. So I think now everyone can understand this. Thank

02:47:59.360 --> 02:48:02.260
you. Okay. So why do we need a base model? And no one will

02:48:02.260 --> 02:48:05.140
ask me doubt on that. Okay. Go ahead. Naresh, go ahead.

02:48:05.280 --> 02:48:10.560
Okay. Your question. Yeah. So let's say I have some data and

02:48:10.560 --> 02:48:15.080
I have trained my base model, right? So after a couple of

02:48:15.080 --> 02:48:19.780
years or three years later, I got a new data to be trained.

02:48:20.740 --> 02:48:25.040
Now, should I take base model and train existing data and

02:48:25.040 --> 02:48:28.060
new data combined? Or should I take already trained model?

02:48:28.420 --> 02:48:31.000
Your previous model will behave as a base model this time.

02:48:32.000 --> 02:48:34.780
Okay. Your previous model. Already trained model will become

02:48:34.780 --> 02:48:37.580
my base model. Base model. Yeah. Yeah. Your training model

02:48:37.580 --> 02:48:40.120
will become a base model next time. Right. Because it is, it

02:48:40.120 --> 02:48:42.240
has already been trained on your previous set of the data,

02:48:42.340 --> 02:48:44.940
right? So take that as a consider that as a base model,

02:48:45.040 --> 02:48:47.960
train that or retrain that model itself. And this is, this,

02:48:48.020 --> 02:48:50.220
this is what we are doing when we are doing a fine tuning,

02:48:50.320 --> 02:48:55.940
right? We are choosing someone else's trained model. This is

02:48:55.940 --> 02:48:57.860
technically what we are doing, right? In terms of fine

02:48:57.860 --> 02:48:59.980
tuning, we are choosing someone else's, someone has trained

02:48:59.980 --> 02:49:04.340
the model. I'm just using it. So next, next time, just use

02:49:04.340 --> 02:49:07.440
your previous model. The version one in a version two. Yeah.

02:49:07.540 --> 02:49:12.400
Got it. Thanks. Yeah. Yes. We need a basic of DLNLP, not a

02:49:12.400 --> 02:49:16.660
full MLDLNLP. Yeah. I mean like, see base is always going to

02:49:16.660 --> 02:49:18.660
help you out. See whatever parameter, which I have written

02:49:18.660 --> 02:49:21.900
in today's class, right? Believe me, these, none of the

02:49:21.900 --> 02:49:24.560
parameters are new. None means literally none. If you will

02:49:24.560 --> 02:49:27.720
go through my deep learning and all this concept, right, NLP

02:49:27.720 --> 02:49:30.460
concept from my previous batch or like from our previous

02:49:30.460 --> 02:49:34.040
classes, you will be able to find out that every concept has

02:49:34.040 --> 02:49:39.580
been explained. On a, like a grassroot label, like in such a

02:49:39.580 --> 02:49:42.080
way, because that is a base. It doesn't matter what system

02:49:42.080 --> 02:49:44.000
you're trying to create. Everything is coming from there

02:49:44.000 --> 02:49:48.300
itself. Right? Even the advanced system. So I always suggest

02:49:48.300 --> 02:49:52.380
people, even nowadays, I suggest people that it's fine. AI

02:49:52.380 --> 02:49:56.380
is fine. LLM is fine. GPT is fine. But at least try to spend

02:49:56.380 --> 02:49:59.060
six, seven months of time, or maybe a good eight, nine

02:49:59.060 --> 02:50:02.480
months of time. Six months is minimum, right? Just to build

02:50:02.480 --> 02:50:04.540
your base because it will be with you for an entire

02:50:04.540 --> 02:50:09.700
lifetime. Right? So base is important. In MLDL, I have

02:50:09.700 --> 02:50:12.900
recently started. So maybe you can join that batch as well.

02:50:12.980 --> 02:50:15.680
So you can start learning like a basic of MLDL and stats.

02:50:15.980 --> 02:50:19.240
And then maybe like a, you can go ahead with my deep

02:50:19.240 --> 02:50:21.720
learning lecture or the previous lecture, which I have given

02:50:21.720 --> 02:50:23.880
in full stack data science. That is also available to you,

02:50:23.900 --> 02:50:26.680
to all of you. Right? Where machine stats, machine learning,

02:50:26.740 --> 02:50:29.600
deep learning, computer vision, NLP, transform architecture,

02:50:30.020 --> 02:50:32.000
everything is available. Everything is literally, everything

02:50:32.000 --> 02:50:34.840
is available. Right? So that will help you out to understand

02:50:34.840 --> 02:50:35.420
the basics of MLDL. If you want to, you know, build your

02:50:35.420 --> 02:50:39.480
base in your free time, just do it. If you want, if you

02:50:39.480 --> 02:50:44.600
wanted to become a better techie, right? So believe me

02:50:44.600 --> 02:50:48.120
tomorrow, you, if you, if you have a, if your base is clear

02:50:48.120 --> 02:50:51.900
and if you're able to learn all those things tomorrow, if

02:50:51.900 --> 02:50:54.180
new technology will come, new thing will come. You don't

02:50:54.180 --> 02:50:56.160
need me. You will be able to understand it automatically.

02:50:56.760 --> 02:51:00.320
Otherwise you will need again and again, someone likes the

02:51:00.320 --> 02:51:02.840
Hanshu Kumar to give you an explanation and teach you.

02:51:03.300 --> 02:51:08.080
Right? Uh, so choice is yours. As simple as that. If you

02:51:08.080 --> 02:51:12.660
don't need me tomorrow, then prepare your base first. That

02:51:12.660 --> 02:51:17.320
is already given in your dashboard. Asking algo's math

02:51:17.320 --> 02:51:20.900
behind it. Yeah. Company by company. Obviously they should

02:51:20.900 --> 02:51:23.140
ask. Even if I'm going to take your interview, I'll be

02:51:23.140 --> 02:51:26.980
asking a basic, I'll not be asking because I know a majority

02:51:26.980 --> 02:51:32.740
of people will get stuck there on a base side of it. Maybe

02:51:32.740 --> 02:51:36.140
your knowledge also. Yeah. That's why I'm like, I'm just

02:51:36.140 --> 02:51:41.160
telling you that form a capability in yourself. Yeah. You

02:51:41.160 --> 02:51:44.260
should not, you know, depend on anyone. Even me in the

02:51:44.260 --> 02:51:44.520
future.

02:51:47.650 --> 02:51:50.490
Yeah. Okay. So thank you so much guys. Hope all of you have

02:51:50.490 --> 02:51:52.530
enjoyed. Hope we have discussed something interesting in

02:51:52.530 --> 02:51:55.470
today's class. And, um, even to like next class is going to

02:51:55.470 --> 02:51:58.110
be very much interesting Saturday class code base and

02:51:58.110 --> 02:52:00.390
everything is ready with me. I have to give you explanation.

02:52:00.590 --> 02:52:03.490
I have to, you know, host it, uh, make it final, make all

02:52:03.490 --> 02:52:05.930
the model live, all the departments of my, you know,

02:52:05.930 --> 02:52:08.990
organization live. Uh, integrate with a multiple systems,

02:52:09.190 --> 02:52:12.370
all those in it and all those agent and telegram everything.

02:52:13.090 --> 02:52:17.370
And, uh, yeah, so that it will be like a real and live, uh,

02:52:17.430 --> 02:52:21.130
to all of us. So code I'll update. So once I will upload,

02:52:21.230 --> 02:52:24.670
you know, the recording, maybe by tonight, uh, by that time

02:52:24.670 --> 02:52:26.870
I'll upload the code as well. Yeah. So along with the

02:52:26.870 --> 02:52:29.570
recording, everything will be uploaded. So fine with that.

02:52:29.650 --> 02:52:32.150
Thank you so much. Take care and see you again. Next class

02:52:32.150 --> 02:52:35.310
guys, Saturday. Don't forget to join this Saturday class.

02:52:35.530 --> 02:52:37.790
It's going to be very important. All the classes are

02:52:37.790 --> 02:52:41.450
important obviously, but yeah, join, let's join Saturday's

02:52:41.450 --> 02:52:44.490
class. Thank you everyone. Take care. Take care.

